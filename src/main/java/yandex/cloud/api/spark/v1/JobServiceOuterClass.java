// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yandex/cloud/spark/v1/job_service.proto

package yandex.cloud.api.spark.v1;

public final class JobServiceOuterClass {
  private JobServiceOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface GetJobRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.GetJobRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    java.lang.String getJobId();
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    com.google.protobuf.ByteString
        getJobIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.GetJobRequest}
   */
  public static final class GetJobRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.GetJobRequest)
      GetJobRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use GetJobRequest.newBuilder() to construct.
    private GetJobRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private GetJobRequest() {
      clusterId_ = "";
      jobId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new GetJobRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private GetJobRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              jobId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_GetJobRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.Builder.class);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int JOB_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object jobId_;
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    @java.lang.Override
    public java.lang.String getJobId() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        jobId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getJobIdBytes() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        jobId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jobId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, jobId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getJobId()
          .equals(other.getJobId())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + JOB_ID_FIELD_NUMBER;
      hash = (53 * hash) + getJobId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.GetJobRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.GetJobRequest)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_GetJobRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        jobId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest(this);
        result.clusterId_ = clusterId_;
        result.jobId_ = jobId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getJobId().isEmpty()) {
          jobId_ = other.jobId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object jobId_ = "";
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The jobId.
       */
      public java.lang.String getJobId() {
        java.lang.Object ref = jobId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          jobId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for jobId.
       */
      public com.google.protobuf.ByteString
          getJobIdBytes() {
        java.lang.Object ref = jobId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          jobId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        jobId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearJobId() {
        
        jobId_ = getDefaultInstance().getJobId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        jobId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.GetJobRequest)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.GetJobRequest)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<GetJobRequest>
        PARSER = new com.google.protobuf.AbstractParser<GetJobRequest>() {
      @java.lang.Override
      public GetJobRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetJobRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<GetJobRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<GetJobRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.GetJobRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListJobsRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ListJobsRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the cluster to list Spark jobs of.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the cluster to list Spark jobs of.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * The maximum number of results per page that should be returned. If the number of available
     * results is larger than `page_size`, the service returns a `next_page_token` that can be used
     * to get the next page of results in subsequent ListJobs requests.
     * Acceptable values are 0 to 1000, inclusive. Default value: 100.
     * </pre>
     *
     * <code>int64 page_size = 2 [(.yandex.cloud.value) = "&lt;=1000"];</code>
     * @return The pageSize.
     */
    long getPageSize();

    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The pageToken.
     */
    java.lang.String getPageToken();
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for pageToken.
     */
    com.google.protobuf.ByteString
        getPageTokenBytes();

    /**
     * <pre>
     * String that describes a display filter.
     * </pre>
     *
     * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
     * @return The filter.
     */
    java.lang.String getFilter();
    /**
     * <pre>
     * String that describes a display filter.
     * </pre>
     *
     * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
     * @return The bytes for filter.
     */
    com.google.protobuf.ByteString
        getFilterBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ListJobsRequest}
   */
  public static final class ListJobsRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ListJobsRequest)
      ListJobsRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListJobsRequest.newBuilder() to construct.
    private ListJobsRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListJobsRequest() {
      clusterId_ = "";
      pageToken_ = "";
      filter_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListJobsRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListJobsRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 16: {

              pageSize_ = input.readInt64();
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              pageToken_ = s;
              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();

              filter_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.Builder.class);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the cluster to list Spark jobs of.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the cluster to list Spark jobs of.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PAGE_SIZE_FIELD_NUMBER = 2;
    private long pageSize_;
    /**
     * <pre>
     * The maximum number of results per page that should be returned. If the number of available
     * results is larger than `page_size`, the service returns a `next_page_token` that can be used
     * to get the next page of results in subsequent ListJobs requests.
     * Acceptable values are 0 to 1000, inclusive. Default value: 100.
     * </pre>
     *
     * <code>int64 page_size = 2 [(.yandex.cloud.value) = "&lt;=1000"];</code>
     * @return The pageSize.
     */
    @java.lang.Override
    public long getPageSize() {
      return pageSize_;
    }

    public static final int PAGE_TOKEN_FIELD_NUMBER = 3;
    private volatile java.lang.Object pageToken_;
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The pageToken.
     */
    @java.lang.Override
    public java.lang.String getPageToken() {
      java.lang.Object ref = pageToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        pageToken_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for pageToken.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getPageTokenBytes() {
      java.lang.Object ref = pageToken_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        pageToken_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FILTER_FIELD_NUMBER = 4;
    private volatile java.lang.Object filter_;
    /**
     * <pre>
     * String that describes a display filter.
     * </pre>
     *
     * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
     * @return The filter.
     */
    @java.lang.Override
    public java.lang.String getFilter() {
      java.lang.Object ref = filter_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        filter_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * String that describes a display filter.
     * </pre>
     *
     * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
     * @return The bytes for filter.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getFilterBytes() {
      java.lang.Object ref = filter_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        filter_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (pageSize_ != 0L) {
        output.writeInt64(2, pageSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(pageToken_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, pageToken_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(filter_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, filter_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (pageSize_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, pageSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(pageToken_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, pageToken_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(filter_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, filter_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (getPageSize()
          != other.getPageSize()) return false;
      if (!getPageToken()
          .equals(other.getPageToken())) return false;
      if (!getFilter()
          .equals(other.getFilter())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + PAGE_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getPageSize());
      hash = (37 * hash) + PAGE_TOKEN_FIELD_NUMBER;
      hash = (53 * hash) + getPageToken().hashCode();
      hash = (37 * hash) + FILTER_FIELD_NUMBER;
      hash = (53 * hash) + getFilter().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ListJobsRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ListJobsRequest)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        pageSize_ = 0L;

        pageToken_ = "";

        filter_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest(this);
        result.clusterId_ = clusterId_;
        result.pageSize_ = pageSize_;
        result.pageToken_ = pageToken_;
        result.filter_ = filter_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (other.getPageSize() != 0L) {
          setPageSize(other.getPageSize());
        }
        if (!other.getPageToken().isEmpty()) {
          pageToken_ = other.pageToken_;
          onChanged();
        }
        if (!other.getFilter().isEmpty()) {
          filter_ = other.filter_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the cluster to list Spark jobs of.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the cluster to list Spark jobs of.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the cluster to list Spark jobs of.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the cluster to list Spark jobs of.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the cluster to list Spark jobs of.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private long pageSize_ ;
      /**
       * <pre>
       * The maximum number of results per page that should be returned. If the number of available
       * results is larger than `page_size`, the service returns a `next_page_token` that can be used
       * to get the next page of results in subsequent ListJobs requests.
       * Acceptable values are 0 to 1000, inclusive. Default value: 100.
       * </pre>
       *
       * <code>int64 page_size = 2 [(.yandex.cloud.value) = "&lt;=1000"];</code>
       * @return The pageSize.
       */
      @java.lang.Override
      public long getPageSize() {
        return pageSize_;
      }
      /**
       * <pre>
       * The maximum number of results per page that should be returned. If the number of available
       * results is larger than `page_size`, the service returns a `next_page_token` that can be used
       * to get the next page of results in subsequent ListJobs requests.
       * Acceptable values are 0 to 1000, inclusive. Default value: 100.
       * </pre>
       *
       * <code>int64 page_size = 2 [(.yandex.cloud.value) = "&lt;=1000"];</code>
       * @param value The pageSize to set.
       * @return This builder for chaining.
       */
      public Builder setPageSize(long value) {
        
        pageSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum number of results per page that should be returned. If the number of available
       * results is larger than `page_size`, the service returns a `next_page_token` that can be used
       * to get the next page of results in subsequent ListJobs requests.
       * Acceptable values are 0 to 1000, inclusive. Default value: 100.
       * </pre>
       *
       * <code>int64 page_size = 2 [(.yandex.cloud.value) = "&lt;=1000"];</code>
       * @return This builder for chaining.
       */
      public Builder clearPageSize() {
        
        pageSize_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object pageToken_ = "";
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The pageToken.
       */
      public java.lang.String getPageToken() {
        java.lang.Object ref = pageToken_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          pageToken_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The bytes for pageToken.
       */
      public com.google.protobuf.ByteString
          getPageTokenBytes() {
        java.lang.Object ref = pageToken_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          pageToken_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The pageToken to set.
       * @return This builder for chaining.
       */
      public Builder setPageToken(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        pageToken_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return This builder for chaining.
       */
      public Builder clearPageToken() {
        
        pageToken_ = getDefaultInstance().getPageToken();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListJobs
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 3 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The bytes for pageToken to set.
       * @return This builder for chaining.
       */
      public Builder setPageTokenBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        pageToken_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object filter_ = "";
      /**
       * <pre>
       * String that describes a display filter.
       * </pre>
       *
       * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
       * @return The filter.
       */
      public java.lang.String getFilter() {
        java.lang.Object ref = filter_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          filter_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * String that describes a display filter.
       * </pre>
       *
       * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
       * @return The bytes for filter.
       */
      public com.google.protobuf.ByteString
          getFilterBytes() {
        java.lang.Object ref = filter_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          filter_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * String that describes a display filter.
       * </pre>
       *
       * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
       * @param value The filter to set.
       * @return This builder for chaining.
       */
      public Builder setFilter(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        filter_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * String that describes a display filter.
       * </pre>
       *
       * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
       * @return This builder for chaining.
       */
      public Builder clearFilter() {
        
        filter_ = getDefaultInstance().getFilter();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * String that describes a display filter.
       * </pre>
       *
       * <code>string filter = 4 [(.yandex.cloud.length) = "&lt;=1000"];</code>
       * @param value The bytes for filter to set.
       * @return This builder for chaining.
       */
      public Builder setFilterBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        filter_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ListJobsRequest)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ListJobsRequest)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ListJobsRequest>
        PARSER = new com.google.protobuf.AbstractParser<ListJobsRequest>() {
      @java.lang.Override
      public ListJobsRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListJobsRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListJobsRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListJobsRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListJobsResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ListJobsResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job> 
        getJobsList();
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.Job getJobs(int index);
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    int getJobsCount();
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder> 
        getJobsOrBuilderList();
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder getJobsOrBuilder(
        int index);

    /**
     * <pre>
     * This token allows you to get the next page of results for ListJobs requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The nextPageToken.
     */
    java.lang.String getNextPageToken();
    /**
     * <pre>
     * This token allows you to get the next page of results for ListJobs requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for nextPageToken.
     */
    com.google.protobuf.ByteString
        getNextPageTokenBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ListJobsResponse}
   */
  public static final class ListJobsResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ListJobsResponse)
      ListJobsResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListJobsResponse.newBuilder() to construct.
    private ListJobsResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListJobsResponse() {
      jobs_ = java.util.Collections.emptyList();
      nextPageToken_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListJobsResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListJobsResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                jobs_ = new java.util.ArrayList<yandex.cloud.api.spark.v1.JobOuterClass.Job>();
                mutable_bitField0_ |= 0x00000001;
              }
              jobs_.add(
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.Job.parser(), extensionRegistry));
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              nextPageToken_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          jobs_ = java.util.Collections.unmodifiableList(jobs_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.Builder.class);
    }

    public static final int JOBS_FIELD_NUMBER = 1;
    private java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job> jobs_;
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    @java.lang.Override
    public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job> getJobsList() {
      return jobs_;
    }
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    @java.lang.Override
    public java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder> 
        getJobsOrBuilderList() {
      return jobs_;
    }
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    @java.lang.Override
    public int getJobsCount() {
      return jobs_.size();
    }
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.Job getJobs(int index) {
      return jobs_.get(index);
    }
    /**
     * <pre>
     * Requested list of Spark jobs.
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder getJobsOrBuilder(
        int index) {
      return jobs_.get(index);
    }

    public static final int NEXT_PAGE_TOKEN_FIELD_NUMBER = 2;
    private volatile java.lang.Object nextPageToken_;
    /**
     * <pre>
     * This token allows you to get the next page of results for ListJobs requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The nextPageToken.
     */
    @java.lang.Override
    public java.lang.String getNextPageToken() {
      java.lang.Object ref = nextPageToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        nextPageToken_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * This token allows you to get the next page of results for ListJobs requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for nextPageToken.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNextPageTokenBytes() {
      java.lang.Object ref = nextPageToken_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nextPageToken_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < jobs_.size(); i++) {
        output.writeMessage(1, jobs_.get(i));
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(nextPageToken_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, nextPageToken_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < jobs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, jobs_.get(i));
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(nextPageToken_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, nextPageToken_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse) obj;

      if (!getJobsList()
          .equals(other.getJobsList())) return false;
      if (!getNextPageToken()
          .equals(other.getNextPageToken())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getJobsCount() > 0) {
        hash = (37 * hash) + JOBS_FIELD_NUMBER;
        hash = (53 * hash) + getJobsList().hashCode();
      }
      hash = (37 * hash) + NEXT_PAGE_TOKEN_FIELD_NUMBER;
      hash = (53 * hash) + getNextPageToken().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ListJobsResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ListJobsResponse)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getJobsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        if (jobsBuilder_ == null) {
          jobs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          jobsBuilder_.clear();
        }
        nextPageToken_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse(this);
        int from_bitField0_ = bitField0_;
        if (jobsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            jobs_ = java.util.Collections.unmodifiableList(jobs_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.jobs_ = jobs_;
        } else {
          result.jobs_ = jobsBuilder_.build();
        }
        result.nextPageToken_ = nextPageToken_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse.getDefaultInstance()) return this;
        if (jobsBuilder_ == null) {
          if (!other.jobs_.isEmpty()) {
            if (jobs_.isEmpty()) {
              jobs_ = other.jobs_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureJobsIsMutable();
              jobs_.addAll(other.jobs_);
            }
            onChanged();
          }
        } else {
          if (!other.jobs_.isEmpty()) {
            if (jobsBuilder_.isEmpty()) {
              jobsBuilder_.dispose();
              jobsBuilder_ = null;
              jobs_ = other.jobs_;
              bitField0_ = (bitField0_ & ~0x00000001);
              jobsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getJobsFieldBuilder() : null;
            } else {
              jobsBuilder_.addAllMessages(other.jobs_);
            }
          }
        }
        if (!other.getNextPageToken().isEmpty()) {
          nextPageToken_ = other.nextPageToken_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job> jobs_ =
        java.util.Collections.emptyList();
      private void ensureJobsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          jobs_ = new java.util.ArrayList<yandex.cloud.api.spark.v1.JobOuterClass.Job>(jobs_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.Job, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder, yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder> jobsBuilder_;

      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job> getJobsList() {
        if (jobsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(jobs_);
        } else {
          return jobsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public int getJobsCount() {
        if (jobsBuilder_ == null) {
          return jobs_.size();
        } else {
          return jobsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.Job getJobs(int index) {
        if (jobsBuilder_ == null) {
          return jobs_.get(index);
        } else {
          return jobsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder setJobs(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.Job value) {
        if (jobsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureJobsIsMutable();
          jobs_.set(index, value);
          onChanged();
        } else {
          jobsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder setJobs(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder builderForValue) {
        if (jobsBuilder_ == null) {
          ensureJobsIsMutable();
          jobs_.set(index, builderForValue.build());
          onChanged();
        } else {
          jobsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder addJobs(yandex.cloud.api.spark.v1.JobOuterClass.Job value) {
        if (jobsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureJobsIsMutable();
          jobs_.add(value);
          onChanged();
        } else {
          jobsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder addJobs(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.Job value) {
        if (jobsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureJobsIsMutable();
          jobs_.add(index, value);
          onChanged();
        } else {
          jobsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder addJobs(
          yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder builderForValue) {
        if (jobsBuilder_ == null) {
          ensureJobsIsMutable();
          jobs_.add(builderForValue.build());
          onChanged();
        } else {
          jobsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder addJobs(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder builderForValue) {
        if (jobsBuilder_ == null) {
          ensureJobsIsMutable();
          jobs_.add(index, builderForValue.build());
          onChanged();
        } else {
          jobsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder addAllJobs(
          java.lang.Iterable<? extends yandex.cloud.api.spark.v1.JobOuterClass.Job> values) {
        if (jobsBuilder_ == null) {
          ensureJobsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, jobs_);
          onChanged();
        } else {
          jobsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder clearJobs() {
        if (jobsBuilder_ == null) {
          jobs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          jobsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public Builder removeJobs(int index) {
        if (jobsBuilder_ == null) {
          ensureJobsIsMutable();
          jobs_.remove(index);
          onChanged();
        } else {
          jobsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder getJobsBuilder(
          int index) {
        return getJobsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder getJobsOrBuilder(
          int index) {
        if (jobsBuilder_ == null) {
          return jobs_.get(index);  } else {
          return jobsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder> 
           getJobsOrBuilderList() {
        if (jobsBuilder_ != null) {
          return jobsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(jobs_);
        }
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder addJobsBuilder() {
        return getJobsFieldBuilder().addBuilder(
            yandex.cloud.api.spark.v1.JobOuterClass.Job.getDefaultInstance());
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder addJobsBuilder(
          int index) {
        return getJobsFieldBuilder().addBuilder(
            index, yandex.cloud.api.spark.v1.JobOuterClass.Job.getDefaultInstance());
      }
      /**
       * <pre>
       * Requested list of Spark jobs.
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.Job jobs = 1;</code>
       */
      public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder> 
           getJobsBuilderList() {
        return getJobsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.Job, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder, yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder> 
          getJobsFieldBuilder() {
        if (jobsBuilder_ == null) {
          jobsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.Job, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder, yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder>(
                  jobs_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          jobs_ = null;
        }
        return jobsBuilder_;
      }

      private java.lang.Object nextPageToken_ = "";
      /**
       * <pre>
       * This token allows you to get the next page of results for ListJobs requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The nextPageToken.
       */
      public java.lang.String getNextPageToken() {
        java.lang.Object ref = nextPageToken_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          nextPageToken_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListJobs requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The bytes for nextPageToken.
       */
      public com.google.protobuf.ByteString
          getNextPageTokenBytes() {
        java.lang.Object ref = nextPageToken_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nextPageToken_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListJobs requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The nextPageToken to set.
       * @return This builder for chaining.
       */
      public Builder setNextPageToken(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        nextPageToken_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListJobs requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return This builder for chaining.
       */
      public Builder clearNextPageToken() {
        
        nextPageToken_ = getDefaultInstance().getNextPageToken();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListJobs requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListClusters request. Subsequent ListClusters
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The bytes for nextPageToken to set.
       * @return This builder for chaining.
       */
      public Builder setNextPageTokenBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        nextPageToken_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ListJobsResponse)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ListJobsResponse)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ListJobsResponse>
        PARSER = new com.google.protobuf.AbstractParser<ListJobsResponse>() {
      @java.lang.Override
      public ListJobsResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListJobsResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListJobsResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListJobsResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobsResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CreateJobRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.CreateJobRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the cluster to create Spark job in.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the cluster to create Spark job in.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * Optional. Name of the job.
     * </pre>
     *
     * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Optional. Name of the job.
     * </pre>
     *
     * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     * @return Whether the sparkJob field is set.
     */
    boolean hasSparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     * @return The sparkJob.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder();

    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     * @return Whether the pysparkJob field is set.
     */
    boolean hasPysparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     * @return The pysparkJob.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder();

    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     * @return Whether the sparkConnectJob field is set.
     */
    boolean hasSparkConnectJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     * @return The sparkConnectJob.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob getSparkConnectJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder getSparkConnectJobOrBuilder();

    /**
     * <pre>
     * Service account used to access Cloud resources.
     * </pre>
     *
     * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The serviceAccountId.
     */
    java.lang.String getServiceAccountId();
    /**
     * <pre>
     * Service account used to access Cloud resources.
     * </pre>
     *
     * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for serviceAccountId.
     */
    com.google.protobuf.ByteString
        getServiceAccountIdBytes();

    public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.JobSpecCase getJobSpecCase();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.CreateJobRequest}
   */
  public static final class CreateJobRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.CreateJobRequest)
      CreateJobRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateJobRequest.newBuilder() to construct.
    private CreateJobRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateJobRequest() {
      clusterId_ = "";
      name_ = "";
      serviceAccountId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateJobRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateJobRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 26: {
              yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder subBuilder = null;
              if (jobSpecCase_ == 3) {
                subBuilder = ((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_).toBuilder();
              }
              jobSpec_ =
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
                jobSpec_ = subBuilder.buildPartial();
              }
              jobSpecCase_ = 3;
              break;
            }
            case 34: {
              yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder subBuilder = null;
              if (jobSpecCase_ == 4) {
                subBuilder = ((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_).toBuilder();
              }
              jobSpec_ =
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
                jobSpec_ = subBuilder.buildPartial();
              }
              jobSpecCase_ = 4;
              break;
            }
            case 42: {
              yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder subBuilder = null;
              if (jobSpecCase_ == 5) {
                subBuilder = ((yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_).toBuilder();
              }
              jobSpec_ =
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_);
                jobSpec_ = subBuilder.buildPartial();
              }
              jobSpecCase_ = 5;
              break;
            }
            case 66: {
              java.lang.String s = input.readStringRequireUtf8();

              serviceAccountId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.Builder.class);
    }

    private int jobSpecCase_ = 0;
    private java.lang.Object jobSpec_;
    public enum JobSpecCase
        implements com.google.protobuf.Internal.EnumLite,
            com.google.protobuf.AbstractMessage.InternalOneOfEnum {
      SPARK_JOB(3),
      PYSPARK_JOB(4),
      SPARK_CONNECT_JOB(5),
      JOBSPEC_NOT_SET(0);
      private final int value;
      private JobSpecCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static JobSpecCase valueOf(int value) {
        return forNumber(value);
      }

      public static JobSpecCase forNumber(int value) {
        switch (value) {
          case 3: return SPARK_JOB;
          case 4: return PYSPARK_JOB;
          case 5: return SPARK_CONNECT_JOB;
          case 0: return JOBSPEC_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public JobSpecCase
    getJobSpecCase() {
      return JobSpecCase.forNumber(
          jobSpecCase_);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the cluster to create Spark job in.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the cluster to create Spark job in.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NAME_FIELD_NUMBER = 2;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Optional. Name of the job.
     * </pre>
     *
     * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Optional. Name of the job.
     * </pre>
     *
     * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int SPARK_JOB_FIELD_NUMBER = 3;
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     * @return Whether the sparkJob field is set.
     */
    @java.lang.Override
    public boolean hasSparkJob() {
      return jobSpecCase_ == 3;
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     * @return The sparkJob.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob() {
      if (jobSpecCase_ == 3) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder() {
      if (jobSpecCase_ == 3) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
    }

    public static final int PYSPARK_JOB_FIELD_NUMBER = 4;
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     * @return Whether the pysparkJob field is set.
     */
    @java.lang.Override
    public boolean hasPysparkJob() {
      return jobSpecCase_ == 4;
    }
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     * @return The pysparkJob.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob() {
      if (jobSpecCase_ == 4) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder() {
      if (jobSpecCase_ == 4) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
    }

    public static final int SPARK_CONNECT_JOB_FIELD_NUMBER = 5;
    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     * @return Whether the sparkConnectJob field is set.
     */
    @java.lang.Override
    public boolean hasSparkConnectJob() {
      return jobSpecCase_ == 5;
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     * @return The sparkConnectJob.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob getSparkConnectJob() {
      if (jobSpecCase_ == 5) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder getSparkConnectJobOrBuilder() {
      if (jobSpecCase_ == 5) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
    }

    public static final int SERVICE_ACCOUNT_ID_FIELD_NUMBER = 8;
    private volatile java.lang.Object serviceAccountId_;
    /**
     * <pre>
     * Service account used to access Cloud resources.
     * </pre>
     *
     * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The serviceAccountId.
     */
    @java.lang.Override
    public java.lang.String getServiceAccountId() {
      java.lang.Object ref = serviceAccountId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        serviceAccountId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Service account used to access Cloud resources.
     * </pre>
     *
     * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for serviceAccountId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getServiceAccountIdBytes() {
      java.lang.Object ref = serviceAccountId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        serviceAccountId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, name_);
      }
      if (jobSpecCase_ == 3) {
        output.writeMessage(3, (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 4) {
        output.writeMessage(4, (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 5) {
        output.writeMessage(5, (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(serviceAccountId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, serviceAccountId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, name_);
      }
      if (jobSpecCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 4) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 5) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(serviceAccountId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, serviceAccountId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getName()
          .equals(other.getName())) return false;
      if (!getServiceAccountId()
          .equals(other.getServiceAccountId())) return false;
      if (!getJobSpecCase().equals(other.getJobSpecCase())) return false;
      switch (jobSpecCase_) {
        case 3:
          if (!getSparkJob()
              .equals(other.getSparkJob())) return false;
          break;
        case 4:
          if (!getPysparkJob()
              .equals(other.getPysparkJob())) return false;
          break;
        case 5:
          if (!getSparkConnectJob()
              .equals(other.getSparkConnectJob())) return false;
          break;
        case 0:
        default:
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + SERVICE_ACCOUNT_ID_FIELD_NUMBER;
      hash = (53 * hash) + getServiceAccountId().hashCode();
      switch (jobSpecCase_) {
        case 3:
          hash = (37 * hash) + SPARK_JOB_FIELD_NUMBER;
          hash = (53 * hash) + getSparkJob().hashCode();
          break;
        case 4:
          hash = (37 * hash) + PYSPARK_JOB_FIELD_NUMBER;
          hash = (53 * hash) + getPysparkJob().hashCode();
          break;
        case 5:
          hash = (37 * hash) + SPARK_CONNECT_JOB_FIELD_NUMBER;
          hash = (53 * hash) + getSparkConnectJob().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.CreateJobRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.CreateJobRequest)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        name_ = "";

        serviceAccountId_ = "";

        jobSpecCase_ = 0;
        jobSpec_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest(this);
        result.clusterId_ = clusterId_;
        result.name_ = name_;
        if (jobSpecCase_ == 3) {
          if (sparkJobBuilder_ == null) {
            result.jobSpec_ = jobSpec_;
          } else {
            result.jobSpec_ = sparkJobBuilder_.build();
          }
        }
        if (jobSpecCase_ == 4) {
          if (pysparkJobBuilder_ == null) {
            result.jobSpec_ = jobSpec_;
          } else {
            result.jobSpec_ = pysparkJobBuilder_.build();
          }
        }
        if (jobSpecCase_ == 5) {
          if (sparkConnectJobBuilder_ == null) {
            result.jobSpec_ = jobSpec_;
          } else {
            result.jobSpec_ = sparkConnectJobBuilder_.build();
          }
        }
        result.serviceAccountId_ = serviceAccountId_;
        result.jobSpecCase_ = jobSpecCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getServiceAccountId().isEmpty()) {
          serviceAccountId_ = other.serviceAccountId_;
          onChanged();
        }
        switch (other.getJobSpecCase()) {
          case SPARK_JOB: {
            mergeSparkJob(other.getSparkJob());
            break;
          }
          case PYSPARK_JOB: {
            mergePysparkJob(other.getPysparkJob());
            break;
          }
          case SPARK_CONNECT_JOB: {
            mergeSparkConnectJob(other.getSparkConnectJob());
            break;
          }
          case JOBSPEC_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int jobSpecCase_ = 0;
      private java.lang.Object jobSpec_;
      public JobSpecCase
          getJobSpecCase() {
        return JobSpecCase.forNumber(
            jobSpecCase_);
      }

      public Builder clearJobSpec() {
        jobSpecCase_ = 0;
        jobSpec_ = null;
        onChanged();
        return this;
      }


      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the cluster to create Spark job in.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the cluster to create Spark job in.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the cluster to create Spark job in.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the cluster to create Spark job in.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the cluster to create Spark job in.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Optional. Name of the job.
       * </pre>
       *
       * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Optional. Name of the job.
       * </pre>
       *
       * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Optional. Name of the job.
       * </pre>
       *
       * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Name of the job.
       * </pre>
       *
       * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional. Name of the job.
       * </pre>
       *
       * <code>string name = 2 [(.yandex.cloud.pattern) = "|[a-z][-a-z0-9]{1,61}[a-z0-9]"];</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder> sparkJobBuilder_;
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       * @return Whether the sparkJob field is set.
       */
      @java.lang.Override
      public boolean hasSparkJob() {
        return jobSpecCase_ == 3;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       * @return The sparkJob.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob() {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 3) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        } else {
          if (jobSpecCase_ == 3) {
            return sparkJobBuilder_.getMessage();
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      public Builder setSparkJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob value) {
        if (sparkJobBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jobSpec_ = value;
          onChanged();
        } else {
          sparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 3;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      public Builder setSparkJob(
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder builderForValue) {
        if (sparkJobBuilder_ == null) {
          jobSpec_ = builderForValue.build();
          onChanged();
        } else {
          sparkJobBuilder_.setMessage(builderForValue.build());
        }
        jobSpecCase_ = 3;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      public Builder mergeSparkJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob value) {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 3 &&
              jobSpec_ != yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance()) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.newBuilder((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_)
                .mergeFrom(value).buildPartial();
          } else {
            jobSpec_ = value;
          }
          onChanged();
        } else {
          if (jobSpecCase_ == 3) {
            sparkJobBuilder_.mergeFrom(value);
          }
          sparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 3;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      public Builder clearSparkJob() {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 3) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
            onChanged();
          }
        } else {
          if (jobSpecCase_ == 3) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
          }
          sparkJobBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder getSparkJobBuilder() {
        return getSparkJobFieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder() {
        if ((jobSpecCase_ == 3) && (sparkJobBuilder_ != null)) {
          return sparkJobBuilder_.getMessageOrBuilder();
        } else {
          if (jobSpecCase_ == 3) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder> 
          getSparkJobFieldBuilder() {
        if (sparkJobBuilder_ == null) {
          if (!(jobSpecCase_ == 3)) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
          }
          sparkJobBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder>(
                  (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_,
                  getParentForChildren(),
                  isClean());
          jobSpec_ = null;
        }
        jobSpecCase_ = 3;
        onChanged();;
        return sparkJobBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder> pysparkJobBuilder_;
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       * @return Whether the pysparkJob field is set.
       */
      @java.lang.Override
      public boolean hasPysparkJob() {
        return jobSpecCase_ == 4;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       * @return The pysparkJob.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob() {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 4) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        } else {
          if (jobSpecCase_ == 4) {
            return pysparkJobBuilder_.getMessage();
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      public Builder setPysparkJob(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob value) {
        if (pysparkJobBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jobSpec_ = value;
          onChanged();
        } else {
          pysparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      public Builder setPysparkJob(
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder builderForValue) {
        if (pysparkJobBuilder_ == null) {
          jobSpec_ = builderForValue.build();
          onChanged();
        } else {
          pysparkJobBuilder_.setMessage(builderForValue.build());
        }
        jobSpecCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      public Builder mergePysparkJob(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob value) {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 4 &&
              jobSpec_ != yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance()) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.newBuilder((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_)
                .mergeFrom(value).buildPartial();
          } else {
            jobSpec_ = value;
          }
          onChanged();
        } else {
          if (jobSpecCase_ == 4) {
            pysparkJobBuilder_.mergeFrom(value);
          }
          pysparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 4;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      public Builder clearPysparkJob() {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 4) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
            onChanged();
          }
        } else {
          if (jobSpecCase_ == 4) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
          }
          pysparkJobBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder getPysparkJobBuilder() {
        return getPysparkJobFieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder() {
        if ((jobSpecCase_ == 4) && (pysparkJobBuilder_ != null)) {
          return pysparkJobBuilder_.getMessageOrBuilder();
        } else {
          if (jobSpecCase_ == 4) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder> 
          getPysparkJobFieldBuilder() {
        if (pysparkJobBuilder_ == null) {
          if (!(jobSpecCase_ == 4)) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
          }
          pysparkJobBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder>(
                  (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_,
                  getParentForChildren(),
                  isClean());
          jobSpec_ = null;
        }
        jobSpecCase_ = 4;
        onChanged();;
        return pysparkJobBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder> sparkConnectJobBuilder_;
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       * @return Whether the sparkConnectJob field is set.
       */
      @java.lang.Override
      public boolean hasSparkConnectJob() {
        return jobSpecCase_ == 5;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       * @return The sparkConnectJob.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob getSparkConnectJob() {
        if (sparkConnectJobBuilder_ == null) {
          if (jobSpecCase_ == 5) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
        } else {
          if (jobSpecCase_ == 5) {
            return sparkConnectJobBuilder_.getMessage();
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      public Builder setSparkConnectJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob value) {
        if (sparkConnectJobBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jobSpec_ = value;
          onChanged();
        } else {
          sparkConnectJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      public Builder setSparkConnectJob(
          yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder builderForValue) {
        if (sparkConnectJobBuilder_ == null) {
          jobSpec_ = builderForValue.build();
          onChanged();
        } else {
          sparkConnectJobBuilder_.setMessage(builderForValue.build());
        }
        jobSpecCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      public Builder mergeSparkConnectJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob value) {
        if (sparkConnectJobBuilder_ == null) {
          if (jobSpecCase_ == 5 &&
              jobSpec_ != yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance()) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.newBuilder((yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_)
                .mergeFrom(value).buildPartial();
          } else {
            jobSpec_ = value;
          }
          onChanged();
        } else {
          if (jobSpecCase_ == 5) {
            sparkConnectJobBuilder_.mergeFrom(value);
          }
          sparkConnectJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 5;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      public Builder clearSparkConnectJob() {
        if (sparkConnectJobBuilder_ == null) {
          if (jobSpecCase_ == 5) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
            onChanged();
          }
        } else {
          if (jobSpecCase_ == 5) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
          }
          sparkConnectJobBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder getSparkConnectJobBuilder() {
        return getSparkConnectJobFieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder getSparkConnectJobOrBuilder() {
        if ((jobSpecCase_ == 5) && (sparkConnectJobBuilder_ != null)) {
          return sparkConnectJobBuilder_.getMessageOrBuilder();
        } else {
          if (jobSpecCase_ == 5) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkConnectJob spark_connect_job = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder> 
          getSparkConnectJobFieldBuilder() {
        if (sparkConnectJobBuilder_ == null) {
          if (!(jobSpecCase_ == 5)) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.getDefaultInstance();
          }
          sparkConnectJobBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJobOrBuilder>(
                  (yandex.cloud.api.spark.v1.JobOuterClass.SparkConnectJob) jobSpec_,
                  getParentForChildren(),
                  isClean());
          jobSpec_ = null;
        }
        jobSpecCase_ = 5;
        onChanged();;
        return sparkConnectJobBuilder_;
      }

      private java.lang.Object serviceAccountId_ = "";
      /**
       * <pre>
       * Service account used to access Cloud resources.
       * </pre>
       *
       * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The serviceAccountId.
       */
      public java.lang.String getServiceAccountId() {
        java.lang.Object ref = serviceAccountId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          serviceAccountId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Service account used to access Cloud resources.
       * </pre>
       *
       * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for serviceAccountId.
       */
      public com.google.protobuf.ByteString
          getServiceAccountIdBytes() {
        java.lang.Object ref = serviceAccountId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          serviceAccountId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Service account used to access Cloud resources.
       * </pre>
       *
       * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The serviceAccountId to set.
       * @return This builder for chaining.
       */
      public Builder setServiceAccountId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        serviceAccountId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Service account used to access Cloud resources.
       * </pre>
       *
       * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearServiceAccountId() {
        
        serviceAccountId_ = getDefaultInstance().getServiceAccountId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Service account used to access Cloud resources.
       * </pre>
       *
       * <code>string service_account_id = 8 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for serviceAccountId to set.
       * @return This builder for chaining.
       */
      public Builder setServiceAccountIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        serviceAccountId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.CreateJobRequest)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.CreateJobRequest)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<CreateJobRequest>
        PARSER = new com.google.protobuf.AbstractParser<CreateJobRequest>() {
      @java.lang.Override
      public CreateJobRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateJobRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CreateJobRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CreateJobRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CreateJobMetadataOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.CreateJobMetadata)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the Spark job.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    java.lang.String getJobId();
    /**
     * <pre>
     * ID of the Spark job.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    com.google.protobuf.ByteString
        getJobIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.CreateJobMetadata}
   */
  public static final class CreateJobMetadata extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.CreateJobMetadata)
      CreateJobMetadataOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CreateJobMetadata.newBuilder() to construct.
    private CreateJobMetadata(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CreateJobMetadata() {
      clusterId_ = "";
      jobId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CreateJobMetadata();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CreateJobMetadata(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              jobId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobMetadata_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.Builder.class);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int JOB_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object jobId_;
    /**
     * <pre>
     * ID of the Spark job.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    @java.lang.Override
    public java.lang.String getJobId() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        jobId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark job.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getJobIdBytes() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        jobId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jobId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, jobId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getJobId()
          .equals(other.getJobId())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + JOB_ID_FIELD_NUMBER;
      hash = (53 * hash) + getJobId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.CreateJobMetadata}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.CreateJobMetadata)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadataOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobMetadata_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        jobId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata(this);
        result.clusterId_ = clusterId_;
        result.jobId_ = jobId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getJobId().isEmpty()) {
          jobId_ = other.jobId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object jobId_ = "";
      /**
       * <pre>
       * ID of the Spark job.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The jobId.
       */
      public java.lang.String getJobId() {
        java.lang.Object ref = jobId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          jobId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for jobId.
       */
      public com.google.protobuf.ByteString
          getJobIdBytes() {
        java.lang.Object ref = jobId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          jobId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        jobId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearJobId() {
        
        jobId_ = getDefaultInstance().getJobId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        jobId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.CreateJobMetadata)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.CreateJobMetadata)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<CreateJobMetadata>
        PARSER = new com.google.protobuf.AbstractParser<CreateJobMetadata>() {
      @java.lang.Override
      public CreateJobMetadata parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CreateJobMetadata(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CreateJobMetadata> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CreateJobMetadata> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.CreateJobMetadata getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface CancelJobRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.CancelJobRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the Spark job to cancel.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    java.lang.String getJobId();
    /**
     * <pre>
     * ID of the Spark job to cancel.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    com.google.protobuf.ByteString
        getJobIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.CancelJobRequest}
   */
  public static final class CancelJobRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.CancelJobRequest)
      CancelJobRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CancelJobRequest.newBuilder() to construct.
    private CancelJobRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CancelJobRequest() {
      clusterId_ = "";
      jobId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CancelJobRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private CancelJobRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              jobId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CancelJobRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.Builder.class);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int JOB_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object jobId_;
    /**
     * <pre>
     * ID of the Spark job to cancel.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    @java.lang.Override
    public java.lang.String getJobId() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        jobId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark job to cancel.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getJobIdBytes() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        jobId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jobId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, jobId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getJobId()
          .equals(other.getJobId())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + JOB_ID_FIELD_NUMBER;
      hash = (53 * hash) + getJobId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.CancelJobRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.CancelJobRequest)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CancelJobRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        jobId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest(this);
        result.clusterId_ = clusterId_;
        result.jobId_ = jobId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getJobId().isEmpty()) {
          jobId_ = other.jobId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object jobId_ = "";
      /**
       * <pre>
       * ID of the Spark job to cancel.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The jobId.
       */
      public java.lang.String getJobId() {
        java.lang.Object ref = jobId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          jobId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to cancel.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for jobId.
       */
      public com.google.protobuf.ByteString
          getJobIdBytes() {
        java.lang.Object ref = jobId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          jobId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to cancel.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        jobId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to cancel.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearJobId() {
        
        jobId_ = getDefaultInstance().getJobId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to cancel.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        jobId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.CancelJobRequest)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.CancelJobRequest)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<CancelJobRequest>
        PARSER = new com.google.protobuf.AbstractParser<CancelJobRequest>() {
      @java.lang.Override
      public CancelJobRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CancelJobRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<CancelJobRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CancelJobRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.CancelJobRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListJobLogRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ListJobLogRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    java.lang.String getJobId();
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    com.google.protobuf.ByteString
        getJobIdBytes();

    /**
     * <pre>
     * The maximum length of job output per papge that should be returned.
     * If the number of available output is larger tha `page_size`, the service returns
     * a `next_page_token` that can be used to get the next page of job output in subsequent ListLog requests.
     * Acceptable values are 0 to 1048576. Default value: 1048576.
     * </pre>
     *
     * <code>int64 page_size = 3 [(.yandex.cloud.value) = "&lt;=1048576"];</code>
     * @return The pageSize.
     */
    long getPageSize();

    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The pageToken.
     */
    java.lang.String getPageToken();
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for pageToken.
     */
    com.google.protobuf.ByteString
        getPageTokenBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ListJobLogRequest}
   */
  public static final class ListJobLogRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ListJobLogRequest)
      ListJobLogRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListJobLogRequest.newBuilder() to construct.
    private ListJobLogRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListJobLogRequest() {
      clusterId_ = "";
      jobId_ = "";
      pageToken_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListJobLogRequest();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListJobLogRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              jobId_ = s;
              break;
            }
            case 24: {

              pageSize_ = input.readInt64();
              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();

              pageToken_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.Builder.class);
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int JOB_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object jobId_;
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The jobId.
     */
    @java.lang.Override
    public java.lang.String getJobId() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        jobId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Spark job to return.
     * </pre>
     *
     * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
     * @return The bytes for jobId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getJobIdBytes() {
      java.lang.Object ref = jobId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        jobId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PAGE_SIZE_FIELD_NUMBER = 3;
    private long pageSize_;
    /**
     * <pre>
     * The maximum length of job output per papge that should be returned.
     * If the number of available output is larger tha `page_size`, the service returns
     * a `next_page_token` that can be used to get the next page of job output in subsequent ListLog requests.
     * Acceptable values are 0 to 1048576. Default value: 1048576.
     * </pre>
     *
     * <code>int64 page_size = 3 [(.yandex.cloud.value) = "&lt;=1048576"];</code>
     * @return The pageSize.
     */
    @java.lang.Override
    public long getPageSize() {
      return pageSize_;
    }

    public static final int PAGE_TOKEN_FIELD_NUMBER = 4;
    private volatile java.lang.Object pageToken_;
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The pageToken.
     */
    @java.lang.Override
    public java.lang.String getPageToken() {
      java.lang.Object ref = pageToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        pageToken_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
     * request to get the next page of results.
     * </pre>
     *
     * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for pageToken.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getPageTokenBytes() {
      java.lang.Object ref = pageToken_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        pageToken_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jobId_);
      }
      if (pageSize_ != 0L) {
        output.writeInt64(3, pageSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(pageToken_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, pageToken_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(jobId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, jobId_);
      }
      if (pageSize_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, pageSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(pageToken_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, pageToken_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest) obj;

      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getJobId()
          .equals(other.getJobId())) return false;
      if (getPageSize()
          != other.getPageSize()) return false;
      if (!getPageToken()
          .equals(other.getPageToken())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + JOB_ID_FIELD_NUMBER;
      hash = (53 * hash) + getJobId().hashCode();
      hash = (37 * hash) + PAGE_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getPageSize());
      hash = (37 * hash) + PAGE_TOKEN_FIELD_NUMBER;
      hash = (53 * hash) + getPageToken().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ListJobLogRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ListJobLogRequest)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        clusterId_ = "";

        jobId_ = "";

        pageSize_ = 0L;

        pageToken_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest(this);
        result.clusterId_ = clusterId_;
        result.jobId_ = jobId_;
        result.pageSize_ = pageSize_;
        result.pageToken_ = pageToken_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest.getDefaultInstance()) return this;
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getJobId().isEmpty()) {
          jobId_ = other.jobId_;
          onChanged();
        }
        if (other.getPageSize() != 0L) {
          setPageSize(other.getPageSize());
        }
        if (!other.getPageToken().isEmpty()) {
          pageToken_ = other.pageToken_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 1 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object jobId_ = "";
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The jobId.
       */
      public java.lang.String getJobId() {
        java.lang.Object ref = jobId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          jobId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return The bytes for jobId.
       */
      public com.google.protobuf.ByteString
          getJobIdBytes() {
        java.lang.Object ref = jobId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          jobId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        jobId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @return This builder for chaining.
       */
      public Builder clearJobId() {
        
        jobId_ = getDefaultInstance().getJobId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Spark job to return.
       * </pre>
       *
       * <code>string job_id = 2 [(.yandex.cloud.required) = true, (.yandex.cloud.length) = "&lt;=50"];</code>
       * @param value The bytes for jobId to set.
       * @return This builder for chaining.
       */
      public Builder setJobIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        jobId_ = value;
        onChanged();
        return this;
      }

      private long pageSize_ ;
      /**
       * <pre>
       * The maximum length of job output per papge that should be returned.
       * If the number of available output is larger tha `page_size`, the service returns
       * a `next_page_token` that can be used to get the next page of job output in subsequent ListLog requests.
       * Acceptable values are 0 to 1048576. Default value: 1048576.
       * </pre>
       *
       * <code>int64 page_size = 3 [(.yandex.cloud.value) = "&lt;=1048576"];</code>
       * @return The pageSize.
       */
      @java.lang.Override
      public long getPageSize() {
        return pageSize_;
      }
      /**
       * <pre>
       * The maximum length of job output per papge that should be returned.
       * If the number of available output is larger tha `page_size`, the service returns
       * a `next_page_token` that can be used to get the next page of job output in subsequent ListLog requests.
       * Acceptable values are 0 to 1048576. Default value: 1048576.
       * </pre>
       *
       * <code>int64 page_size = 3 [(.yandex.cloud.value) = "&lt;=1048576"];</code>
       * @param value The pageSize to set.
       * @return This builder for chaining.
       */
      public Builder setPageSize(long value) {
        
        pageSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The maximum length of job output per papge that should be returned.
       * If the number of available output is larger tha `page_size`, the service returns
       * a `next_page_token` that can be used to get the next page of job output in subsequent ListLog requests.
       * Acceptable values are 0 to 1048576. Default value: 1048576.
       * </pre>
       *
       * <code>int64 page_size = 3 [(.yandex.cloud.value) = "&lt;=1048576"];</code>
       * @return This builder for chaining.
       */
      public Builder clearPageSize() {
        
        pageSize_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object pageToken_ = "";
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The pageToken.
       */
      public java.lang.String getPageToken() {
        java.lang.Object ref = pageToken_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          pageToken_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The bytes for pageToken.
       */
      public com.google.protobuf.ByteString
          getPageTokenBytes() {
        java.lang.Object ref = pageToken_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          pageToken_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The pageToken to set.
       * @return This builder for chaining.
       */
      public Builder setPageToken(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        pageToken_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return This builder for chaining.
       */
      public Builder clearPageToken() {
        
        pageToken_ = getDefaultInstance().getPageToken();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Page token. Set `page_token` to the `next_page_token` returned by a previous ListLog
       * request to get the next page of results.
       * </pre>
       *
       * <code>string page_token = 4 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The bytes for pageToken to set.
       * @return This builder for chaining.
       */
      public Builder setPageTokenBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        pageToken_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ListJobLogRequest)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ListJobLogRequest)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ListJobLogRequest>
        PARSER = new com.google.protobuf.AbstractParser<ListJobLogRequest>() {
      @java.lang.Override
      public ListJobLogRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListJobLogRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListJobLogRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListJobLogRequest> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ListJobLogResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ListJobLogResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Requested part of Spark Job log.
     * </pre>
     *
     * <code>string content = 1;</code>
     * @return The content.
     */
    java.lang.String getContent();
    /**
     * <pre>
     * Requested part of Spark Job log.
     * </pre>
     *
     * <code>string content = 1;</code>
     * @return The bytes for content.
     */
    com.google.protobuf.ByteString
        getContentBytes();

    /**
     * <pre>
     * This token allows you to get the next page of results for ListLog requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListLog request. Subsequent ListLog
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The nextPageToken.
     */
    java.lang.String getNextPageToken();
    /**
     * <pre>
     * This token allows you to get the next page of results for ListLog requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListLog request. Subsequent ListLog
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for nextPageToken.
     */
    com.google.protobuf.ByteString
        getNextPageTokenBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ListJobLogResponse}
   */
  public static final class ListJobLogResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ListJobLogResponse)
      ListJobLogResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ListJobLogResponse.newBuilder() to construct.
    private ListJobLogResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ListJobLogResponse() {
      content_ = "";
      nextPageToken_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ListJobLogResponse();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ListJobLogResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              content_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              nextPageToken_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.Builder.class);
    }

    public static final int CONTENT_FIELD_NUMBER = 1;
    private volatile java.lang.Object content_;
    /**
     * <pre>
     * Requested part of Spark Job log.
     * </pre>
     *
     * <code>string content = 1;</code>
     * @return The content.
     */
    @java.lang.Override
    public java.lang.String getContent() {
      java.lang.Object ref = content_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        content_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Requested part of Spark Job log.
     * </pre>
     *
     * <code>string content = 1;</code>
     * @return The bytes for content.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getContentBytes() {
      java.lang.Object ref = content_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        content_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NEXT_PAGE_TOKEN_FIELD_NUMBER = 2;
    private volatile java.lang.Object nextPageToken_;
    /**
     * <pre>
     * This token allows you to get the next page of results for ListLog requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListLog request. Subsequent ListLog
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The nextPageToken.
     */
    @java.lang.Override
    public java.lang.String getNextPageToken() {
      java.lang.Object ref = nextPageToken_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        nextPageToken_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * This token allows you to get the next page of results for ListLog requests,
     * if the number of results is larger than `page_size` specified in the request.
     * To get the next page, specify the value of `next_page_token` as a value for
     * the `page_token` parameter in the next ListLog request. Subsequent ListLog
     * requests will have their own `next_page_token` to continue paging through the results.
     * </pre>
     *
     * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
     * @return The bytes for nextPageToken.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNextPageTokenBytes() {
      java.lang.Object ref = nextPageToken_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nextPageToken_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(content_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, content_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(nextPageToken_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, nextPageToken_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(content_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, content_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(nextPageToken_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, nextPageToken_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse other = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse) obj;

      if (!getContent()
          .equals(other.getContent())) return false;
      if (!getNextPageToken()
          .equals(other.getNextPageToken())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + CONTENT_FIELD_NUMBER;
      hash = (53 * hash) + getContent().hashCode();
      hash = (37 * hash) + NEXT_PAGE_TOKEN_FIELD_NUMBER;
      hash = (53 * hash) + getNextPageToken().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ListJobLogResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ListJobLogResponse)
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.class, yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        content_ = "";

        nextPageToken_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse build() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse buildPartial() {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse result = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse(this);
        result.content_ = content_;
        result.nextPageToken_ = nextPageToken_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse other) {
        if (other == yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse.getDefaultInstance()) return this;
        if (!other.getContent().isEmpty()) {
          content_ = other.content_;
          onChanged();
        }
        if (!other.getNextPageToken().isEmpty()) {
          nextPageToken_ = other.nextPageToken_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object content_ = "";
      /**
       * <pre>
       * Requested part of Spark Job log.
       * </pre>
       *
       * <code>string content = 1;</code>
       * @return The content.
       */
      public java.lang.String getContent() {
        java.lang.Object ref = content_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          content_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Requested part of Spark Job log.
       * </pre>
       *
       * <code>string content = 1;</code>
       * @return The bytes for content.
       */
      public com.google.protobuf.ByteString
          getContentBytes() {
        java.lang.Object ref = content_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          content_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Requested part of Spark Job log.
       * </pre>
       *
       * <code>string content = 1;</code>
       * @param value The content to set.
       * @return This builder for chaining.
       */
      public Builder setContent(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        content_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Requested part of Spark Job log.
       * </pre>
       *
       * <code>string content = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearContent() {
        
        content_ = getDefaultInstance().getContent();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Requested part of Spark Job log.
       * </pre>
       *
       * <code>string content = 1;</code>
       * @param value The bytes for content to set.
       * @return This builder for chaining.
       */
      public Builder setContentBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        content_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object nextPageToken_ = "";
      /**
       * <pre>
       * This token allows you to get the next page of results for ListLog requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListLog request. Subsequent ListLog
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The nextPageToken.
       */
      public java.lang.String getNextPageToken() {
        java.lang.Object ref = nextPageToken_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          nextPageToken_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListLog requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListLog request. Subsequent ListLog
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return The bytes for nextPageToken.
       */
      public com.google.protobuf.ByteString
          getNextPageTokenBytes() {
        java.lang.Object ref = nextPageToken_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nextPageToken_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListLog requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListLog request. Subsequent ListLog
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The nextPageToken to set.
       * @return This builder for chaining.
       */
      public Builder setNextPageToken(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        nextPageToken_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListLog requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListLog request. Subsequent ListLog
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @return This builder for chaining.
       */
      public Builder clearNextPageToken() {
        
        nextPageToken_ = getDefaultInstance().getNextPageToken();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This token allows you to get the next page of results for ListLog requests,
       * if the number of results is larger than `page_size` specified in the request.
       * To get the next page, specify the value of `next_page_token` as a value for
       * the `page_token` parameter in the next ListLog request. Subsequent ListLog
       * requests will have their own `next_page_token` to continue paging through the results.
       * </pre>
       *
       * <code>string next_page_token = 2 [(.yandex.cloud.length) = "&lt;=200"];</code>
       * @param value The bytes for nextPageToken to set.
       * @return This builder for chaining.
       */
      public Builder setNextPageTokenBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        nextPageToken_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ListJobLogResponse)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ListJobLogResponse)
    private static final yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse();
    }

    public static yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ListJobLogResponse>
        PARSER = new com.google.protobuf.AbstractParser<ListJobLogResponse>() {
      @java.lang.Override
      public ListJobLogResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ListJobLogResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ListJobLogResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ListJobLogResponse> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobServiceOuterClass.ListJobLogResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_GetJobRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ListJobsRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ListJobsResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_CreateJobRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_CreateJobMetadata_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_CancelJobRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ListJobLogRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ListJobLogResponse_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\'yandex/cloud/spark/v1/job_service.prot" +
      "o\022\025yandex.cloud.spark.v1\032\037yandex/cloud/s" +
      "park/v1/job.proto\032&yandex/cloud/operatio" +
      "n/operation.proto\032\035yandex/cloud/validati" +
      "on.proto\032 yandex/cloud/api/operation.pro" +
      "to\"O\n\rGetJobRequest\022 \n\ncluster_id\030\001 \001(\tB" +
      "\014\350\3071\001\212\3101\004<=50\022\034\n\006job_id\030\002 \001(\tB\014\350\3071\001\212\3101\004<" +
      "=50\"\215\001\n\017ListJobsRequest\022 \n\ncluster_id\030\001 " +
      "\001(\tB\014\350\3071\001\212\3101\004<=50\022\035\n\tpage_size\030\002 \001(\003B\n\372\307" +
      "1\006<=1000\022\035\n\npage_token\030\003 \001(\tB\t\212\3101\005<=200\022" +
      "\032\n\006filter\030\004 \001(\tB\n\212\3101\006<=1000\"`\n\020ListJobsR" +
      "esponse\022(\n\004jobs\030\001 \003(\0132\032.yandex.cloud.spa" +
      "rk.v1.Job\022\"\n\017next_page_token\030\002 \001(\tB\t\212\3101\005" +
      "<=200\"\330\002\n\020CreateJobRequest\022 \n\ncluster_id" +
      "\030\001 \001(\tB\014\350\3071\001\212\3101\004<=50\022/\n\004name\030\002 \001(\tB!\362\3071\035" +
      "|[a-z][-a-z0-9]{1,61}[a-z0-9]\0224\n\tspark_j" +
      "ob\030\003 \001(\0132\037.yandex.cloud.spark.v1.SparkJo" +
      "bH\000\0228\n\013pyspark_job\030\004 \001(\0132!.yandex.cloud." +
      "spark.v1.PysparkJobH\000\022C\n\021spark_connect_j" +
      "ob\030\005 \001(\0132&.yandex.cloud.spark.v1.SparkCo" +
      "nnectJobH\000\022$\n\022service_account_id\030\010 \001(\tB\010" +
      "\212\3101\004<=50B\n\n\010job_specJ\004\010\006\020\007J\004\010\007\020\010\"O\n\021Crea" +
      "teJobMetadata\022 \n\ncluster_id\030\001 \001(\tB\014\350\3071\001\212" +
      "\3101\004<=50\022\030\n\006job_id\030\002 \001(\tB\010\212\3101\004<=50\"R\n\020Can" +
      "celJobRequest\022 \n\ncluster_id\030\001 \001(\tB\014\350\3071\001\212" +
      "\3101\004<=50\022\034\n\006job_id\030\002 \001(\tB\014\350\3071\001\212\3101\004<=50\"\224\001" +
      "\n\021ListJobLogRequest\022 \n\ncluster_id\030\001 \001(\tB" +
      "\014\350\3071\001\212\3101\004<=50\022\034\n\006job_id\030\002 \001(\tB\014\350\3071\001\212\3101\004<" +
      "=50\022 \n\tpage_size\030\003 \001(\003B\r\372\3071\t<=1048576\022\035\n" +
      "\npage_token\030\004 \001(\tB\t\212\3101\005<=200\"I\n\022ListJobL" +
      "ogResponse\022\017\n\007content\030\001 \001(\t\022\"\n\017next_page" +
      "_token\030\002 \001(\tB\t\212\3101\005<=2002\374\003\n\nJobService\022Y" +
      "\n\004List\022&.yandex.cloud.spark.v1.ListJobsR" +
      "equest\032\'.yandex.cloud.spark.v1.ListJobsR" +
      "esponse\"\000\022r\n\006Create\022\'.yandex.cloud.spark" +
      ".v1.CreateJobRequest\032!.yandex.cloud.oper" +
      "ation.Operation\"\034\262\322*\030\n\021CreateJobMetadata" +
      "\022\003Job\022I\n\003Get\022$.yandex.cloud.spark.v1.Get" +
      "JobRequest\032\032.yandex.cloud.spark.v1.Job\"\000" +
      "\022`\n\007ListLog\022(.yandex.cloud.spark.v1.List" +
      "JobLogRequest\032).yandex.cloud.spark.v1.Li" +
      "stJobLogResponse\"\000\022r\n\006Cancel\022\'.yandex.cl" +
      "oud.spark.v1.CancelJobRequest\032!.yandex.c" +
      "loud.operation.Operation\"\034\262\322*\030\n\021CreateJo" +
      "bMetadata\022\003JobB\\\n\031yandex.cloud.api.spark" +
      ".v1Z?github.com/yandex-cloud/go-genproto" +
      "/yandex/cloud/spark/v1;sparkb\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          yandex.cloud.api.spark.v1.JobOuterClass.getDescriptor(),
          yandex.cloud.api.operation.OperationOuterClass.getDescriptor(),
          yandex.cloud.api.Validation.getDescriptor(),
          yandex.cloud.api.OperationOuterClass.getDescriptor(),
        });
    internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_yandex_cloud_spark_v1_GetJobRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_GetJobRequest_descriptor,
        new java.lang.String[] { "ClusterId", "JobId", });
    internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_yandex_cloud_spark_v1_ListJobsRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ListJobsRequest_descriptor,
        new java.lang.String[] { "ClusterId", "PageSize", "PageToken", "Filter", });
    internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_yandex_cloud_spark_v1_ListJobsResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ListJobsResponse_descriptor,
        new java.lang.String[] { "Jobs", "NextPageToken", });
    internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_yandex_cloud_spark_v1_CreateJobRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_CreateJobRequest_descriptor,
        new java.lang.String[] { "ClusterId", "Name", "SparkJob", "PysparkJob", "SparkConnectJob", "ServiceAccountId", "JobSpec", });
    internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_yandex_cloud_spark_v1_CreateJobMetadata_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_CreateJobMetadata_descriptor,
        new java.lang.String[] { "ClusterId", "JobId", });
    internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_yandex_cloud_spark_v1_CancelJobRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_CancelJobRequest_descriptor,
        new java.lang.String[] { "ClusterId", "JobId", });
    internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_yandex_cloud_spark_v1_ListJobLogRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ListJobLogRequest_descriptor,
        new java.lang.String[] { "ClusterId", "JobId", "PageSize", "PageToken", });
    internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_yandex_cloud_spark_v1_ListJobLogResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ListJobLogResponse_descriptor,
        new java.lang.String[] { "Content", "NextPageToken", });
    com.google.protobuf.ExtensionRegistry registry =
        com.google.protobuf.ExtensionRegistry.newInstance();
    registry.add(yandex.cloud.api.OperationOuterClass.operation);
    registry.add(yandex.cloud.api.Validation.length);
    registry.add(yandex.cloud.api.Validation.pattern);
    registry.add(yandex.cloud.api.Validation.required);
    registry.add(yandex.cloud.api.Validation.value);
    com.google.protobuf.Descriptors.FileDescriptor
        .internalUpdateFileDescriptor(descriptor, registry);
    yandex.cloud.api.spark.v1.JobOuterClass.getDescriptor();
    yandex.cloud.api.operation.OperationOuterClass.getDescriptor();
    yandex.cloud.api.Validation.getDescriptor();
    yandex.cloud.api.OperationOuterClass.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
