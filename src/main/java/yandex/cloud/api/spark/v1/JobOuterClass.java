// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yandex/cloud/spark/v1/job.proto

package yandex.cloud.api.spark.v1;

public final class JobOuterClass {
  private JobOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface JobOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.Job)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Required. Unique ID of the Spark job.
     * This ID is assigned by MDB in the process of creating Spark job.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    java.lang.String getId();
    /**
     * <pre>
     * Required. Unique ID of the Spark job.
     * This ID is assigned by MDB in the process of creating Spark job.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     * Required. Unique ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * Required. Unique ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return Whether the createdAt field is set.
     */
    boolean hasCreatedAt();
    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return The createdAt.
     */
    com.google.protobuf.Timestamp getCreatedAt();
    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder();

    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     * @return Whether the startedAt field is set.
     */
    boolean hasStartedAt();
    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     * @return The startedAt.
     */
    com.google.protobuf.Timestamp getStartedAt();
    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     */
    com.google.protobuf.TimestampOrBuilder getStartedAtOrBuilder();

    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     * @return Whether the finishedAt field is set.
     */
    boolean hasFinishedAt();
    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     * @return The finishedAt.
     */
    com.google.protobuf.Timestamp getFinishedAt();
    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     */
    com.google.protobuf.TimestampOrBuilder getFinishedAtOrBuilder();

    /**
     * <pre>
     * Name of the Spark job.
     * </pre>
     *
     * <code>string name = 6;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the Spark job.
     * </pre>
     *
     * <code>string name = 6;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * The id of the user who created the job
     * </pre>
     *
     * <code>string created_by = 7;</code>
     * @return The createdBy.
     */
    java.lang.String getCreatedBy();
    /**
     * <pre>
     * The id of the user who created the job
     * </pre>
     *
     * <code>string created_by = 7;</code>
     * @return The bytes for createdBy.
     */
    com.google.protobuf.ByteString
        getCreatedByBytes();

    /**
     * <pre>
     * Status.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
     * @return The enum numeric value on the wire for status.
     */
    int getStatusValue();
    /**
     * <pre>
     * Status.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
     * @return The status.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.Job.Status getStatus();

    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     * @return Whether the sparkJob field is set.
     */
    boolean hasSparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     * @return The sparkJob.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder();

    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     * @return Whether the pysparkJob field is set.
     */
    boolean hasPysparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     * @return The pysparkJob.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob();
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder();

    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     * @return Whether the applicationInfo field is set.
     */
    boolean hasApplicationInfo();
    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     * @return The applicationInfo.
     */
    yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getApplicationInfo();
    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder getApplicationInfoOrBuilder();

    /**
     * <pre>
     * Spark UI Url.
     * </pre>
     *
     * <code>string ui_url = 12;</code>
     * @return The uiUrl.
     */
    java.lang.String getUiUrl();
    /**
     * <pre>
     * Spark UI Url.
     * </pre>
     *
     * <code>string ui_url = 12;</code>
     * @return The bytes for uiUrl.
     */
    com.google.protobuf.ByteString
        getUiUrlBytes();

    public yandex.cloud.api.spark.v1.JobOuterClass.Job.JobSpecCase getJobSpecCase();
  }
  /**
   * <pre>
   * Spark job.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.spark.v1.Job}
   */
  public static final class Job extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.Job)
      JobOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Job.newBuilder() to construct.
    private Job(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Job() {
      id_ = "";
      clusterId_ = "";
      name_ = "";
      createdBy_ = "";
      status_ = 0;
      uiUrl_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Job();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Job(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 26: {
              com.google.protobuf.Timestamp.Builder subBuilder = null;
              if (createdAt_ != null) {
                subBuilder = createdAt_.toBuilder();
              }
              createdAt_ = input.readMessage(com.google.protobuf.Timestamp.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(createdAt_);
                createdAt_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Timestamp.Builder subBuilder = null;
              if (startedAt_ != null) {
                subBuilder = startedAt_.toBuilder();
              }
              startedAt_ = input.readMessage(com.google.protobuf.Timestamp.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(startedAt_);
                startedAt_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Timestamp.Builder subBuilder = null;
              if (finishedAt_ != null) {
                subBuilder = finishedAt_.toBuilder();
              }
              finishedAt_ = input.readMessage(com.google.protobuf.Timestamp.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(finishedAt_);
                finishedAt_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 58: {
              java.lang.String s = input.readStringRequireUtf8();

              createdBy_ = s;
              break;
            }
            case 64: {
              int rawValue = input.readEnum();

              status_ = rawValue;
              break;
            }
            case 74: {
              yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder subBuilder = null;
              if (jobSpecCase_ == 9) {
                subBuilder = ((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_).toBuilder();
              }
              jobSpec_ =
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
                jobSpec_ = subBuilder.buildPartial();
              }
              jobSpecCase_ = 9;
              break;
            }
            case 82: {
              yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder subBuilder = null;
              if (jobSpecCase_ == 10) {
                subBuilder = ((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_).toBuilder();
              }
              jobSpec_ =
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
                jobSpec_ = subBuilder.buildPartial();
              }
              jobSpecCase_ = 10;
              break;
            }
            case 90: {
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder subBuilder = null;
              if (applicationInfo_ != null) {
                subBuilder = applicationInfo_.toBuilder();
              }
              applicationInfo_ = input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationInfo_);
                applicationInfo_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              java.lang.String s = input.readStringRequireUtf8();

              uiUrl_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_Job_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_Job_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobOuterClass.Job.class, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.spark.v1.Job.Status}
     */
    public enum Status
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>STATUS_UNSPECIFIED = 0;</code>
       */
      STATUS_UNSPECIFIED(0),
      /**
       * <pre>
       * Job created and is waiting to acquire.
       * </pre>
       *
       * <code>PROVISIONING = 1;</code>
       */
      PROVISIONING(1),
      /**
       * <pre>
       * Job acquired and is waiting for execution.
       * </pre>
       *
       * <code>PENDING = 2;</code>
       */
      PENDING(2),
      /**
       * <pre>
       * Job is running.
       * </pre>
       *
       * <code>RUNNING = 3;</code>
       */
      RUNNING(3),
      /**
       * <pre>
       * Job failed.
       * </pre>
       *
       * <code>ERROR = 4;</code>
       */
      ERROR(4),
      /**
       * <pre>
       * Job finished.
       * </pre>
       *
       * <code>DONE = 5;</code>
       */
      DONE(5),
      /**
       * <pre>
       * Job cancelled.
       * </pre>
       *
       * <code>CANCELLED = 6;</code>
       */
      CANCELLED(6),
      /**
       * <pre>
       * Job is waiting for cancellation.
       * </pre>
       *
       * <code>CANCELLING = 7;</code>
       */
      CANCELLING(7),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>STATUS_UNSPECIFIED = 0;</code>
       */
      public static final int STATUS_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * Job created and is waiting to acquire.
       * </pre>
       *
       * <code>PROVISIONING = 1;</code>
       */
      public static final int PROVISIONING_VALUE = 1;
      /**
       * <pre>
       * Job acquired and is waiting for execution.
       * </pre>
       *
       * <code>PENDING = 2;</code>
       */
      public static final int PENDING_VALUE = 2;
      /**
       * <pre>
       * Job is running.
       * </pre>
       *
       * <code>RUNNING = 3;</code>
       */
      public static final int RUNNING_VALUE = 3;
      /**
       * <pre>
       * Job failed.
       * </pre>
       *
       * <code>ERROR = 4;</code>
       */
      public static final int ERROR_VALUE = 4;
      /**
       * <pre>
       * Job finished.
       * </pre>
       *
       * <code>DONE = 5;</code>
       */
      public static final int DONE_VALUE = 5;
      /**
       * <pre>
       * Job cancelled.
       * </pre>
       *
       * <code>CANCELLED = 6;</code>
       */
      public static final int CANCELLED_VALUE = 6;
      /**
       * <pre>
       * Job is waiting for cancellation.
       * </pre>
       *
       * <code>CANCELLING = 7;</code>
       */
      public static final int CANCELLING_VALUE = 7;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Status valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Status forNumber(int value) {
        switch (value) {
          case 0: return STATUS_UNSPECIFIED;
          case 1: return PROVISIONING;
          case 2: return PENDING;
          case 3: return RUNNING;
          case 4: return ERROR;
          case 5: return DONE;
          case 6: return CANCELLED;
          case 7: return CANCELLING;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Status>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Status> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Status>() {
              public Status findValueByNumber(int number) {
                return Status.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.Job.getDescriptor().getEnumTypes().get(0);
      }

      private static final Status[] VALUES = values();

      public static Status valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Status(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.spark.v1.Job.Status)
    }

    private int jobSpecCase_ = 0;
    private java.lang.Object jobSpec_;
    public enum JobSpecCase
        implements com.google.protobuf.Internal.EnumLite,
            com.google.protobuf.AbstractMessage.InternalOneOfEnum {
      SPARK_JOB(9),
      PYSPARK_JOB(10),
      JOBSPEC_NOT_SET(0);
      private final int value;
      private JobSpecCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static JobSpecCase valueOf(int value) {
        return forNumber(value);
      }

      public static JobSpecCase forNumber(int value) {
        switch (value) {
          case 9: return SPARK_JOB;
          case 10: return PYSPARK_JOB;
          case 0: return JOBSPEC_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public JobSpecCase
    getJobSpecCase() {
      return JobSpecCase.forNumber(
          jobSpecCase_);
    }

    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     * Required. Unique ID of the Spark job.
     * This ID is assigned by MDB in the process of creating Spark job.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    @java.lang.Override
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. Unique ID of the Spark job.
     * This ID is assigned by MDB in the process of creating Spark job.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * Required. Unique ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. Unique ID of the Spark cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CREATED_AT_FIELD_NUMBER = 3;
    private com.google.protobuf.Timestamp createdAt_;
    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return Whether the createdAt field is set.
     */
    @java.lang.Override
    public boolean hasCreatedAt() {
      return createdAt_ != null;
    }
    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return The createdAt.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getCreatedAt() {
      return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
    }
    /**
     * <pre>
     * The time when the Spark job was created.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
      return getCreatedAt();
    }

    public static final int STARTED_AT_FIELD_NUMBER = 4;
    private com.google.protobuf.Timestamp startedAt_;
    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     * @return Whether the startedAt field is set.
     */
    @java.lang.Override
    public boolean hasStartedAt() {
      return startedAt_ != null;
    }
    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     * @return The startedAt.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getStartedAt() {
      return startedAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : startedAt_;
    }
    /**
     * <pre>
     * The time when the Spark job was started.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp started_at = 4;</code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getStartedAtOrBuilder() {
      return getStartedAt();
    }

    public static final int FINISHED_AT_FIELD_NUMBER = 5;
    private com.google.protobuf.Timestamp finishedAt_;
    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     * @return Whether the finishedAt field is set.
     */
    @java.lang.Override
    public boolean hasFinishedAt() {
      return finishedAt_ != null;
    }
    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     * @return The finishedAt.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getFinishedAt() {
      return finishedAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : finishedAt_;
    }
    /**
     * <pre>
     * The time when the Spark job was finished.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp finished_at = 5;</code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getFinishedAtOrBuilder() {
      return getFinishedAt();
    }

    public static final int NAME_FIELD_NUMBER = 6;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the Spark job.
     * </pre>
     *
     * <code>string name = 6;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the Spark job.
     * </pre>
     *
     * <code>string name = 6;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CREATED_BY_FIELD_NUMBER = 7;
    private volatile java.lang.Object createdBy_;
    /**
     * <pre>
     * The id of the user who created the job
     * </pre>
     *
     * <code>string created_by = 7;</code>
     * @return The createdBy.
     */
    @java.lang.Override
    public java.lang.String getCreatedBy() {
      java.lang.Object ref = createdBy_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        createdBy_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * The id of the user who created the job
     * </pre>
     *
     * <code>string created_by = 7;</code>
     * @return The bytes for createdBy.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getCreatedByBytes() {
      java.lang.Object ref = createdBy_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        createdBy_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int STATUS_FIELD_NUMBER = 8;
    private int status_;
    /**
     * <pre>
     * Status.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
     * @return The enum numeric value on the wire for status.
     */
    @java.lang.Override public int getStatusValue() {
      return status_;
    }
    /**
     * <pre>
     * Status.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
     * @return The status.
     */
    @java.lang.Override public yandex.cloud.api.spark.v1.JobOuterClass.Job.Status getStatus() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.spark.v1.JobOuterClass.Job.Status result = yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.valueOf(status_);
      return result == null ? yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.UNRECOGNIZED : result;
    }

    public static final int SPARK_JOB_FIELD_NUMBER = 9;
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     * @return Whether the sparkJob field is set.
     */
    @java.lang.Override
    public boolean hasSparkJob() {
      return jobSpecCase_ == 9;
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     * @return The sparkJob.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob() {
      if (jobSpecCase_ == 9) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder() {
      if (jobSpecCase_ == 9) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
    }

    public static final int PYSPARK_JOB_FIELD_NUMBER = 10;
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     * @return Whether the pysparkJob field is set.
     */
    @java.lang.Override
    public boolean hasPysparkJob() {
      return jobSpecCase_ == 10;
    }
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     * @return The pysparkJob.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob() {
      if (jobSpecCase_ == 10) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
    }
    /**
     * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder() {
      if (jobSpecCase_ == 10) {
         return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
      }
      return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
    }

    public static final int APPLICATION_INFO_FIELD_NUMBER = 11;
    private yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo applicationInfo_;
    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     * @return Whether the applicationInfo field is set.
     */
    @java.lang.Override
    public boolean hasApplicationInfo() {
      return applicationInfo_ != null;
    }
    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     * @return The applicationInfo.
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getApplicationInfo() {
      return applicationInfo_ == null ? yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.getDefaultInstance() : applicationInfo_;
    }
    /**
     * <pre>
     * Attributes of application.
     * </pre>
     *
     * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder getApplicationInfoOrBuilder() {
      return getApplicationInfo();
    }

    public static final int UI_URL_FIELD_NUMBER = 12;
    private volatile java.lang.Object uiUrl_;
    /**
     * <pre>
     * Spark UI Url.
     * </pre>
     *
     * <code>string ui_url = 12;</code>
     * @return The uiUrl.
     */
    @java.lang.Override
    public java.lang.String getUiUrl() {
      java.lang.Object ref = uiUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        uiUrl_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Spark UI Url.
     * </pre>
     *
     * <code>string ui_url = 12;</code>
     * @return The bytes for uiUrl.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getUiUrlBytes() {
      java.lang.Object ref = uiUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        uiUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, clusterId_);
      }
      if (createdAt_ != null) {
        output.writeMessage(3, getCreatedAt());
      }
      if (startedAt_ != null) {
        output.writeMessage(4, getStartedAt());
      }
      if (finishedAt_ != null) {
        output.writeMessage(5, getFinishedAt());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(createdBy_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 7, createdBy_);
      }
      if (status_ != yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.STATUS_UNSPECIFIED.getNumber()) {
        output.writeEnum(8, status_);
      }
      if (jobSpecCase_ == 9) {
        output.writeMessage(9, (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 10) {
        output.writeMessage(10, (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
      }
      if (applicationInfo_ != null) {
        output.writeMessage(11, getApplicationInfo());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(uiUrl_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 12, uiUrl_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, clusterId_);
      }
      if (createdAt_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCreatedAt());
      }
      if (startedAt_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getStartedAt());
      }
      if (finishedAt_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getFinishedAt());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(createdBy_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(7, createdBy_);
      }
      if (status_ != yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.STATUS_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(8, status_);
      }
      if (jobSpecCase_ == 9) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_);
      }
      if (jobSpecCase_ == 10) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_);
      }
      if (applicationInfo_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getApplicationInfo());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(uiUrl_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(12, uiUrl_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobOuterClass.Job)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobOuterClass.Job other = (yandex.cloud.api.spark.v1.JobOuterClass.Job) obj;

      if (!getId()
          .equals(other.getId())) return false;
      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (hasCreatedAt() != other.hasCreatedAt()) return false;
      if (hasCreatedAt()) {
        if (!getCreatedAt()
            .equals(other.getCreatedAt())) return false;
      }
      if (hasStartedAt() != other.hasStartedAt()) return false;
      if (hasStartedAt()) {
        if (!getStartedAt()
            .equals(other.getStartedAt())) return false;
      }
      if (hasFinishedAt() != other.hasFinishedAt()) return false;
      if (hasFinishedAt()) {
        if (!getFinishedAt()
            .equals(other.getFinishedAt())) return false;
      }
      if (!getName()
          .equals(other.getName())) return false;
      if (!getCreatedBy()
          .equals(other.getCreatedBy())) return false;
      if (status_ != other.status_) return false;
      if (hasApplicationInfo() != other.hasApplicationInfo()) return false;
      if (hasApplicationInfo()) {
        if (!getApplicationInfo()
            .equals(other.getApplicationInfo())) return false;
      }
      if (!getUiUrl()
          .equals(other.getUiUrl())) return false;
      if (!getJobSpecCase().equals(other.getJobSpecCase())) return false;
      switch (jobSpecCase_) {
        case 9:
          if (!getSparkJob()
              .equals(other.getSparkJob())) return false;
          break;
        case 10:
          if (!getPysparkJob()
              .equals(other.getPysparkJob())) return false;
          break;
        case 0:
        default:
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      if (hasCreatedAt()) {
        hash = (37 * hash) + CREATED_AT_FIELD_NUMBER;
        hash = (53 * hash) + getCreatedAt().hashCode();
      }
      if (hasStartedAt()) {
        hash = (37 * hash) + STARTED_AT_FIELD_NUMBER;
        hash = (53 * hash) + getStartedAt().hashCode();
      }
      if (hasFinishedAt()) {
        hash = (37 * hash) + FINISHED_AT_FIELD_NUMBER;
        hash = (53 * hash) + getFinishedAt().hashCode();
      }
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + CREATED_BY_FIELD_NUMBER;
      hash = (53 * hash) + getCreatedBy().hashCode();
      hash = (37 * hash) + STATUS_FIELD_NUMBER;
      hash = (53 * hash) + status_;
      if (hasApplicationInfo()) {
        hash = (37 * hash) + APPLICATION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationInfo().hashCode();
      }
      hash = (37 * hash) + UI_URL_FIELD_NUMBER;
      hash = (53 * hash) + getUiUrl().hashCode();
      switch (jobSpecCase_) {
        case 9:
          hash = (37 * hash) + SPARK_JOB_FIELD_NUMBER;
          hash = (53 * hash) + getSparkJob().hashCode();
          break;
        case 10:
          hash = (37 * hash) + PYSPARK_JOB_FIELD_NUMBER;
          hash = (53 * hash) + getPysparkJob().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.Job parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobOuterClass.Job prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Spark job.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.spark.v1.Job}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.Job)
        yandex.cloud.api.spark.v1.JobOuterClass.JobOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_Job_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_Job_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobOuterClass.Job.class, yandex.cloud.api.spark.v1.JobOuterClass.Job.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobOuterClass.Job.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        clusterId_ = "";

        if (createdAtBuilder_ == null) {
          createdAt_ = null;
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }
        if (startedAtBuilder_ == null) {
          startedAt_ = null;
        } else {
          startedAt_ = null;
          startedAtBuilder_ = null;
        }
        if (finishedAtBuilder_ == null) {
          finishedAt_ = null;
        } else {
          finishedAt_ = null;
          finishedAtBuilder_ = null;
        }
        name_ = "";

        createdBy_ = "";

        status_ = 0;

        if (applicationInfoBuilder_ == null) {
          applicationInfo_ = null;
        } else {
          applicationInfo_ = null;
          applicationInfoBuilder_ = null;
        }
        uiUrl_ = "";

        jobSpecCase_ = 0;
        jobSpec_ = null;
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_Job_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.Job getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.Job.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.Job build() {
        yandex.cloud.api.spark.v1.JobOuterClass.Job result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.Job buildPartial() {
        yandex.cloud.api.spark.v1.JobOuterClass.Job result = new yandex.cloud.api.spark.v1.JobOuterClass.Job(this);
        result.id_ = id_;
        result.clusterId_ = clusterId_;
        if (createdAtBuilder_ == null) {
          result.createdAt_ = createdAt_;
        } else {
          result.createdAt_ = createdAtBuilder_.build();
        }
        if (startedAtBuilder_ == null) {
          result.startedAt_ = startedAt_;
        } else {
          result.startedAt_ = startedAtBuilder_.build();
        }
        if (finishedAtBuilder_ == null) {
          result.finishedAt_ = finishedAt_;
        } else {
          result.finishedAt_ = finishedAtBuilder_.build();
        }
        result.name_ = name_;
        result.createdBy_ = createdBy_;
        result.status_ = status_;
        if (jobSpecCase_ == 9) {
          if (sparkJobBuilder_ == null) {
            result.jobSpec_ = jobSpec_;
          } else {
            result.jobSpec_ = sparkJobBuilder_.build();
          }
        }
        if (jobSpecCase_ == 10) {
          if (pysparkJobBuilder_ == null) {
            result.jobSpec_ = jobSpec_;
          } else {
            result.jobSpec_ = pysparkJobBuilder_.build();
          }
        }
        if (applicationInfoBuilder_ == null) {
          result.applicationInfo_ = applicationInfo_;
        } else {
          result.applicationInfo_ = applicationInfoBuilder_.build();
        }
        result.uiUrl_ = uiUrl_;
        result.jobSpecCase_ = jobSpecCase_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobOuterClass.Job) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.Job)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobOuterClass.Job other) {
        if (other == yandex.cloud.api.spark.v1.JobOuterClass.Job.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (other.hasCreatedAt()) {
          mergeCreatedAt(other.getCreatedAt());
        }
        if (other.hasStartedAt()) {
          mergeStartedAt(other.getStartedAt());
        }
        if (other.hasFinishedAt()) {
          mergeFinishedAt(other.getFinishedAt());
        }
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getCreatedBy().isEmpty()) {
          createdBy_ = other.createdBy_;
          onChanged();
        }
        if (other.status_ != 0) {
          setStatusValue(other.getStatusValue());
        }
        if (other.hasApplicationInfo()) {
          mergeApplicationInfo(other.getApplicationInfo());
        }
        if (!other.getUiUrl().isEmpty()) {
          uiUrl_ = other.uiUrl_;
          onChanged();
        }
        switch (other.getJobSpecCase()) {
          case SPARK_JOB: {
            mergeSparkJob(other.getSparkJob());
            break;
          }
          case PYSPARK_JOB: {
            mergePysparkJob(other.getPysparkJob());
            break;
          }
          case JOBSPEC_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobOuterClass.Job parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobOuterClass.Job) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int jobSpecCase_ = 0;
      private java.lang.Object jobSpec_;
      public JobSpecCase
          getJobSpecCase() {
        return JobSpecCase.forNumber(
            jobSpecCase_);
      }

      public Builder clearJobSpec() {
        jobSpecCase_ = 0;
        jobSpec_ = null;
        onChanged();
        return this;
      }


      private java.lang.Object id_ = "";
      /**
       * <pre>
       * Required. Unique ID of the Spark job.
       * This ID is assigned by MDB in the process of creating Spark job.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The id.
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark job.
       * This ID is assigned by MDB in the process of creating Spark job.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The bytes for id.
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark job.
       * This ID is assigned by MDB in the process of creating Spark job.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The id to set.
       * @return This builder for chaining.
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark job.
       * This ID is assigned by MDB in the process of creating Spark job.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark job.
       * This ID is assigned by MDB in the process of creating Spark job.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The bytes for id to set.
       * @return This builder for chaining.
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * Required. Unique ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. Unique ID of the Spark cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp createdAt_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> createdAtBuilder_;
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       * @return Whether the createdAt field is set.
       */
      public boolean hasCreatedAt() {
        return createdAtBuilder_ != null || createdAt_ != null;
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       * @return The createdAt.
       */
      public com.google.protobuf.Timestamp getCreatedAt() {
        if (createdAtBuilder_ == null) {
          return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        } else {
          return createdAtBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          createdAt_ = value;
          onChanged();
        } else {
          createdAtBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(
          com.google.protobuf.Timestamp.Builder builderForValue) {
        if (createdAtBuilder_ == null) {
          createdAt_ = builderForValue.build();
          onChanged();
        } else {
          createdAtBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder mergeCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (createdAt_ != null) {
            createdAt_ =
              com.google.protobuf.Timestamp.newBuilder(createdAt_).mergeFrom(value).buildPartial();
          } else {
            createdAt_ = value;
          }
          onChanged();
        } else {
          createdAtBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder clearCreatedAt() {
        if (createdAtBuilder_ == null) {
          createdAt_ = null;
          onChanged();
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.Timestamp.Builder getCreatedAtBuilder() {
        
        onChanged();
        return getCreatedAtFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
        if (createdAtBuilder_ != null) {
          return createdAtBuilder_.getMessageOrBuilder();
        } else {
          return createdAt_ == null ?
              com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        }
      }
      /**
       * <pre>
       * The time when the Spark job was created.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> 
          getCreatedAtFieldBuilder() {
        if (createdAtBuilder_ == null) {
          createdAtBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(
                  getCreatedAt(),
                  getParentForChildren(),
                  isClean());
          createdAt_ = null;
        }
        return createdAtBuilder_;
      }

      private com.google.protobuf.Timestamp startedAt_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> startedAtBuilder_;
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       * @return Whether the startedAt field is set.
       */
      public boolean hasStartedAt() {
        return startedAtBuilder_ != null || startedAt_ != null;
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       * @return The startedAt.
       */
      public com.google.protobuf.Timestamp getStartedAt() {
        if (startedAtBuilder_ == null) {
          return startedAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : startedAt_;
        } else {
          return startedAtBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public Builder setStartedAt(com.google.protobuf.Timestamp value) {
        if (startedAtBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          startedAt_ = value;
          onChanged();
        } else {
          startedAtBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public Builder setStartedAt(
          com.google.protobuf.Timestamp.Builder builderForValue) {
        if (startedAtBuilder_ == null) {
          startedAt_ = builderForValue.build();
          onChanged();
        } else {
          startedAtBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public Builder mergeStartedAt(com.google.protobuf.Timestamp value) {
        if (startedAtBuilder_ == null) {
          if (startedAt_ != null) {
            startedAt_ =
              com.google.protobuf.Timestamp.newBuilder(startedAt_).mergeFrom(value).buildPartial();
          } else {
            startedAt_ = value;
          }
          onChanged();
        } else {
          startedAtBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public Builder clearStartedAt() {
        if (startedAtBuilder_ == null) {
          startedAt_ = null;
          onChanged();
        } else {
          startedAt_ = null;
          startedAtBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public com.google.protobuf.Timestamp.Builder getStartedAtBuilder() {
        
        onChanged();
        return getStartedAtFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      public com.google.protobuf.TimestampOrBuilder getStartedAtOrBuilder() {
        if (startedAtBuilder_ != null) {
          return startedAtBuilder_.getMessageOrBuilder();
        } else {
          return startedAt_ == null ?
              com.google.protobuf.Timestamp.getDefaultInstance() : startedAt_;
        }
      }
      /**
       * <pre>
       * The time when the Spark job was started.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp started_at = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> 
          getStartedAtFieldBuilder() {
        if (startedAtBuilder_ == null) {
          startedAtBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(
                  getStartedAt(),
                  getParentForChildren(),
                  isClean());
          startedAt_ = null;
        }
        return startedAtBuilder_;
      }

      private com.google.protobuf.Timestamp finishedAt_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> finishedAtBuilder_;
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       * @return Whether the finishedAt field is set.
       */
      public boolean hasFinishedAt() {
        return finishedAtBuilder_ != null || finishedAt_ != null;
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       * @return The finishedAt.
       */
      public com.google.protobuf.Timestamp getFinishedAt() {
        if (finishedAtBuilder_ == null) {
          return finishedAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : finishedAt_;
        } else {
          return finishedAtBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public Builder setFinishedAt(com.google.protobuf.Timestamp value) {
        if (finishedAtBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          finishedAt_ = value;
          onChanged();
        } else {
          finishedAtBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public Builder setFinishedAt(
          com.google.protobuf.Timestamp.Builder builderForValue) {
        if (finishedAtBuilder_ == null) {
          finishedAt_ = builderForValue.build();
          onChanged();
        } else {
          finishedAtBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public Builder mergeFinishedAt(com.google.protobuf.Timestamp value) {
        if (finishedAtBuilder_ == null) {
          if (finishedAt_ != null) {
            finishedAt_ =
              com.google.protobuf.Timestamp.newBuilder(finishedAt_).mergeFrom(value).buildPartial();
          } else {
            finishedAt_ = value;
          }
          onChanged();
        } else {
          finishedAtBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public Builder clearFinishedAt() {
        if (finishedAtBuilder_ == null) {
          finishedAt_ = null;
          onChanged();
        } else {
          finishedAt_ = null;
          finishedAtBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public com.google.protobuf.Timestamp.Builder getFinishedAtBuilder() {
        
        onChanged();
        return getFinishedAtFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      public com.google.protobuf.TimestampOrBuilder getFinishedAtOrBuilder() {
        if (finishedAtBuilder_ != null) {
          return finishedAtBuilder_.getMessageOrBuilder();
        } else {
          return finishedAt_ == null ?
              com.google.protobuf.Timestamp.getDefaultInstance() : finishedAt_;
        }
      }
      /**
       * <pre>
       * The time when the Spark job was finished.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp finished_at = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> 
          getFinishedAtFieldBuilder() {
        if (finishedAtBuilder_ == null) {
          finishedAtBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(
                  getFinishedAt(),
                  getParentForChildren(),
                  isClean());
          finishedAt_ = null;
        }
        return finishedAtBuilder_;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the Spark job.
       * </pre>
       *
       * <code>string name = 6;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the Spark job.
       * </pre>
       *
       * <code>string name = 6;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the Spark job.
       * </pre>
       *
       * <code>string name = 6;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Spark job.
       * </pre>
       *
       * <code>string name = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Spark job.
       * </pre>
       *
       * <code>string name = 6;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object createdBy_ = "";
      /**
       * <pre>
       * The id of the user who created the job
       * </pre>
       *
       * <code>string created_by = 7;</code>
       * @return The createdBy.
       */
      public java.lang.String getCreatedBy() {
        java.lang.Object ref = createdBy_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          createdBy_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The id of the user who created the job
       * </pre>
       *
       * <code>string created_by = 7;</code>
       * @return The bytes for createdBy.
       */
      public com.google.protobuf.ByteString
          getCreatedByBytes() {
        java.lang.Object ref = createdBy_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          createdBy_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The id of the user who created the job
       * </pre>
       *
       * <code>string created_by = 7;</code>
       * @param value The createdBy to set.
       * @return This builder for chaining.
       */
      public Builder setCreatedBy(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        createdBy_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The id of the user who created the job
       * </pre>
       *
       * <code>string created_by = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearCreatedBy() {
        
        createdBy_ = getDefaultInstance().getCreatedBy();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The id of the user who created the job
       * </pre>
       *
       * <code>string created_by = 7;</code>
       * @param value The bytes for createdBy to set.
       * @return This builder for chaining.
       */
      public Builder setCreatedByBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        createdBy_ = value;
        onChanged();
        return this;
      }

      private int status_ = 0;
      /**
       * <pre>
       * Status.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
       * @return The enum numeric value on the wire for status.
       */
      @java.lang.Override public int getStatusValue() {
        return status_;
      }
      /**
       * <pre>
       * Status.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
       * @param value The enum numeric value on the wire for status to set.
       * @return This builder for chaining.
       */
      public Builder setStatusValue(int value) {
        
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Status.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
       * @return The status.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.Job.Status getStatus() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.spark.v1.JobOuterClass.Job.Status result = yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.valueOf(status_);
        return result == null ? yandex.cloud.api.spark.v1.JobOuterClass.Job.Status.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Status.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(yandex.cloud.api.spark.v1.JobOuterClass.Job.Status value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        status_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Status.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.Job.Status status = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        
        status_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder> sparkJobBuilder_;
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       * @return Whether the sparkJob field is set.
       */
      @java.lang.Override
      public boolean hasSparkJob() {
        return jobSpecCase_ == 9;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       * @return The sparkJob.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getSparkJob() {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 9) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        } else {
          if (jobSpecCase_ == 9) {
            return sparkJobBuilder_.getMessage();
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      public Builder setSparkJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob value) {
        if (sparkJobBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jobSpec_ = value;
          onChanged();
        } else {
          sparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 9;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      public Builder setSparkJob(
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder builderForValue) {
        if (sparkJobBuilder_ == null) {
          jobSpec_ = builderForValue.build();
          onChanged();
        } else {
          sparkJobBuilder_.setMessage(builderForValue.build());
        }
        jobSpecCase_ = 9;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      public Builder mergeSparkJob(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob value) {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 9 &&
              jobSpec_ != yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance()) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.newBuilder((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_)
                .mergeFrom(value).buildPartial();
          } else {
            jobSpec_ = value;
          }
          onChanged();
        } else {
          if (jobSpecCase_ == 9) {
            sparkJobBuilder_.mergeFrom(value);
          }
          sparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 9;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      public Builder clearSparkJob() {
        if (sparkJobBuilder_ == null) {
          if (jobSpecCase_ == 9) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
            onChanged();
          }
        } else {
          if (jobSpecCase_ == 9) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
          }
          sparkJobBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder getSparkJobBuilder() {
        return getSparkJobFieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder getSparkJobOrBuilder() {
        if ((jobSpecCase_ == 9) && (sparkJobBuilder_ != null)) {
          return sparkJobBuilder_.getMessageOrBuilder();
        } else {
          if (jobSpecCase_ == 9) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.SparkJob spark_job = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder> 
          getSparkJobFieldBuilder() {
        if (sparkJobBuilder_ == null) {
          if (!(jobSpecCase_ == 9)) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
          }
          sparkJobBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.SparkJob, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder>(
                  (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) jobSpec_,
                  getParentForChildren(),
                  isClean());
          jobSpec_ = null;
        }
        jobSpecCase_ = 9;
        onChanged();;
        return sparkJobBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder> pysparkJobBuilder_;
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       * @return Whether the pysparkJob field is set.
       */
      @java.lang.Override
      public boolean hasPysparkJob() {
        return jobSpecCase_ == 10;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       * @return The pysparkJob.
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getPysparkJob() {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 10) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        } else {
          if (jobSpecCase_ == 10) {
            return pysparkJobBuilder_.getMessage();
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      public Builder setPysparkJob(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob value) {
        if (pysparkJobBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          jobSpec_ = value;
          onChanged();
        } else {
          pysparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 10;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      public Builder setPysparkJob(
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder builderForValue) {
        if (pysparkJobBuilder_ == null) {
          jobSpec_ = builderForValue.build();
          onChanged();
        } else {
          pysparkJobBuilder_.setMessage(builderForValue.build());
        }
        jobSpecCase_ = 10;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      public Builder mergePysparkJob(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob value) {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 10 &&
              jobSpec_ != yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance()) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.newBuilder((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_)
                .mergeFrom(value).buildPartial();
          } else {
            jobSpec_ = value;
          }
          onChanged();
        } else {
          if (jobSpecCase_ == 10) {
            pysparkJobBuilder_.mergeFrom(value);
          }
          pysparkJobBuilder_.setMessage(value);
        }
        jobSpecCase_ = 10;
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      public Builder clearPysparkJob() {
        if (pysparkJobBuilder_ == null) {
          if (jobSpecCase_ == 10) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
            onChanged();
          }
        } else {
          if (jobSpecCase_ == 10) {
            jobSpecCase_ = 0;
            jobSpec_ = null;
          }
          pysparkJobBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder getPysparkJobBuilder() {
        return getPysparkJobFieldBuilder().getBuilder();
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder getPysparkJobOrBuilder() {
        if ((jobSpecCase_ == 10) && (pysparkJobBuilder_ != null)) {
          return pysparkJobBuilder_.getMessageOrBuilder();
        } else {
          if (jobSpecCase_ == 10) {
            return (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_;
          }
          return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
        }
      }
      /**
       * <code>.yandex.cloud.spark.v1.PysparkJob pyspark_job = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder> 
          getPysparkJobFieldBuilder() {
        if (pysparkJobBuilder_ == null) {
          if (!(jobSpecCase_ == 10)) {
            jobSpec_ = yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
          }
          pysparkJobBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder>(
                  (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) jobSpec_,
                  getParentForChildren(),
                  isClean());
          jobSpec_ = null;
        }
        jobSpecCase_ = 10;
        onChanged();;
        return pysparkJobBuilder_;
      }

      private yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo applicationInfo_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder> applicationInfoBuilder_;
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       * @return Whether the applicationInfo field is set.
       */
      public boolean hasApplicationInfo() {
        return applicationInfoBuilder_ != null || applicationInfo_ != null;
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       * @return The applicationInfo.
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getApplicationInfo() {
        if (applicationInfoBuilder_ == null) {
          return applicationInfo_ == null ? yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.getDefaultInstance() : applicationInfo_;
        } else {
          return applicationInfoBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public Builder setApplicationInfo(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo value) {
        if (applicationInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationInfo_ = value;
          onChanged();
        } else {
          applicationInfoBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public Builder setApplicationInfo(
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder builderForValue) {
        if (applicationInfoBuilder_ == null) {
          applicationInfo_ = builderForValue.build();
          onChanged();
        } else {
          applicationInfoBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public Builder mergeApplicationInfo(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo value) {
        if (applicationInfoBuilder_ == null) {
          if (applicationInfo_ != null) {
            applicationInfo_ =
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.newBuilder(applicationInfo_).mergeFrom(value).buildPartial();
          } else {
            applicationInfo_ = value;
          }
          onChanged();
        } else {
          applicationInfoBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public Builder clearApplicationInfo() {
        if (applicationInfoBuilder_ == null) {
          applicationInfo_ = null;
          onChanged();
        } else {
          applicationInfo_ = null;
          applicationInfoBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder getApplicationInfoBuilder() {
        
        onChanged();
        return getApplicationInfoFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder getApplicationInfoOrBuilder() {
        if (applicationInfoBuilder_ != null) {
          return applicationInfoBuilder_.getMessageOrBuilder();
        } else {
          return applicationInfo_ == null ?
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.getDefaultInstance() : applicationInfo_;
        }
      }
      /**
       * <pre>
       * Attributes of application.
       * </pre>
       *
       * <code>.yandex.cloud.spark.v1.ApplicationInfo application_info = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder> 
          getApplicationInfoFieldBuilder() {
        if (applicationInfoBuilder_ == null) {
          applicationInfoBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder>(
                  getApplicationInfo(),
                  getParentForChildren(),
                  isClean());
          applicationInfo_ = null;
        }
        return applicationInfoBuilder_;
      }

      private java.lang.Object uiUrl_ = "";
      /**
       * <pre>
       * Spark UI Url.
       * </pre>
       *
       * <code>string ui_url = 12;</code>
       * @return The uiUrl.
       */
      public java.lang.String getUiUrl() {
        java.lang.Object ref = uiUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          uiUrl_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Spark UI Url.
       * </pre>
       *
       * <code>string ui_url = 12;</code>
       * @return The bytes for uiUrl.
       */
      public com.google.protobuf.ByteString
          getUiUrlBytes() {
        java.lang.Object ref = uiUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          uiUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Spark UI Url.
       * </pre>
       *
       * <code>string ui_url = 12;</code>
       * @param value The uiUrl to set.
       * @return This builder for chaining.
       */
      public Builder setUiUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        uiUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Spark UI Url.
       * </pre>
       *
       * <code>string ui_url = 12;</code>
       * @return This builder for chaining.
       */
      public Builder clearUiUrl() {
        
        uiUrl_ = getDefaultInstance().getUiUrl();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Spark UI Url.
       * </pre>
       *
       * <code>string ui_url = 12;</code>
       * @param value The bytes for uiUrl to set.
       * @return This builder for chaining.
       */
      public Builder setUiUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        uiUrl_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.Job)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.Job)
    private static final yandex.cloud.api.spark.v1.JobOuterClass.Job DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobOuterClass.Job();
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.Job getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Job>
        PARSER = new com.google.protobuf.AbstractParser<Job>() {
      @java.lang.Override
      public Job parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Job(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Job> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Job> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.Job getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationAttemptOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ApplicationAttempt)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of application attempt
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    java.lang.String getId();
    /**
     * <pre>
     * ID of application attempt
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     * ID of Application Master container
     * </pre>
     *
     * <code>string am_container_id = 2;</code>
     * @return The amContainerId.
     */
    java.lang.String getAmContainerId();
    /**
     * <pre>
     * ID of Application Master container
     * </pre>
     *
     * <code>string am_container_id = 2;</code>
     * @return The bytes for amContainerId.
     */
    com.google.protobuf.ByteString
        getAmContainerIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ApplicationAttempt}
   */
  public static final class ApplicationAttempt extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ApplicationAttempt)
      ApplicationAttemptOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationAttempt.newBuilder() to construct.
    private ApplicationAttempt(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationAttempt() {
      id_ = "";
      amContainerId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ApplicationAttempt();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttempt(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              amContainerId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationAttempt_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.class, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder.class);
    }

    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     * ID of application attempt
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    @java.lang.Override
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of application attempt
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int AM_CONTAINER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object amContainerId_;
    /**
     * <pre>
     * ID of Application Master container
     * </pre>
     *
     * <code>string am_container_id = 2;</code>
     * @return The amContainerId.
     */
    @java.lang.Override
    public java.lang.String getAmContainerId() {
      java.lang.Object ref = amContainerId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        amContainerId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of Application Master container
     * </pre>
     *
     * <code>string am_container_id = 2;</code>
     * @return The bytes for amContainerId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getAmContainerIdBytes() {
      java.lang.Object ref = amContainerId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        amContainerId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(amContainerId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, amContainerId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(amContainerId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, amContainerId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt other = (yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt) obj;

      if (!getId()
          .equals(other.getId())) return false;
      if (!getAmContainerId()
          .equals(other.getAmContainerId())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      hash = (37 * hash) + AM_CONTAINER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getAmContainerId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ApplicationAttempt}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ApplicationAttempt)
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationAttempt_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.class, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        amContainerId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt build() {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt buildPartial() {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt result = new yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt(this);
        result.id_ = id_;
        result.amContainerId_ = amContainerId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt other) {
        if (other == yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (!other.getAmContainerId().isEmpty()) {
          amContainerId_ = other.amContainerId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object id_ = "";
      /**
       * <pre>
       * ID of application attempt
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The id.
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of application attempt
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The bytes for id.
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of application attempt
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The id to set.
       * @return This builder for chaining.
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of application attempt
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of application attempt
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The bytes for id to set.
       * @return This builder for chaining.
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object amContainerId_ = "";
      /**
       * <pre>
       * ID of Application Master container
       * </pre>
       *
       * <code>string am_container_id = 2;</code>
       * @return The amContainerId.
       */
      public java.lang.String getAmContainerId() {
        java.lang.Object ref = amContainerId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          amContainerId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of Application Master container
       * </pre>
       *
       * <code>string am_container_id = 2;</code>
       * @return The bytes for amContainerId.
       */
      public com.google.protobuf.ByteString
          getAmContainerIdBytes() {
        java.lang.Object ref = amContainerId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          amContainerId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of Application Master container
       * </pre>
       *
       * <code>string am_container_id = 2;</code>
       * @param value The amContainerId to set.
       * @return This builder for chaining.
       */
      public Builder setAmContainerId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        amContainerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of Application Master container
       * </pre>
       *
       * <code>string am_container_id = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAmContainerId() {
        
        amContainerId_ = getDefaultInstance().getAmContainerId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of Application Master container
       * </pre>
       *
       * <code>string am_container_id = 2;</code>
       * @param value The bytes for amContainerId to set.
       * @return This builder for chaining.
       */
      public Builder setAmContainerIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        amContainerId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ApplicationAttempt)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ApplicationAttempt)
    private static final yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt();
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ApplicationAttempt>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationAttempt>() {
      @java.lang.Override
      public ApplicationAttempt parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationAttempt(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationAttempt> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttempt> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.ApplicationInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of application
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    java.lang.String getId();
    /**
     * <pre>
     * ID of application
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> 
        getApplicationAttemptsList();
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getApplicationAttempts(int index);
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    int getApplicationAttemptsCount();
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder> 
        getApplicationAttemptsOrBuilderList();
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder getApplicationAttemptsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.ApplicationInfo}
   */
  public static final class ApplicationInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.ApplicationInfo)
      ApplicationInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationInfo.newBuilder() to construct.
    private ApplicationInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationInfo() {
      id_ = "";
      applicationAttempts_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ApplicationInfo();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                applicationAttempts_ = new java.util.ArrayList<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt>();
                mutable_bitField0_ |= 0x00000001;
              }
              applicationAttempts_.add(
                  input.readMessage(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.parser(), extensionRegistry));
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          applicationAttempts_ = java.util.Collections.unmodifiableList(applicationAttempts_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.class, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder.class);
    }

    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     * ID of application
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    @java.lang.Override
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of application
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int APPLICATION_ATTEMPTS_FIELD_NUMBER = 2;
    private java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> applicationAttempts_;
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    @java.lang.Override
    public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> getApplicationAttemptsList() {
      return applicationAttempts_;
    }
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    @java.lang.Override
    public java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder> 
        getApplicationAttemptsOrBuilderList() {
      return applicationAttempts_;
    }
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    @java.lang.Override
    public int getApplicationAttemptsCount() {
      return applicationAttempts_.size();
    }
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getApplicationAttempts(int index) {
      return applicationAttempts_.get(index);
    }
    /**
     * <pre>
     * Application attempts
     * </pre>
     *
     * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder getApplicationAttemptsOrBuilder(
        int index) {
      return applicationAttempts_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      for (int i = 0; i < applicationAttempts_.size(); i++) {
        output.writeMessage(2, applicationAttempts_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      for (int i = 0; i < applicationAttempts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, applicationAttempts_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo other = (yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo) obj;

      if (!getId()
          .equals(other.getId())) return false;
      if (!getApplicationAttemptsList()
          .equals(other.getApplicationAttemptsList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      if (getApplicationAttemptsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.ApplicationInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.ApplicationInfo)
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.class, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptsFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        if (applicationAttemptsBuilder_ == null) {
          applicationAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          applicationAttemptsBuilder_.clear();
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo build() {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo buildPartial() {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo result = new yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo(this);
        int from_bitField0_ = bitField0_;
        result.id_ = id_;
        if (applicationAttemptsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            applicationAttempts_ = java.util.Collections.unmodifiableList(applicationAttempts_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.applicationAttempts_ = applicationAttempts_;
        } else {
          result.applicationAttempts_ = applicationAttemptsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo other) {
        if (other == yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (applicationAttemptsBuilder_ == null) {
          if (!other.applicationAttempts_.isEmpty()) {
            if (applicationAttempts_.isEmpty()) {
              applicationAttempts_ = other.applicationAttempts_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureApplicationAttemptsIsMutable();
              applicationAttempts_.addAll(other.applicationAttempts_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationAttempts_.isEmpty()) {
            if (applicationAttemptsBuilder_.isEmpty()) {
              applicationAttemptsBuilder_.dispose();
              applicationAttemptsBuilder_ = null;
              applicationAttempts_ = other.applicationAttempts_;
              bitField0_ = (bitField0_ & ~0x00000001);
              applicationAttemptsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationAttemptsFieldBuilder() : null;
            } else {
              applicationAttemptsBuilder_.addAllMessages(other.applicationAttempts_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object id_ = "";
      /**
       * <pre>
       * ID of application
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The id.
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of application
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The bytes for id.
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of application
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The id to set.
       * @return This builder for chaining.
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of application
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of application
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The bytes for id to set.
       * @return This builder for chaining.
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> applicationAttempts_ =
        java.util.Collections.emptyList();
      private void ensureApplicationAttemptsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          applicationAttempts_ = new java.util.ArrayList<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt>(applicationAttempts_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder> applicationAttemptsBuilder_;

      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> getApplicationAttemptsList() {
        if (applicationAttemptsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationAttempts_);
        } else {
          return applicationAttemptsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public int getApplicationAttemptsCount() {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.size();
        } else {
          return applicationAttemptsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt getApplicationAttempts(int index) {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.get(index);
        } else {
          return applicationAttemptsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder setApplicationAttempts(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.set(index, value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder setApplicationAttempts(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder addApplicationAttempts(yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder addApplicationAttempts(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt value) {
        if (applicationAttemptsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(index, value);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder addApplicationAttempts(
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder addApplicationAttempts(
          int index, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder builderForValue) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationAttemptsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder addAllApplicationAttempts(
          java.lang.Iterable<? extends yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt> values) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applicationAttempts_);
          onChanged();
        } else {
          applicationAttemptsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder clearApplicationAttempts() {
        if (applicationAttemptsBuilder_ == null) {
          applicationAttempts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          applicationAttemptsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public Builder removeApplicationAttempts(int index) {
        if (applicationAttemptsBuilder_ == null) {
          ensureApplicationAttemptsIsMutable();
          applicationAttempts_.remove(index);
          onChanged();
        } else {
          applicationAttemptsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder getApplicationAttemptsBuilder(
          int index) {
        return getApplicationAttemptsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder getApplicationAttemptsOrBuilder(
          int index) {
        if (applicationAttemptsBuilder_ == null) {
          return applicationAttempts_.get(index);  } else {
          return applicationAttemptsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public java.util.List<? extends yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder> 
           getApplicationAttemptsOrBuilderList() {
        if (applicationAttemptsBuilder_ != null) {
          return applicationAttemptsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationAttempts_);
        }
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder addApplicationAttemptsBuilder() {
        return getApplicationAttemptsFieldBuilder().addBuilder(
            yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.getDefaultInstance());
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder addApplicationAttemptsBuilder(
          int index) {
        return getApplicationAttemptsFieldBuilder().addBuilder(
            index, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.getDefaultInstance());
      }
      /**
       * <pre>
       * Application attempts
       * </pre>
       *
       * <code>repeated .yandex.cloud.spark.v1.ApplicationAttempt application_attempts = 2;</code>
       */
      public java.util.List<yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder> 
           getApplicationAttemptsBuilderList() {
        return getApplicationAttemptsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder> 
          getApplicationAttemptsFieldBuilder() {
        if (applicationAttemptsBuilder_ == null) {
          applicationAttemptsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttempt.Builder, yandex.cloud.api.spark.v1.JobOuterClass.ApplicationAttemptOrBuilder>(
                  applicationAttempts_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          applicationAttempts_ = null;
        }
        return applicationAttemptsBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.ApplicationInfo)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.ApplicationInfo)
    private static final yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo();
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ApplicationInfo>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationInfo>() {
      @java.lang.Override
      public ApplicationInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ApplicationInfo(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationInfo> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.ApplicationInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SparkJobOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.SparkJob)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return A list containing the args.
     */
    java.util.List<java.lang.String>
        getArgsList();
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return The count of args.
     */
    int getArgsCount();
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the element to return.
     * @return The args at the given index.
     */
    java.lang.String getArgs(int index);
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the args at the given index.
     */
    com.google.protobuf.ByteString
        getArgsBytes(int index);

    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return A list containing the jarFileUris.
     */
    java.util.List<java.lang.String>
        getJarFileUrisList();
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return The count of jarFileUris.
     */
    int getJarFileUrisCount();
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the element to return.
     * @return The jarFileUris at the given index.
     */
    java.lang.String getJarFileUris(int index);
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the jarFileUris at the given index.
     */
    com.google.protobuf.ByteString
        getJarFileUrisBytes(int index);

    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return A list containing the fileUris.
     */
    java.util.List<java.lang.String>
        getFileUrisList();
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return The count of fileUris.
     */
    int getFileUrisCount();
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the element to return.
     * @return The fileUris at the given index.
     */
    java.lang.String getFileUris(int index);
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the fileUris at the given index.
     */
    com.google.protobuf.ByteString
        getFileUrisBytes(int index);

    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return A list containing the archiveUris.
     */
    java.util.List<java.lang.String>
        getArchiveUrisList();
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return The count of archiveUris.
     */
    int getArchiveUrisCount();
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the element to return.
     * @return The archiveUris at the given index.
     */
    java.lang.String getArchiveUris(int index);
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the archiveUris at the given index.
     */
    com.google.protobuf.ByteString
        getArchiveUrisBytes(int index);

    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    int getPropertiesCount();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    boolean containsProperties(
        java.lang.String key);
    /**
     * Use {@link #getPropertiesMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, java.lang.String>
    getProperties();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    java.util.Map<java.lang.String, java.lang.String>
    getPropertiesMap();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    java.lang.String getPropertiesOrDefault(
        java.lang.String key,
        java.lang.String defaultValue);
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    java.lang.String getPropertiesOrThrow(
        java.lang.String key);

    /**
     * <pre>
     * The HCFS URI of the jar file containing the main class.
     * </pre>
     *
     * <code>string main_jar_file_uri = 6;</code>
     * @return The mainJarFileUri.
     */
    java.lang.String getMainJarFileUri();
    /**
     * <pre>
     * The HCFS URI of the jar file containing the main class.
     * </pre>
     *
     * <code>string main_jar_file_uri = 6;</code>
     * @return The bytes for mainJarFileUri.
     */
    com.google.protobuf.ByteString
        getMainJarFileUriBytes();

    /**
     * <pre>
     * The name of the driver's main class.
     * </pre>
     *
     * <code>string main_class = 7;</code>
     * @return The mainClass.
     */
    java.lang.String getMainClass();
    /**
     * <pre>
     * The name of the driver's main class.
     * </pre>
     *
     * <code>string main_class = 7;</code>
     * @return The bytes for mainClass.
     */
    com.google.protobuf.ByteString
        getMainClassBytes();

    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return A list containing the packages.
     */
    java.util.List<java.lang.String>
        getPackagesList();
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return The count of packages.
     */
    int getPackagesCount();
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the element to return.
     * @return The packages at the given index.
     */
    java.lang.String getPackages(int index);
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the value to return.
     * @return The bytes of the packages at the given index.
     */
    com.google.protobuf.ByteString
        getPackagesBytes(int index);

    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return A list containing the repositories.
     */
    java.util.List<java.lang.String>
        getRepositoriesList();
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return The count of repositories.
     */
    int getRepositoriesCount();
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the element to return.
     * @return The repositories at the given index.
     */
    java.lang.String getRepositories(int index);
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the value to return.
     * @return The bytes of the repositories at the given index.
     */
    com.google.protobuf.ByteString
        getRepositoriesBytes(int index);

    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return A list containing the excludePackages.
     */
    java.util.List<java.lang.String>
        getExcludePackagesList();
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return The count of excludePackages.
     */
    int getExcludePackagesCount();
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the element to return.
     * @return The excludePackages at the given index.
     */
    java.lang.String getExcludePackages(int index);
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the value to return.
     * @return The bytes of the excludePackages at the given index.
     */
    com.google.protobuf.ByteString
        getExcludePackagesBytes(int index);
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.SparkJob}
   */
  public static final class SparkJob extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.SparkJob)
      SparkJobOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SparkJob.newBuilder() to construct.
    private SparkJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SparkJob() {
      args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      mainJarFileUri_ = "";
      mainClass_ = "";
      packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new SparkJob();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SparkJob(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                args_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              args_.add(s);
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                jarFileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              jarFileUris_.add(s);
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                fileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              fileUris_.add(s);
              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                archiveUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              archiveUris_.add(s);
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) != 0)) {
                properties_ = com.google.protobuf.MapField.newMapField(
                    PropertiesDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000010;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
              properties__ = input.readMessage(
                  PropertiesDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              properties_.getMutableMap().put(
                  properties__.getKey(), properties__.getValue());
              break;
            }
            case 50: {
              java.lang.String s = input.readStringRequireUtf8();

              mainJarFileUri_ = s;
              break;
            }
            case 58: {
              java.lang.String s = input.readStringRequireUtf8();

              mainClass_ = s;
              break;
            }
            case 66: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000020) != 0)) {
                packages_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000020;
              }
              packages_.add(s);
              break;
            }
            case 74: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000040) != 0)) {
                repositories_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000040;
              }
              repositories_.add(s);
              break;
            }
            case 82: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000080) != 0)) {
                excludePackages_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000080;
              }
              excludePackages_.add(s);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          args_ = args_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = jarFileUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          fileUris_ = fileUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = archiveUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000020) != 0)) {
          packages_ = packages_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000040) != 0)) {
          repositories_ = repositories_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000080) != 0)) {
          excludePackages_ = excludePackages_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 5:
          return internalGetProperties();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.class, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder.class);
    }

    public static final int ARGS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList args_;
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return A list containing the args.
     */
    public com.google.protobuf.ProtocolStringList
        getArgsList() {
      return args_;
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return The count of args.
     */
    public int getArgsCount() {
      return args_.size();
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the element to return.
     * @return The args at the given index.
     */
    public java.lang.String getArgs(int index) {
      return args_.get(index);
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the args at the given index.
     */
    public com.google.protobuf.ByteString
        getArgsBytes(int index) {
      return args_.getByteString(index);
    }

    public static final int JAR_FILE_URIS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList jarFileUris_;
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return A list containing the jarFileUris.
     */
    public com.google.protobuf.ProtocolStringList
        getJarFileUrisList() {
      return jarFileUris_;
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return The count of jarFileUris.
     */
    public int getJarFileUrisCount() {
      return jarFileUris_.size();
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the element to return.
     * @return The jarFileUris at the given index.
     */
    public java.lang.String getJarFileUris(int index) {
      return jarFileUris_.get(index);
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the jarFileUris at the given index.
     */
    public com.google.protobuf.ByteString
        getJarFileUrisBytes(int index) {
      return jarFileUris_.getByteString(index);
    }

    public static final int FILE_URIS_FIELD_NUMBER = 3;
    private com.google.protobuf.LazyStringList fileUris_;
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return A list containing the fileUris.
     */
    public com.google.protobuf.ProtocolStringList
        getFileUrisList() {
      return fileUris_;
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return The count of fileUris.
     */
    public int getFileUrisCount() {
      return fileUris_.size();
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the element to return.
     * @return The fileUris at the given index.
     */
    public java.lang.String getFileUris(int index) {
      return fileUris_.get(index);
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the fileUris at the given index.
     */
    public com.google.protobuf.ByteString
        getFileUrisBytes(int index) {
      return fileUris_.getByteString(index);
    }

    public static final int ARCHIVE_URIS_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList archiveUris_;
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return A list containing the archiveUris.
     */
    public com.google.protobuf.ProtocolStringList
        getArchiveUrisList() {
      return archiveUris_;
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return The count of archiveUris.
     */
    public int getArchiveUrisCount() {
      return archiveUris_.size();
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the element to return.
     * @return The archiveUris at the given index.
     */
    public java.lang.String getArchiveUris(int index) {
      return archiveUris_.get(index);
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the archiveUris at the given index.
     */
    public com.google.protobuf.ByteString
        getArchiveUrisBytes(int index) {
      return archiveUris_.getByteString(index);
    }

    public static final int PROPERTIES_FIELD_NUMBER = 5;
    private static final class PropertiesDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, java.lang.String> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, java.lang.String>newDefaultInstance(
                  yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> properties_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetProperties() {
      if (properties_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            PropertiesDefaultEntryHolder.defaultEntry);
      }
      return properties_;
    }

    public int getPropertiesCount() {
      return internalGetProperties().getMap().size();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    @java.lang.Override
    public boolean containsProperties(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetProperties().getMap().containsKey(key);
    }
    /**
     * Use {@link #getPropertiesMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getProperties() {
      return getPropertiesMap();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
      return internalGetProperties().getMap();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.lang.String getPropertiesOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetProperties().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.lang.String getPropertiesOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetProperties().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int MAIN_JAR_FILE_URI_FIELD_NUMBER = 6;
    private volatile java.lang.Object mainJarFileUri_;
    /**
     * <pre>
     * The HCFS URI of the jar file containing the main class.
     * </pre>
     *
     * <code>string main_jar_file_uri = 6;</code>
     * @return The mainJarFileUri.
     */
    @java.lang.Override
    public java.lang.String getMainJarFileUri() {
      java.lang.Object ref = mainJarFileUri_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainJarFileUri_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * The HCFS URI of the jar file containing the main class.
     * </pre>
     *
     * <code>string main_jar_file_uri = 6;</code>
     * @return The bytes for mainJarFileUri.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getMainJarFileUriBytes() {
      java.lang.Object ref = mainJarFileUri_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mainJarFileUri_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int MAIN_CLASS_FIELD_NUMBER = 7;
    private volatile java.lang.Object mainClass_;
    /**
     * <pre>
     * The name of the driver's main class.
     * </pre>
     *
     * <code>string main_class = 7;</code>
     * @return The mainClass.
     */
    @java.lang.Override
    public java.lang.String getMainClass() {
      java.lang.Object ref = mainClass_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainClass_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * The name of the driver's main class.
     * </pre>
     *
     * <code>string main_class = 7;</code>
     * @return The bytes for mainClass.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getMainClassBytes() {
      java.lang.Object ref = mainClass_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mainClass_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PACKAGES_FIELD_NUMBER = 8;
    private com.google.protobuf.LazyStringList packages_;
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return A list containing the packages.
     */
    public com.google.protobuf.ProtocolStringList
        getPackagesList() {
      return packages_;
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return The count of packages.
     */
    public int getPackagesCount() {
      return packages_.size();
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the element to return.
     * @return The packages at the given index.
     */
    public java.lang.String getPackages(int index) {
      return packages_.get(index);
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the value to return.
     * @return The bytes of the packages at the given index.
     */
    public com.google.protobuf.ByteString
        getPackagesBytes(int index) {
      return packages_.getByteString(index);
    }

    public static final int REPOSITORIES_FIELD_NUMBER = 9;
    private com.google.protobuf.LazyStringList repositories_;
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return A list containing the repositories.
     */
    public com.google.protobuf.ProtocolStringList
        getRepositoriesList() {
      return repositories_;
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return The count of repositories.
     */
    public int getRepositoriesCount() {
      return repositories_.size();
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the element to return.
     * @return The repositories at the given index.
     */
    public java.lang.String getRepositories(int index) {
      return repositories_.get(index);
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the value to return.
     * @return The bytes of the repositories at the given index.
     */
    public com.google.protobuf.ByteString
        getRepositoriesBytes(int index) {
      return repositories_.getByteString(index);
    }

    public static final int EXCLUDE_PACKAGES_FIELD_NUMBER = 10;
    private com.google.protobuf.LazyStringList excludePackages_;
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return A list containing the excludePackages.
     */
    public com.google.protobuf.ProtocolStringList
        getExcludePackagesList() {
      return excludePackages_;
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return The count of excludePackages.
     */
    public int getExcludePackagesCount() {
      return excludePackages_.size();
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the element to return.
     * @return The excludePackages at the given index.
     */
    public java.lang.String getExcludePackages(int index) {
      return excludePackages_.get(index);
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the value to return.
     * @return The bytes of the excludePackages at the given index.
     */
    public com.google.protobuf.ByteString
        getExcludePackagesBytes(int index) {
      return excludePackages_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < args_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, args_.getRaw(i));
      }
      for (int i = 0; i < jarFileUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jarFileUris_.getRaw(i));
      }
      for (int i = 0; i < fileUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, fileUris_.getRaw(i));
      }
      for (int i = 0; i < archiveUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, archiveUris_.getRaw(i));
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetProperties(),
          PropertiesDefaultEntryHolder.defaultEntry,
          5);
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainJarFileUri_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, mainJarFileUri_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainClass_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 7, mainClass_);
      }
      for (int i = 0; i < packages_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, packages_.getRaw(i));
      }
      for (int i = 0; i < repositories_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, repositories_.getRaw(i));
      }
      for (int i = 0; i < excludePackages_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, excludePackages_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < args_.size(); i++) {
          dataSize += computeStringSizeNoTag(args_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getArgsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < jarFileUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(jarFileUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getJarFileUrisList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < fileUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(fileUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getFileUrisList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < archiveUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(archiveUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getArchiveUrisList().size();
      }
      for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
           : internalGetProperties().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
        properties__ = PropertiesDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(5, properties__);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainJarFileUri_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, mainJarFileUri_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainClass_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(7, mainClass_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < packages_.size(); i++) {
          dataSize += computeStringSizeNoTag(packages_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getPackagesList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < repositories_.size(); i++) {
          dataSize += computeStringSizeNoTag(repositories_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getRepositoriesList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < excludePackages_.size(); i++) {
          dataSize += computeStringSizeNoTag(excludePackages_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getExcludePackagesList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobOuterClass.SparkJob)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobOuterClass.SparkJob other = (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) obj;

      if (!getArgsList()
          .equals(other.getArgsList())) return false;
      if (!getJarFileUrisList()
          .equals(other.getJarFileUrisList())) return false;
      if (!getFileUrisList()
          .equals(other.getFileUrisList())) return false;
      if (!getArchiveUrisList()
          .equals(other.getArchiveUrisList())) return false;
      if (!internalGetProperties().equals(
          other.internalGetProperties())) return false;
      if (!getMainJarFileUri()
          .equals(other.getMainJarFileUri())) return false;
      if (!getMainClass()
          .equals(other.getMainClass())) return false;
      if (!getPackagesList()
          .equals(other.getPackagesList())) return false;
      if (!getRepositoriesList()
          .equals(other.getRepositoriesList())) return false;
      if (!getExcludePackagesList()
          .equals(other.getExcludePackagesList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getArgsCount() > 0) {
        hash = (37 * hash) + ARGS_FIELD_NUMBER;
        hash = (53 * hash) + getArgsList().hashCode();
      }
      if (getJarFileUrisCount() > 0) {
        hash = (37 * hash) + JAR_FILE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getJarFileUrisList().hashCode();
      }
      if (getFileUrisCount() > 0) {
        hash = (37 * hash) + FILE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getFileUrisList().hashCode();
      }
      if (getArchiveUrisCount() > 0) {
        hash = (37 * hash) + ARCHIVE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getArchiveUrisList().hashCode();
      }
      if (!internalGetProperties().getMap().isEmpty()) {
        hash = (37 * hash) + PROPERTIES_FIELD_NUMBER;
        hash = (53 * hash) + internalGetProperties().hashCode();
      }
      hash = (37 * hash) + MAIN_JAR_FILE_URI_FIELD_NUMBER;
      hash = (53 * hash) + getMainJarFileUri().hashCode();
      hash = (37 * hash) + MAIN_CLASS_FIELD_NUMBER;
      hash = (53 * hash) + getMainClass().hashCode();
      if (getPackagesCount() > 0) {
        hash = (37 * hash) + PACKAGES_FIELD_NUMBER;
        hash = (53 * hash) + getPackagesList().hashCode();
      }
      if (getRepositoriesCount() > 0) {
        hash = (37 * hash) + REPOSITORIES_FIELD_NUMBER;
        hash = (53 * hash) + getRepositoriesList().hashCode();
      }
      if (getExcludePackagesCount() > 0) {
        hash = (37 * hash) + EXCLUDE_PACKAGES_FIELD_NUMBER;
        hash = (53 * hash) + getExcludePackagesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.SparkJob}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.SparkJob)
        yandex.cloud.api.spark.v1.JobOuterClass.SparkJobOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 5:
            return internalGetProperties();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 5:
            return internalGetMutableProperties();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.class, yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        internalGetMutableProperties().clear();
        mainJarFileUri_ = "";

        mainClass_ = "";

        packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000040);
        excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_SparkJob_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob build() {
        yandex.cloud.api.spark.v1.JobOuterClass.SparkJob result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob buildPartial() {
        yandex.cloud.api.spark.v1.JobOuterClass.SparkJob result = new yandex.cloud.api.spark.v1.JobOuterClass.SparkJob(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) != 0)) {
          args_ = args_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.args_ = args_;
        if (((bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = jarFileUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.jarFileUris_ = jarFileUris_;
        if (((bitField0_ & 0x00000004) != 0)) {
          fileUris_ = fileUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.fileUris_ = fileUris_;
        if (((bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = archiveUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.archiveUris_ = archiveUris_;
        result.properties_ = internalGetProperties();
        result.properties_.makeImmutable();
        result.mainJarFileUri_ = mainJarFileUri_;
        result.mainClass_ = mainClass_;
        if (((bitField0_ & 0x00000020) != 0)) {
          packages_ = packages_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000020);
        }
        result.packages_ = packages_;
        if (((bitField0_ & 0x00000040) != 0)) {
          repositories_ = repositories_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000040);
        }
        result.repositories_ = repositories_;
        if (((bitField0_ & 0x00000080) != 0)) {
          excludePackages_ = excludePackages_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000080);
        }
        result.excludePackages_ = excludePackages_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.SparkJob)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobOuterClass.SparkJob other) {
        if (other == yandex.cloud.api.spark.v1.JobOuterClass.SparkJob.getDefaultInstance()) return this;
        if (!other.args_.isEmpty()) {
          if (args_.isEmpty()) {
            args_ = other.args_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureArgsIsMutable();
            args_.addAll(other.args_);
          }
          onChanged();
        }
        if (!other.jarFileUris_.isEmpty()) {
          if (jarFileUris_.isEmpty()) {
            jarFileUris_ = other.jarFileUris_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureJarFileUrisIsMutable();
            jarFileUris_.addAll(other.jarFileUris_);
          }
          onChanged();
        }
        if (!other.fileUris_.isEmpty()) {
          if (fileUris_.isEmpty()) {
            fileUris_ = other.fileUris_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureFileUrisIsMutable();
            fileUris_.addAll(other.fileUris_);
          }
          onChanged();
        }
        if (!other.archiveUris_.isEmpty()) {
          if (archiveUris_.isEmpty()) {
            archiveUris_ = other.archiveUris_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureArchiveUrisIsMutable();
            archiveUris_.addAll(other.archiveUris_);
          }
          onChanged();
        }
        internalGetMutableProperties().mergeFrom(
            other.internalGetProperties());
        if (!other.getMainJarFileUri().isEmpty()) {
          mainJarFileUri_ = other.mainJarFileUri_;
          onChanged();
        }
        if (!other.getMainClass().isEmpty()) {
          mainClass_ = other.mainClass_;
          onChanged();
        }
        if (!other.packages_.isEmpty()) {
          if (packages_.isEmpty()) {
            packages_ = other.packages_;
            bitField0_ = (bitField0_ & ~0x00000020);
          } else {
            ensurePackagesIsMutable();
            packages_.addAll(other.packages_);
          }
          onChanged();
        }
        if (!other.repositories_.isEmpty()) {
          if (repositories_.isEmpty()) {
            repositories_ = other.repositories_;
            bitField0_ = (bitField0_ & ~0x00000040);
          } else {
            ensureRepositoriesIsMutable();
            repositories_.addAll(other.repositories_);
          }
          onChanged();
        }
        if (!other.excludePackages_.isEmpty()) {
          if (excludePackages_.isEmpty()) {
            excludePackages_ = other.excludePackages_;
            bitField0_ = (bitField0_ & ~0x00000080);
          } else {
            ensureExcludePackagesIsMutable();
            excludePackages_.addAll(other.excludePackages_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobOuterClass.SparkJob parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobOuterClass.SparkJob) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureArgsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          args_ = new com.google.protobuf.LazyStringArrayList(args_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return A list containing the args.
       */
      public com.google.protobuf.ProtocolStringList
          getArgsList() {
        return args_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return The count of args.
       */
      public int getArgsCount() {
        return args_.size();
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index of the element to return.
       * @return The args at the given index.
       */
      public java.lang.String getArgs(int index) {
        return args_.get(index);
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the args at the given index.
       */
      public com.google.protobuf.ByteString
          getArgsBytes(int index) {
        return args_.getByteString(index);
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index to set the value at.
       * @param value The args to set.
       * @return This builder for chaining.
       */
      public Builder setArgs(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArgsIsMutable();
        args_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param value The args to add.
       * @return This builder for chaining.
       */
      public Builder addArgs(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArgsIsMutable();
        args_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param values The args to add.
       * @return This builder for chaining.
       */
      public Builder addAllArgs(
          java.lang.Iterable<java.lang.String> values) {
        ensureArgsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, args_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearArgs() {
        args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param value The bytes of the args to add.
       * @return This builder for chaining.
       */
      public Builder addArgsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureArgsIsMutable();
        args_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureJarFileUrisIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = new com.google.protobuf.LazyStringArrayList(jarFileUris_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return A list containing the jarFileUris.
       */
      public com.google.protobuf.ProtocolStringList
          getJarFileUrisList() {
        return jarFileUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return The count of jarFileUris.
       */
      public int getJarFileUrisCount() {
        return jarFileUris_.size();
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index of the element to return.
       * @return The jarFileUris at the given index.
       */
      public java.lang.String getJarFileUris(int index) {
        return jarFileUris_.get(index);
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index of the value to return.
       * @return The bytes of the jarFileUris at the given index.
       */
      public com.google.protobuf.ByteString
          getJarFileUrisBytes(int index) {
        return jarFileUris_.getByteString(index);
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index to set the value at.
       * @param value The jarFileUris to set.
       * @return This builder for chaining.
       */
      public Builder setJarFileUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureJarFileUrisIsMutable();
        jarFileUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param value The jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addJarFileUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureJarFileUrisIsMutable();
        jarFileUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param values The jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllJarFileUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureJarFileUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, jarFileUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearJarFileUris() {
        jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param value The bytes of the jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addJarFileUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureJarFileUrisIsMutable();
        jarFileUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureFileUrisIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          fileUris_ = new com.google.protobuf.LazyStringArrayList(fileUris_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return A list containing the fileUris.
       */
      public com.google.protobuf.ProtocolStringList
          getFileUrisList() {
        return fileUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return The count of fileUris.
       */
      public int getFileUrisCount() {
        return fileUris_.size();
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index of the element to return.
       * @return The fileUris at the given index.
       */
      public java.lang.String getFileUris(int index) {
        return fileUris_.get(index);
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the fileUris at the given index.
       */
      public com.google.protobuf.ByteString
          getFileUrisBytes(int index) {
        return fileUris_.getByteString(index);
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index to set the value at.
       * @param value The fileUris to set.
       * @return This builder for chaining.
       */
      public Builder setFileUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFileUrisIsMutable();
        fileUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param value The fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addFileUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFileUrisIsMutable();
        fileUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param values The fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllFileUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureFileUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, fileUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearFileUris() {
        fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param value The bytes of the fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addFileUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureFileUrisIsMutable();
        fileUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureArchiveUrisIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = new com.google.protobuf.LazyStringArrayList(archiveUris_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return A list containing the archiveUris.
       */
      public com.google.protobuf.ProtocolStringList
          getArchiveUrisList() {
        return archiveUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return The count of archiveUris.
       */
      public int getArchiveUrisCount() {
        return archiveUris_.size();
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index of the element to return.
       * @return The archiveUris at the given index.
       */
      public java.lang.String getArchiveUris(int index) {
        return archiveUris_.get(index);
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index of the value to return.
       * @return The bytes of the archiveUris at the given index.
       */
      public com.google.protobuf.ByteString
          getArchiveUrisBytes(int index) {
        return archiveUris_.getByteString(index);
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index to set the value at.
       * @param value The archiveUris to set.
       * @return This builder for chaining.
       */
      public Builder setArchiveUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArchiveUrisIsMutable();
        archiveUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param value The archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addArchiveUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArchiveUrisIsMutable();
        archiveUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param values The archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllArchiveUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureArchiveUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, archiveUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearArchiveUris() {
        archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param value The bytes of the archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addArchiveUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureArchiveUrisIsMutable();
        archiveUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, java.lang.String> properties_;
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetProperties() {
        if (properties_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              PropertiesDefaultEntryHolder.defaultEntry);
        }
        return properties_;
      }
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetMutableProperties() {
        onChanged();;
        if (properties_ == null) {
          properties_ = com.google.protobuf.MapField.newMapField(
              PropertiesDefaultEntryHolder.defaultEntry);
        }
        if (!properties_.isMutable()) {
          properties_ = properties_.copy();
        }
        return properties_;
      }

      public int getPropertiesCount() {
        return internalGetProperties().getMap().size();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      @java.lang.Override
      public boolean containsProperties(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        return internalGetProperties().getMap().containsKey(key);
      }
      /**
       * Use {@link #getPropertiesMap()} instead.
       */
      @java.lang.Override
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String> getProperties() {
        return getPropertiesMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
        return internalGetProperties().getMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.lang.String getPropertiesOrDefault(
          java.lang.String key,
          java.lang.String defaultValue) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetProperties().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.lang.String getPropertiesOrThrow(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetProperties().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearProperties() {
        internalGetMutableProperties().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      public Builder removeProperties(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        internalGetMutableProperties().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String>
      getMutableProperties() {
        return internalGetMutableProperties().getMutableMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      public Builder putProperties(
          java.lang.String key,
          java.lang.String value) {
        if (key == null) { throw new NullPointerException("map key"); }
        if (value == null) {
  throw new NullPointerException("map value");
}

        internalGetMutableProperties().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      public Builder putAllProperties(
          java.util.Map<java.lang.String, java.lang.String> values) {
        internalGetMutableProperties().getMutableMap()
            .putAll(values);
        return this;
      }

      private java.lang.Object mainJarFileUri_ = "";
      /**
       * <pre>
       * The HCFS URI of the jar file containing the main class.
       * </pre>
       *
       * <code>string main_jar_file_uri = 6;</code>
       * @return The mainJarFileUri.
       */
      public java.lang.String getMainJarFileUri() {
        java.lang.Object ref = mainJarFileUri_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          mainJarFileUri_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The HCFS URI of the jar file containing the main class.
       * </pre>
       *
       * <code>string main_jar_file_uri = 6;</code>
       * @return The bytes for mainJarFileUri.
       */
      public com.google.protobuf.ByteString
          getMainJarFileUriBytes() {
        java.lang.Object ref = mainJarFileUri_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          mainJarFileUri_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The HCFS URI of the jar file containing the main class.
       * </pre>
       *
       * <code>string main_jar_file_uri = 6;</code>
       * @param value The mainJarFileUri to set.
       * @return This builder for chaining.
       */
      public Builder setMainJarFileUri(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        mainJarFileUri_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The HCFS URI of the jar file containing the main class.
       * </pre>
       *
       * <code>string main_jar_file_uri = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearMainJarFileUri() {
        
        mainJarFileUri_ = getDefaultInstance().getMainJarFileUri();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The HCFS URI of the jar file containing the main class.
       * </pre>
       *
       * <code>string main_jar_file_uri = 6;</code>
       * @param value The bytes for mainJarFileUri to set.
       * @return This builder for chaining.
       */
      public Builder setMainJarFileUriBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        mainJarFileUri_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object mainClass_ = "";
      /**
       * <pre>
       * The name of the driver's main class.
       * </pre>
       *
       * <code>string main_class = 7;</code>
       * @return The mainClass.
       */
      public java.lang.String getMainClass() {
        java.lang.Object ref = mainClass_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          mainClass_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The name of the driver's main class.
       * </pre>
       *
       * <code>string main_class = 7;</code>
       * @return The bytes for mainClass.
       */
      public com.google.protobuf.ByteString
          getMainClassBytes() {
        java.lang.Object ref = mainClass_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          mainClass_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The name of the driver's main class.
       * </pre>
       *
       * <code>string main_class = 7;</code>
       * @param value The mainClass to set.
       * @return This builder for chaining.
       */
      public Builder setMainClass(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        mainClass_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The name of the driver's main class.
       * </pre>
       *
       * <code>string main_class = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearMainClass() {
        
        mainClass_ = getDefaultInstance().getMainClass();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The name of the driver's main class.
       * </pre>
       *
       * <code>string main_class = 7;</code>
       * @param value The bytes for mainClass to set.
       * @return This builder for chaining.
       */
      public Builder setMainClassBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        mainClass_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensurePackagesIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          packages_ = new com.google.protobuf.LazyStringArrayList(packages_);
          bitField0_ |= 0x00000020;
         }
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return A list containing the packages.
       */
      public com.google.protobuf.ProtocolStringList
          getPackagesList() {
        return packages_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return The count of packages.
       */
      public int getPackagesCount() {
        return packages_.size();
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index of the element to return.
       * @return The packages at the given index.
       */
      public java.lang.String getPackages(int index) {
        return packages_.get(index);
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index of the value to return.
       * @return The bytes of the packages at the given index.
       */
      public com.google.protobuf.ByteString
          getPackagesBytes(int index) {
        return packages_.getByteString(index);
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index to set the value at.
       * @param value The packages to set.
       * @return This builder for chaining.
       */
      public Builder setPackages(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePackagesIsMutable();
        packages_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param value The packages to add.
       * @return This builder for chaining.
       */
      public Builder addPackages(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePackagesIsMutable();
        packages_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param values The packages to add.
       * @return This builder for chaining.
       */
      public Builder addAllPackages(
          java.lang.Iterable<java.lang.String> values) {
        ensurePackagesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, packages_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearPackages() {
        packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param value The bytes of the packages to add.
       * @return This builder for chaining.
       */
      public Builder addPackagesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensurePackagesIsMutable();
        packages_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureRepositoriesIsMutable() {
        if (!((bitField0_ & 0x00000040) != 0)) {
          repositories_ = new com.google.protobuf.LazyStringArrayList(repositories_);
          bitField0_ |= 0x00000040;
         }
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return A list containing the repositories.
       */
      public com.google.protobuf.ProtocolStringList
          getRepositoriesList() {
        return repositories_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return The count of repositories.
       */
      public int getRepositoriesCount() {
        return repositories_.size();
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index of the element to return.
       * @return The repositories at the given index.
       */
      public java.lang.String getRepositories(int index) {
        return repositories_.get(index);
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index of the value to return.
       * @return The bytes of the repositories at the given index.
       */
      public com.google.protobuf.ByteString
          getRepositoriesBytes(int index) {
        return repositories_.getByteString(index);
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index to set the value at.
       * @param value The repositories to set.
       * @return This builder for chaining.
       */
      public Builder setRepositories(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRepositoriesIsMutable();
        repositories_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param value The repositories to add.
       * @return This builder for chaining.
       */
      public Builder addRepositories(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRepositoriesIsMutable();
        repositories_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param values The repositories to add.
       * @return This builder for chaining.
       */
      public Builder addAllRepositories(
          java.lang.Iterable<java.lang.String> values) {
        ensureRepositoriesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, repositories_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearRepositories() {
        repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000040);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param value The bytes of the repositories to add.
       * @return This builder for chaining.
       */
      public Builder addRepositoriesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureRepositoriesIsMutable();
        repositories_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureExcludePackagesIsMutable() {
        if (!((bitField0_ & 0x00000080) != 0)) {
          excludePackages_ = new com.google.protobuf.LazyStringArrayList(excludePackages_);
          bitField0_ |= 0x00000080;
         }
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return A list containing the excludePackages.
       */
      public com.google.protobuf.ProtocolStringList
          getExcludePackagesList() {
        return excludePackages_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return The count of excludePackages.
       */
      public int getExcludePackagesCount() {
        return excludePackages_.size();
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index of the element to return.
       * @return The excludePackages at the given index.
       */
      public java.lang.String getExcludePackages(int index) {
        return excludePackages_.get(index);
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index of the value to return.
       * @return The bytes of the excludePackages at the given index.
       */
      public com.google.protobuf.ByteString
          getExcludePackagesBytes(int index) {
        return excludePackages_.getByteString(index);
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index to set the value at.
       * @param value The excludePackages to set.
       * @return This builder for chaining.
       */
      public Builder setExcludePackages(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureExcludePackagesIsMutable();
        excludePackages_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param value The excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePackages(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureExcludePackagesIsMutable();
        excludePackages_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param values The excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addAllExcludePackages(
          java.lang.Iterable<java.lang.String> values) {
        ensureExcludePackagesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, excludePackages_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return This builder for chaining.
       */
      public Builder clearExcludePackages() {
        excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param value The bytes of the excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePackagesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureExcludePackagesIsMutable();
        excludePackages_.add(value);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.SparkJob)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.SparkJob)
    private static final yandex.cloud.api.spark.v1.JobOuterClass.SparkJob DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobOuterClass.SparkJob();
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SparkJob>
        PARSER = new com.google.protobuf.AbstractParser<SparkJob>() {
      @java.lang.Override
      public SparkJob parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SparkJob(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SparkJob> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SparkJob> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.SparkJob getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PysparkJobOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.spark.v1.PysparkJob)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return A list containing the args.
     */
    java.util.List<java.lang.String>
        getArgsList();
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return The count of args.
     */
    int getArgsCount();
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the element to return.
     * @return The args at the given index.
     */
    java.lang.String getArgs(int index);
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the args at the given index.
     */
    com.google.protobuf.ByteString
        getArgsBytes(int index);

    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return A list containing the jarFileUris.
     */
    java.util.List<java.lang.String>
        getJarFileUrisList();
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return The count of jarFileUris.
     */
    int getJarFileUrisCount();
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the element to return.
     * @return The jarFileUris at the given index.
     */
    java.lang.String getJarFileUris(int index);
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the jarFileUris at the given index.
     */
    com.google.protobuf.ByteString
        getJarFileUrisBytes(int index);

    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return A list containing the fileUris.
     */
    java.util.List<java.lang.String>
        getFileUrisList();
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return The count of fileUris.
     */
    int getFileUrisCount();
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the element to return.
     * @return The fileUris at the given index.
     */
    java.lang.String getFileUris(int index);
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the fileUris at the given index.
     */
    com.google.protobuf.ByteString
        getFileUrisBytes(int index);

    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return A list containing the archiveUris.
     */
    java.util.List<java.lang.String>
        getArchiveUrisList();
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return The count of archiveUris.
     */
    int getArchiveUrisCount();
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the element to return.
     * @return The archiveUris at the given index.
     */
    java.lang.String getArchiveUris(int index);
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the archiveUris at the given index.
     */
    com.google.protobuf.ByteString
        getArchiveUrisBytes(int index);

    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    int getPropertiesCount();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    boolean containsProperties(
        java.lang.String key);
    /**
     * Use {@link #getPropertiesMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, java.lang.String>
    getProperties();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    java.util.Map<java.lang.String, java.lang.String>
    getPropertiesMap();
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    java.lang.String getPropertiesOrDefault(
        java.lang.String key,
        java.lang.String defaultValue);
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    java.lang.String getPropertiesOrThrow(
        java.lang.String key);

    /**
     * <pre>
     * URI of the main Python file to use as the driver. Must be a .py file.
     * </pre>
     *
     * <code>string main_python_file_uri = 6;</code>
     * @return The mainPythonFileUri.
     */
    java.lang.String getMainPythonFileUri();
    /**
     * <pre>
     * URI of the main Python file to use as the driver. Must be a .py file.
     * </pre>
     *
     * <code>string main_python_file_uri = 6;</code>
     * @return The bytes for mainPythonFileUri.
     */
    com.google.protobuf.ByteString
        getMainPythonFileUriBytes();

    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @return A list containing the pythonFileUris.
     */
    java.util.List<java.lang.String>
        getPythonFileUrisList();
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @return The count of pythonFileUris.
     */
    int getPythonFileUrisCount();
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @param index The index of the element to return.
     * @return The pythonFileUris at the given index.
     */
    java.lang.String getPythonFileUris(int index);
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @param index The index of the value to return.
     * @return The bytes of the pythonFileUris at the given index.
     */
    com.google.protobuf.ByteString
        getPythonFileUrisBytes(int index);

    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return A list containing the packages.
     */
    java.util.List<java.lang.String>
        getPackagesList();
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return The count of packages.
     */
    int getPackagesCount();
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the element to return.
     * @return The packages at the given index.
     */
    java.lang.String getPackages(int index);
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the value to return.
     * @return The bytes of the packages at the given index.
     */
    com.google.protobuf.ByteString
        getPackagesBytes(int index);

    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return A list containing the repositories.
     */
    java.util.List<java.lang.String>
        getRepositoriesList();
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return The count of repositories.
     */
    int getRepositoriesCount();
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the element to return.
     * @return The repositories at the given index.
     */
    java.lang.String getRepositories(int index);
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the value to return.
     * @return The bytes of the repositories at the given index.
     */
    com.google.protobuf.ByteString
        getRepositoriesBytes(int index);

    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return A list containing the excludePackages.
     */
    java.util.List<java.lang.String>
        getExcludePackagesList();
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return The count of excludePackages.
     */
    int getExcludePackagesCount();
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the element to return.
     * @return The excludePackages at the given index.
     */
    java.lang.String getExcludePackages(int index);
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the value to return.
     * @return The bytes of the excludePackages at the given index.
     */
    com.google.protobuf.ByteString
        getExcludePackagesBytes(int index);
  }
  /**
   * Protobuf type {@code yandex.cloud.spark.v1.PysparkJob}
   */
  public static final class PysparkJob extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.spark.v1.PysparkJob)
      PysparkJobOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PysparkJob.newBuilder() to construct.
    private PysparkJob(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PysparkJob() {
      args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      mainPythonFileUri_ = "";
      pythonFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new PysparkJob();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PysparkJob(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                args_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              args_.add(s);
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                jarFileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              jarFileUris_.add(s);
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                fileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              fileUris_.add(s);
              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                archiveUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              archiveUris_.add(s);
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) != 0)) {
                properties_ = com.google.protobuf.MapField.newMapField(
                    PropertiesDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000010;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
              properties__ = input.readMessage(
                  PropertiesDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              properties_.getMutableMap().put(
                  properties__.getKey(), properties__.getValue());
              break;
            }
            case 50: {
              java.lang.String s = input.readStringRequireUtf8();

              mainPythonFileUri_ = s;
              break;
            }
            case 58: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000020) != 0)) {
                pythonFileUris_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000020;
              }
              pythonFileUris_.add(s);
              break;
            }
            case 66: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000040) != 0)) {
                packages_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000040;
              }
              packages_.add(s);
              break;
            }
            case 74: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000080) != 0)) {
                repositories_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000080;
              }
              repositories_.add(s);
              break;
            }
            case 82: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000100) != 0)) {
                excludePackages_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000100;
              }
              excludePackages_.add(s);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          args_ = args_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = jarFileUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          fileUris_ = fileUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = archiveUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000020) != 0)) {
          pythonFileUris_ = pythonFileUris_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000040) != 0)) {
          packages_ = packages_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000080) != 0)) {
          repositories_ = repositories_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000100) != 0)) {
          excludePackages_ = excludePackages_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 5:
          return internalGetProperties();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.class, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder.class);
    }

    public static final int ARGS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList args_;
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return A list containing the args.
     */
    public com.google.protobuf.ProtocolStringList
        getArgsList() {
      return args_;
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @return The count of args.
     */
    public int getArgsCount() {
      return args_.size();
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the element to return.
     * @return The args at the given index.
     */
    public java.lang.String getArgs(int index) {
      return args_.get(index);
    }
    /**
     * <pre>
     * Optional arguments to pass to the driver.
     * </pre>
     *
     * <code>repeated string args = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the args at the given index.
     */
    public com.google.protobuf.ByteString
        getArgsBytes(int index) {
      return args_.getByteString(index);
    }

    public static final int JAR_FILE_URIS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList jarFileUris_;
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return A list containing the jarFileUris.
     */
    public com.google.protobuf.ProtocolStringList
        getJarFileUrisList() {
      return jarFileUris_;
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @return The count of jarFileUris.
     */
    public int getJarFileUrisCount() {
      return jarFileUris_.size();
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the element to return.
     * @return The jarFileUris at the given index.
     */
    public java.lang.String getJarFileUris(int index) {
      return jarFileUris_.get(index);
    }
    /**
     * <pre>
     * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
     * </pre>
     *
     * <code>repeated string jar_file_uris = 2;</code>
     * @param index The index of the value to return.
     * @return The bytes of the jarFileUris at the given index.
     */
    public com.google.protobuf.ByteString
        getJarFileUrisBytes(int index) {
      return jarFileUris_.getByteString(index);
    }

    public static final int FILE_URIS_FIELD_NUMBER = 3;
    private com.google.protobuf.LazyStringList fileUris_;
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return A list containing the fileUris.
     */
    public com.google.protobuf.ProtocolStringList
        getFileUrisList() {
      return fileUris_;
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @return The count of fileUris.
     */
    public int getFileUrisCount() {
      return fileUris_.size();
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the element to return.
     * @return The fileUris at the given index.
     */
    public java.lang.String getFileUris(int index) {
      return fileUris_.get(index);
    }
    /**
     * <pre>
     * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
     * </pre>
     *
     * <code>repeated string file_uris = 3;</code>
     * @param index The index of the value to return.
     * @return The bytes of the fileUris at the given index.
     */
    public com.google.protobuf.ByteString
        getFileUrisBytes(int index) {
      return fileUris_.getByteString(index);
    }

    public static final int ARCHIVE_URIS_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList archiveUris_;
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return A list containing the archiveUris.
     */
    public com.google.protobuf.ProtocolStringList
        getArchiveUrisList() {
      return archiveUris_;
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @return The count of archiveUris.
     */
    public int getArchiveUrisCount() {
      return archiveUris_.size();
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the element to return.
     * @return The archiveUris at the given index.
     */
    public java.lang.String getArchiveUris(int index) {
      return archiveUris_.get(index);
    }
    /**
     * <pre>
     * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
     * </pre>
     *
     * <code>repeated string archive_uris = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the archiveUris at the given index.
     */
    public com.google.protobuf.ByteString
        getArchiveUrisBytes(int index) {
      return archiveUris_.getByteString(index);
    }

    public static final int PROPERTIES_FIELD_NUMBER = 5;
    private static final class PropertiesDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, java.lang.String> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, java.lang.String>newDefaultInstance(
                  yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> properties_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetProperties() {
      if (properties_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            PropertiesDefaultEntryHolder.defaultEntry);
      }
      return properties_;
    }

    public int getPropertiesCount() {
      return internalGetProperties().getMap().size();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */

    @java.lang.Override
    public boolean containsProperties(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetProperties().getMap().containsKey(key);
    }
    /**
     * Use {@link #getPropertiesMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getProperties() {
      return getPropertiesMap();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
      return internalGetProperties().getMap();
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.lang.String getPropertiesOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetProperties().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * A mapping of property names to values, used to configure Spark.
     * </pre>
     *
     * <code>map&lt;string, string&gt; properties = 5;</code>
     */
    @java.lang.Override

    public java.lang.String getPropertiesOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetProperties().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int MAIN_PYTHON_FILE_URI_FIELD_NUMBER = 6;
    private volatile java.lang.Object mainPythonFileUri_;
    /**
     * <pre>
     * URI of the main Python file to use as the driver. Must be a .py file.
     * </pre>
     *
     * <code>string main_python_file_uri = 6;</code>
     * @return The mainPythonFileUri.
     */
    @java.lang.Override
    public java.lang.String getMainPythonFileUri() {
      java.lang.Object ref = mainPythonFileUri_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        mainPythonFileUri_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * URI of the main Python file to use as the driver. Must be a .py file.
     * </pre>
     *
     * <code>string main_python_file_uri = 6;</code>
     * @return The bytes for mainPythonFileUri.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getMainPythonFileUriBytes() {
      java.lang.Object ref = mainPythonFileUri_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        mainPythonFileUri_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PYTHON_FILE_URIS_FIELD_NUMBER = 7;
    private com.google.protobuf.LazyStringList pythonFileUris_;
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @return A list containing the pythonFileUris.
     */
    public com.google.protobuf.ProtocolStringList
        getPythonFileUrisList() {
      return pythonFileUris_;
    }
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @return The count of pythonFileUris.
     */
    public int getPythonFileUrisCount() {
      return pythonFileUris_.size();
    }
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @param index The index of the element to return.
     * @return The pythonFileUris at the given index.
     */
    public java.lang.String getPythonFileUris(int index) {
      return pythonFileUris_.get(index);
    }
    /**
     * <pre>
     * URIs of Python files to pass to the PySpark framework.
     * </pre>
     *
     * <code>repeated string python_file_uris = 7;</code>
     * @param index The index of the value to return.
     * @return The bytes of the pythonFileUris at the given index.
     */
    public com.google.protobuf.ByteString
        getPythonFileUrisBytes(int index) {
      return pythonFileUris_.getByteString(index);
    }

    public static final int PACKAGES_FIELD_NUMBER = 8;
    private com.google.protobuf.LazyStringList packages_;
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return A list containing the packages.
     */
    public com.google.protobuf.ProtocolStringList
        getPackagesList() {
      return packages_;
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @return The count of packages.
     */
    public int getPackagesCount() {
      return packages_.size();
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the element to return.
     * @return The packages at the given index.
     */
    public java.lang.String getPackages(int index) {
      return packages_.get(index);
    }
    /**
     * <pre>
     * List of maven coordinates of jars to include on the driver and executor classpaths.
     * </pre>
     *
     * <code>repeated string packages = 8;</code>
     * @param index The index of the value to return.
     * @return The bytes of the packages at the given index.
     */
    public com.google.protobuf.ByteString
        getPackagesBytes(int index) {
      return packages_.getByteString(index);
    }

    public static final int REPOSITORIES_FIELD_NUMBER = 9;
    private com.google.protobuf.LazyStringList repositories_;
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return A list containing the repositories.
     */
    public com.google.protobuf.ProtocolStringList
        getRepositoriesList() {
      return repositories_;
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @return The count of repositories.
     */
    public int getRepositoriesCount() {
      return repositories_.size();
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the element to return.
     * @return The repositories at the given index.
     */
    public java.lang.String getRepositories(int index) {
      return repositories_.get(index);
    }
    /**
     * <pre>
     * List of additional remote repositories to search for the maven coordinates given with --packages.
     * </pre>
     *
     * <code>repeated string repositories = 9;</code>
     * @param index The index of the value to return.
     * @return The bytes of the repositories at the given index.
     */
    public com.google.protobuf.ByteString
        getRepositoriesBytes(int index) {
      return repositories_.getByteString(index);
    }

    public static final int EXCLUDE_PACKAGES_FIELD_NUMBER = 10;
    private com.google.protobuf.LazyStringList excludePackages_;
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return A list containing the excludePackages.
     */
    public com.google.protobuf.ProtocolStringList
        getExcludePackagesList() {
      return excludePackages_;
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @return The count of excludePackages.
     */
    public int getExcludePackagesCount() {
      return excludePackages_.size();
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the element to return.
     * @return The excludePackages at the given index.
     */
    public java.lang.String getExcludePackages(int index) {
      return excludePackages_.get(index);
    }
    /**
     * <pre>
     * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
     * </pre>
     *
     * <code>repeated string exclude_packages = 10;</code>
     * @param index The index of the value to return.
     * @return The bytes of the excludePackages at the given index.
     */
    public com.google.protobuf.ByteString
        getExcludePackagesBytes(int index) {
      return excludePackages_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < args_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, args_.getRaw(i));
      }
      for (int i = 0; i < jarFileUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, jarFileUris_.getRaw(i));
      }
      for (int i = 0; i < fileUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, fileUris_.getRaw(i));
      }
      for (int i = 0; i < archiveUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, archiveUris_.getRaw(i));
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetProperties(),
          PropertiesDefaultEntryHolder.defaultEntry,
          5);
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainPythonFileUri_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, mainPythonFileUri_);
      }
      for (int i = 0; i < pythonFileUris_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 7, pythonFileUris_.getRaw(i));
      }
      for (int i = 0; i < packages_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, packages_.getRaw(i));
      }
      for (int i = 0; i < repositories_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, repositories_.getRaw(i));
      }
      for (int i = 0; i < excludePackages_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, excludePackages_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < args_.size(); i++) {
          dataSize += computeStringSizeNoTag(args_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getArgsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < jarFileUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(jarFileUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getJarFileUrisList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < fileUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(fileUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getFileUrisList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < archiveUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(archiveUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getArchiveUrisList().size();
      }
      for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
           : internalGetProperties().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
        properties__ = PropertiesDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(5, properties__);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(mainPythonFileUri_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, mainPythonFileUri_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < pythonFileUris_.size(); i++) {
          dataSize += computeStringSizeNoTag(pythonFileUris_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getPythonFileUrisList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < packages_.size(); i++) {
          dataSize += computeStringSizeNoTag(packages_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getPackagesList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < repositories_.size(); i++) {
          dataSize += computeStringSizeNoTag(repositories_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getRepositoriesList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < excludePackages_.size(); i++) {
          dataSize += computeStringSizeNoTag(excludePackages_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getExcludePackagesList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob)) {
        return super.equals(obj);
      }
      yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob other = (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) obj;

      if (!getArgsList()
          .equals(other.getArgsList())) return false;
      if (!getJarFileUrisList()
          .equals(other.getJarFileUrisList())) return false;
      if (!getFileUrisList()
          .equals(other.getFileUrisList())) return false;
      if (!getArchiveUrisList()
          .equals(other.getArchiveUrisList())) return false;
      if (!internalGetProperties().equals(
          other.internalGetProperties())) return false;
      if (!getMainPythonFileUri()
          .equals(other.getMainPythonFileUri())) return false;
      if (!getPythonFileUrisList()
          .equals(other.getPythonFileUrisList())) return false;
      if (!getPackagesList()
          .equals(other.getPackagesList())) return false;
      if (!getRepositoriesList()
          .equals(other.getRepositoriesList())) return false;
      if (!getExcludePackagesList()
          .equals(other.getExcludePackagesList())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getArgsCount() > 0) {
        hash = (37 * hash) + ARGS_FIELD_NUMBER;
        hash = (53 * hash) + getArgsList().hashCode();
      }
      if (getJarFileUrisCount() > 0) {
        hash = (37 * hash) + JAR_FILE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getJarFileUrisList().hashCode();
      }
      if (getFileUrisCount() > 0) {
        hash = (37 * hash) + FILE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getFileUrisList().hashCode();
      }
      if (getArchiveUrisCount() > 0) {
        hash = (37 * hash) + ARCHIVE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getArchiveUrisList().hashCode();
      }
      if (!internalGetProperties().getMap().isEmpty()) {
        hash = (37 * hash) + PROPERTIES_FIELD_NUMBER;
        hash = (53 * hash) + internalGetProperties().hashCode();
      }
      hash = (37 * hash) + MAIN_PYTHON_FILE_URI_FIELD_NUMBER;
      hash = (53 * hash) + getMainPythonFileUri().hashCode();
      if (getPythonFileUrisCount() > 0) {
        hash = (37 * hash) + PYTHON_FILE_URIS_FIELD_NUMBER;
        hash = (53 * hash) + getPythonFileUrisList().hashCode();
      }
      if (getPackagesCount() > 0) {
        hash = (37 * hash) + PACKAGES_FIELD_NUMBER;
        hash = (53 * hash) + getPackagesList().hashCode();
      }
      if (getRepositoriesCount() > 0) {
        hash = (37 * hash) + REPOSITORIES_FIELD_NUMBER;
        hash = (53 * hash) + getRepositoriesList().hashCode();
      }
      if (getExcludePackagesCount() > 0) {
        hash = (37 * hash) + EXCLUDE_PACKAGES_FIELD_NUMBER;
        hash = (53 * hash) + getExcludePackagesList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.spark.v1.PysparkJob}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.spark.v1.PysparkJob)
        yandex.cloud.api.spark.v1.JobOuterClass.PysparkJobOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 5:
            return internalGetProperties();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 5:
            return internalGetMutableProperties();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.class, yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.Builder.class);
      }

      // Construct using yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        internalGetMutableProperties().clear();
        mainPythonFileUri_ = "";

        pythonFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000040);
        repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getDefaultInstanceForType() {
        return yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob build() {
        yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob buildPartial() {
        yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob result = new yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) != 0)) {
          args_ = args_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.args_ = args_;
        if (((bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = jarFileUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.jarFileUris_ = jarFileUris_;
        if (((bitField0_ & 0x00000004) != 0)) {
          fileUris_ = fileUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.fileUris_ = fileUris_;
        if (((bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = archiveUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.archiveUris_ = archiveUris_;
        result.properties_ = internalGetProperties();
        result.properties_.makeImmutable();
        result.mainPythonFileUri_ = mainPythonFileUri_;
        if (((bitField0_ & 0x00000020) != 0)) {
          pythonFileUris_ = pythonFileUris_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000020);
        }
        result.pythonFileUris_ = pythonFileUris_;
        if (((bitField0_ & 0x00000040) != 0)) {
          packages_ = packages_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000040);
        }
        result.packages_ = packages_;
        if (((bitField0_ & 0x00000080) != 0)) {
          repositories_ = repositories_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000080);
        }
        result.repositories_ = repositories_;
        if (((bitField0_ & 0x00000100) != 0)) {
          excludePackages_ = excludePackages_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000100);
        }
        result.excludePackages_ = excludePackages_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) {
          return mergeFrom((yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob other) {
        if (other == yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob.getDefaultInstance()) return this;
        if (!other.args_.isEmpty()) {
          if (args_.isEmpty()) {
            args_ = other.args_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureArgsIsMutable();
            args_.addAll(other.args_);
          }
          onChanged();
        }
        if (!other.jarFileUris_.isEmpty()) {
          if (jarFileUris_.isEmpty()) {
            jarFileUris_ = other.jarFileUris_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureJarFileUrisIsMutable();
            jarFileUris_.addAll(other.jarFileUris_);
          }
          onChanged();
        }
        if (!other.fileUris_.isEmpty()) {
          if (fileUris_.isEmpty()) {
            fileUris_ = other.fileUris_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureFileUrisIsMutable();
            fileUris_.addAll(other.fileUris_);
          }
          onChanged();
        }
        if (!other.archiveUris_.isEmpty()) {
          if (archiveUris_.isEmpty()) {
            archiveUris_ = other.archiveUris_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureArchiveUrisIsMutable();
            archiveUris_.addAll(other.archiveUris_);
          }
          onChanged();
        }
        internalGetMutableProperties().mergeFrom(
            other.internalGetProperties());
        if (!other.getMainPythonFileUri().isEmpty()) {
          mainPythonFileUri_ = other.mainPythonFileUri_;
          onChanged();
        }
        if (!other.pythonFileUris_.isEmpty()) {
          if (pythonFileUris_.isEmpty()) {
            pythonFileUris_ = other.pythonFileUris_;
            bitField0_ = (bitField0_ & ~0x00000020);
          } else {
            ensurePythonFileUrisIsMutable();
            pythonFileUris_.addAll(other.pythonFileUris_);
          }
          onChanged();
        }
        if (!other.packages_.isEmpty()) {
          if (packages_.isEmpty()) {
            packages_ = other.packages_;
            bitField0_ = (bitField0_ & ~0x00000040);
          } else {
            ensurePackagesIsMutable();
            packages_.addAll(other.packages_);
          }
          onChanged();
        }
        if (!other.repositories_.isEmpty()) {
          if (repositories_.isEmpty()) {
            repositories_ = other.repositories_;
            bitField0_ = (bitField0_ & ~0x00000080);
          } else {
            ensureRepositoriesIsMutable();
            repositories_.addAll(other.repositories_);
          }
          onChanged();
        }
        if (!other.excludePackages_.isEmpty()) {
          if (excludePackages_.isEmpty()) {
            excludePackages_ = other.excludePackages_;
            bitField0_ = (bitField0_ & ~0x00000100);
          } else {
            ensureExcludePackagesIsMutable();
            excludePackages_.addAll(other.excludePackages_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureArgsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          args_ = new com.google.protobuf.LazyStringArrayList(args_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return A list containing the args.
       */
      public com.google.protobuf.ProtocolStringList
          getArgsList() {
        return args_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return The count of args.
       */
      public int getArgsCount() {
        return args_.size();
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index of the element to return.
       * @return The args at the given index.
       */
      public java.lang.String getArgs(int index) {
        return args_.get(index);
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the args at the given index.
       */
      public com.google.protobuf.ByteString
          getArgsBytes(int index) {
        return args_.getByteString(index);
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param index The index to set the value at.
       * @param value The args to set.
       * @return This builder for chaining.
       */
      public Builder setArgs(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArgsIsMutable();
        args_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param value The args to add.
       * @return This builder for chaining.
       */
      public Builder addArgs(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArgsIsMutable();
        args_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param values The args to add.
       * @return This builder for chaining.
       */
      public Builder addAllArgs(
          java.lang.Iterable<java.lang.String> values) {
        ensureArgsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, args_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearArgs() {
        args_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Optional arguments to pass to the driver.
       * </pre>
       *
       * <code>repeated string args = 1;</code>
       * @param value The bytes of the args to add.
       * @return This builder for chaining.
       */
      public Builder addArgsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureArgsIsMutable();
        args_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureJarFileUrisIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          jarFileUris_ = new com.google.protobuf.LazyStringArrayList(jarFileUris_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return A list containing the jarFileUris.
       */
      public com.google.protobuf.ProtocolStringList
          getJarFileUrisList() {
        return jarFileUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return The count of jarFileUris.
       */
      public int getJarFileUrisCount() {
        return jarFileUris_.size();
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index of the element to return.
       * @return The jarFileUris at the given index.
       */
      public java.lang.String getJarFileUris(int index) {
        return jarFileUris_.get(index);
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index of the value to return.
       * @return The bytes of the jarFileUris at the given index.
       */
      public com.google.protobuf.ByteString
          getJarFileUrisBytes(int index) {
        return jarFileUris_.getByteString(index);
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param index The index to set the value at.
       * @param value The jarFileUris to set.
       * @return This builder for chaining.
       */
      public Builder setJarFileUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureJarFileUrisIsMutable();
        jarFileUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param value The jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addJarFileUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureJarFileUrisIsMutable();
        jarFileUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param values The jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllJarFileUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureJarFileUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, jarFileUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearJarFileUris() {
        jarFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Jar file URIs to add to the CLASSPATHs of the Spark driver and tasks.
       * </pre>
       *
       * <code>repeated string jar_file_uris = 2;</code>
       * @param value The bytes of the jarFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addJarFileUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureJarFileUrisIsMutable();
        jarFileUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureFileUrisIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          fileUris_ = new com.google.protobuf.LazyStringArrayList(fileUris_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return A list containing the fileUris.
       */
      public com.google.protobuf.ProtocolStringList
          getFileUrisList() {
        return fileUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return The count of fileUris.
       */
      public int getFileUrisCount() {
        return fileUris_.size();
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index of the element to return.
       * @return The fileUris at the given index.
       */
      public java.lang.String getFileUris(int index) {
        return fileUris_.get(index);
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index of the value to return.
       * @return The bytes of the fileUris at the given index.
       */
      public com.google.protobuf.ByteString
          getFileUrisBytes(int index) {
        return fileUris_.getByteString(index);
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param index The index to set the value at.
       * @param value The fileUris to set.
       * @return This builder for chaining.
       */
      public Builder setFileUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFileUrisIsMutable();
        fileUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param value The fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addFileUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureFileUrisIsMutable();
        fileUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param values The fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllFileUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureFileUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, fileUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearFileUris() {
        fileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of files to be copied to the working directory of Spark drivers and distributed tasks.
       * </pre>
       *
       * <code>repeated string file_uris = 3;</code>
       * @param value The bytes of the fileUris to add.
       * @return This builder for chaining.
       */
      public Builder addFileUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureFileUrisIsMutable();
        fileUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureArchiveUrisIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          archiveUris_ = new com.google.protobuf.LazyStringArrayList(archiveUris_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return A list containing the archiveUris.
       */
      public com.google.protobuf.ProtocolStringList
          getArchiveUrisList() {
        return archiveUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return The count of archiveUris.
       */
      public int getArchiveUrisCount() {
        return archiveUris_.size();
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index of the element to return.
       * @return The archiveUris at the given index.
       */
      public java.lang.String getArchiveUris(int index) {
        return archiveUris_.get(index);
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index of the value to return.
       * @return The bytes of the archiveUris at the given index.
       */
      public com.google.protobuf.ByteString
          getArchiveUrisBytes(int index) {
        return archiveUris_.getByteString(index);
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param index The index to set the value at.
       * @param value The archiveUris to set.
       * @return This builder for chaining.
       */
      public Builder setArchiveUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArchiveUrisIsMutable();
        archiveUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param value The archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addArchiveUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureArchiveUrisIsMutable();
        archiveUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param values The archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllArchiveUris(
          java.lang.Iterable<java.lang.String> values) {
        ensureArchiveUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, archiveUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearArchiveUris() {
        archiveUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of archives to be extracted in the working directory of Spark drivers and tasks.
       * </pre>
       *
       * <code>repeated string archive_uris = 4;</code>
       * @param value The bytes of the archiveUris to add.
       * @return This builder for chaining.
       */
      public Builder addArchiveUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureArchiveUrisIsMutable();
        archiveUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, java.lang.String> properties_;
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetProperties() {
        if (properties_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              PropertiesDefaultEntryHolder.defaultEntry);
        }
        return properties_;
      }
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetMutableProperties() {
        onChanged();;
        if (properties_ == null) {
          properties_ = com.google.protobuf.MapField.newMapField(
              PropertiesDefaultEntryHolder.defaultEntry);
        }
        if (!properties_.isMutable()) {
          properties_ = properties_.copy();
        }
        return properties_;
      }

      public int getPropertiesCount() {
        return internalGetProperties().getMap().size();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      @java.lang.Override
      public boolean containsProperties(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        return internalGetProperties().getMap().containsKey(key);
      }
      /**
       * Use {@link #getPropertiesMap()} instead.
       */
      @java.lang.Override
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String> getProperties() {
        return getPropertiesMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.util.Map<java.lang.String, java.lang.String> getPropertiesMap() {
        return internalGetProperties().getMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.lang.String getPropertiesOrDefault(
          java.lang.String key,
          java.lang.String defaultValue) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetProperties().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      @java.lang.Override

      public java.lang.String getPropertiesOrThrow(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetProperties().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearProperties() {
        internalGetMutableProperties().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      public Builder removeProperties(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        internalGetMutableProperties().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String>
      getMutableProperties() {
        return internalGetMutableProperties().getMutableMap();
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */
      public Builder putProperties(
          java.lang.String key,
          java.lang.String value) {
        if (key == null) { throw new NullPointerException("map key"); }
        if (value == null) {
  throw new NullPointerException("map value");
}

        internalGetMutableProperties().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       * A mapping of property names to values, used to configure Spark.
       * </pre>
       *
       * <code>map&lt;string, string&gt; properties = 5;</code>
       */

      public Builder putAllProperties(
          java.util.Map<java.lang.String, java.lang.String> values) {
        internalGetMutableProperties().getMutableMap()
            .putAll(values);
        return this;
      }

      private java.lang.Object mainPythonFileUri_ = "";
      /**
       * <pre>
       * URI of the main Python file to use as the driver. Must be a .py file.
       * </pre>
       *
       * <code>string main_python_file_uri = 6;</code>
       * @return The mainPythonFileUri.
       */
      public java.lang.String getMainPythonFileUri() {
        java.lang.Object ref = mainPythonFileUri_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          mainPythonFileUri_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * URI of the main Python file to use as the driver. Must be a .py file.
       * </pre>
       *
       * <code>string main_python_file_uri = 6;</code>
       * @return The bytes for mainPythonFileUri.
       */
      public com.google.protobuf.ByteString
          getMainPythonFileUriBytes() {
        java.lang.Object ref = mainPythonFileUri_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          mainPythonFileUri_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * URI of the main Python file to use as the driver. Must be a .py file.
       * </pre>
       *
       * <code>string main_python_file_uri = 6;</code>
       * @param value The mainPythonFileUri to set.
       * @return This builder for chaining.
       */
      public Builder setMainPythonFileUri(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        mainPythonFileUri_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URI of the main Python file to use as the driver. Must be a .py file.
       * </pre>
       *
       * <code>string main_python_file_uri = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearMainPythonFileUri() {
        
        mainPythonFileUri_ = getDefaultInstance().getMainPythonFileUri();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URI of the main Python file to use as the driver. Must be a .py file.
       * </pre>
       *
       * <code>string main_python_file_uri = 6;</code>
       * @param value The bytes for mainPythonFileUri to set.
       * @return This builder for chaining.
       */
      public Builder setMainPythonFileUriBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        mainPythonFileUri_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList pythonFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensurePythonFileUrisIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          pythonFileUris_ = new com.google.protobuf.LazyStringArrayList(pythonFileUris_);
          bitField0_ |= 0x00000020;
         }
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @return A list containing the pythonFileUris.
       */
      public com.google.protobuf.ProtocolStringList
          getPythonFileUrisList() {
        return pythonFileUris_.getUnmodifiableView();
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @return The count of pythonFileUris.
       */
      public int getPythonFileUrisCount() {
        return pythonFileUris_.size();
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param index The index of the element to return.
       * @return The pythonFileUris at the given index.
       */
      public java.lang.String getPythonFileUris(int index) {
        return pythonFileUris_.get(index);
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param index The index of the value to return.
       * @return The bytes of the pythonFileUris at the given index.
       */
      public com.google.protobuf.ByteString
          getPythonFileUrisBytes(int index) {
        return pythonFileUris_.getByteString(index);
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param index The index to set the value at.
       * @param value The pythonFileUris to set.
       * @return This builder for chaining.
       */
      public Builder setPythonFileUris(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePythonFileUrisIsMutable();
        pythonFileUris_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param value The pythonFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addPythonFileUris(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePythonFileUrisIsMutable();
        pythonFileUris_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param values The pythonFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addAllPythonFileUris(
          java.lang.Iterable<java.lang.String> values) {
        ensurePythonFileUrisIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, pythonFileUris_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearPythonFileUris() {
        pythonFileUris_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * URIs of Python files to pass to the PySpark framework.
       * </pre>
       *
       * <code>repeated string python_file_uris = 7;</code>
       * @param value The bytes of the pythonFileUris to add.
       * @return This builder for chaining.
       */
      public Builder addPythonFileUrisBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensurePythonFileUrisIsMutable();
        pythonFileUris_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensurePackagesIsMutable() {
        if (!((bitField0_ & 0x00000040) != 0)) {
          packages_ = new com.google.protobuf.LazyStringArrayList(packages_);
          bitField0_ |= 0x00000040;
         }
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return A list containing the packages.
       */
      public com.google.protobuf.ProtocolStringList
          getPackagesList() {
        return packages_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return The count of packages.
       */
      public int getPackagesCount() {
        return packages_.size();
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index of the element to return.
       * @return The packages at the given index.
       */
      public java.lang.String getPackages(int index) {
        return packages_.get(index);
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index of the value to return.
       * @return The bytes of the packages at the given index.
       */
      public com.google.protobuf.ByteString
          getPackagesBytes(int index) {
        return packages_.getByteString(index);
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param index The index to set the value at.
       * @param value The packages to set.
       * @return This builder for chaining.
       */
      public Builder setPackages(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePackagesIsMutable();
        packages_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param value The packages to add.
       * @return This builder for chaining.
       */
      public Builder addPackages(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensurePackagesIsMutable();
        packages_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param values The packages to add.
       * @return This builder for chaining.
       */
      public Builder addAllPackages(
          java.lang.Iterable<java.lang.String> values) {
        ensurePackagesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, packages_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearPackages() {
        packages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000040);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of maven coordinates of jars to include on the driver and executor classpaths.
       * </pre>
       *
       * <code>repeated string packages = 8;</code>
       * @param value The bytes of the packages to add.
       * @return This builder for chaining.
       */
      public Builder addPackagesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensurePackagesIsMutable();
        packages_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureRepositoriesIsMutable() {
        if (!((bitField0_ & 0x00000080) != 0)) {
          repositories_ = new com.google.protobuf.LazyStringArrayList(repositories_);
          bitField0_ |= 0x00000080;
         }
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return A list containing the repositories.
       */
      public com.google.protobuf.ProtocolStringList
          getRepositoriesList() {
        return repositories_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return The count of repositories.
       */
      public int getRepositoriesCount() {
        return repositories_.size();
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index of the element to return.
       * @return The repositories at the given index.
       */
      public java.lang.String getRepositories(int index) {
        return repositories_.get(index);
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index of the value to return.
       * @return The bytes of the repositories at the given index.
       */
      public com.google.protobuf.ByteString
          getRepositoriesBytes(int index) {
        return repositories_.getByteString(index);
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param index The index to set the value at.
       * @param value The repositories to set.
       * @return This builder for chaining.
       */
      public Builder setRepositories(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRepositoriesIsMutable();
        repositories_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param value The repositories to add.
       * @return This builder for chaining.
       */
      public Builder addRepositories(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRepositoriesIsMutable();
        repositories_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param values The repositories to add.
       * @return This builder for chaining.
       */
      public Builder addAllRepositories(
          java.lang.Iterable<java.lang.String> values) {
        ensureRepositoriesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, repositories_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearRepositories() {
        repositories_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of additional remote repositories to search for the maven coordinates given with --packages.
       * </pre>
       *
       * <code>repeated string repositories = 9;</code>
       * @param value The bytes of the repositories to add.
       * @return This builder for chaining.
       */
      public Builder addRepositoriesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureRepositoriesIsMutable();
        repositories_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureExcludePackagesIsMutable() {
        if (!((bitField0_ & 0x00000100) != 0)) {
          excludePackages_ = new com.google.protobuf.LazyStringArrayList(excludePackages_);
          bitField0_ |= 0x00000100;
         }
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return A list containing the excludePackages.
       */
      public com.google.protobuf.ProtocolStringList
          getExcludePackagesList() {
        return excludePackages_.getUnmodifiableView();
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return The count of excludePackages.
       */
      public int getExcludePackagesCount() {
        return excludePackages_.size();
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index of the element to return.
       * @return The excludePackages at the given index.
       */
      public java.lang.String getExcludePackages(int index) {
        return excludePackages_.get(index);
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index of the value to return.
       * @return The bytes of the excludePackages at the given index.
       */
      public com.google.protobuf.ByteString
          getExcludePackagesBytes(int index) {
        return excludePackages_.getByteString(index);
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param index The index to set the value at.
       * @param value The excludePackages to set.
       * @return This builder for chaining.
       */
      public Builder setExcludePackages(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureExcludePackagesIsMutable();
        excludePackages_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param value The excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePackages(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureExcludePackagesIsMutable();
        excludePackages_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param values The excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addAllExcludePackages(
          java.lang.Iterable<java.lang.String> values) {
        ensureExcludePackagesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, excludePackages_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @return This builder for chaining.
       */
      public Builder clearExcludePackages() {
        excludePackages_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000100);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * List of groupId:artifactId, to exclude while resolving the dependencies provided in --packages to avoid dependency conflicts.
       * </pre>
       *
       * <code>repeated string exclude_packages = 10;</code>
       * @param value The bytes of the excludePackages to add.
       * @return This builder for chaining.
       */
      public Builder addExcludePackagesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureExcludePackagesIsMutable();
        excludePackages_.add(value);
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.spark.v1.PysparkJob)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.spark.v1.PysparkJob)
    private static final yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob();
    }

    public static yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<PysparkJob>
        PARSER = new com.google.protobuf.AbstractParser<PysparkJob>() {
      @java.lang.Override
      public PysparkJob parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new PysparkJob(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PysparkJob> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PysparkJob> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.spark.v1.JobOuterClass.PysparkJob getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_Job_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_Job_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ApplicationAttempt_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_ApplicationInfo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_SparkJob_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_SparkJob_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_PysparkJob_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\037yandex/cloud/spark/v1/job.proto\022\025yande" +
      "x.cloud.spark.v1\032\037google/protobuf/timest" +
      "amp.proto\"\334\004\n\003Job\022\n\n\002id\030\001 \001(\t\022\022\n\ncluster" +
      "_id\030\002 \001(\t\022.\n\ncreated_at\030\003 \001(\0132\032.google.p" +
      "rotobuf.Timestamp\022.\n\nstarted_at\030\004 \001(\0132\032." +
      "google.protobuf.Timestamp\022/\n\013finished_at" +
      "\030\005 \001(\0132\032.google.protobuf.Timestamp\022\014\n\004na" +
      "me\030\006 \001(\t\022\022\n\ncreated_by\030\007 \001(\t\0221\n\006status\030\010" +
      " \001(\0162!.yandex.cloud.spark.v1.Job.Status\022" +
      "4\n\tspark_job\030\t \001(\0132\037.yandex.cloud.spark." +
      "v1.SparkJobH\000\0228\n\013pyspark_job\030\n \001(\0132!.yan" +
      "dex.cloud.spark.v1.PysparkJobH\000\022@\n\020appli" +
      "cation_info\030\013 \001(\0132&.yandex.cloud.spark.v" +
      "1.ApplicationInfo\022\016\n\006ui_url\030\014 \001(\t\"\200\001\n\006St" +
      "atus\022\026\n\022STATUS_UNSPECIFIED\020\000\022\020\n\014PROVISIO" +
      "NING\020\001\022\013\n\007PENDING\020\002\022\013\n\007RUNNING\020\003\022\t\n\005ERRO" +
      "R\020\004\022\010\n\004DONE\020\005\022\r\n\tCANCELLED\020\006\022\016\n\nCANCELLI" +
      "NG\020\007B\n\n\010job_spec\"9\n\022ApplicationAttempt\022\n" +
      "\n\002id\030\001 \001(\t\022\027\n\017am_container_id\030\002 \001(\t\"f\n\017A" +
      "pplicationInfo\022\n\n\002id\030\001 \001(\t\022G\n\024applicatio" +
      "n_attempts\030\002 \003(\0132).yandex.cloud.spark.v1" +
      ".ApplicationAttempt\"\301\002\n\010SparkJob\022\014\n\004args" +
      "\030\001 \003(\t\022\025\n\rjar_file_uris\030\002 \003(\t\022\021\n\tfile_ur" +
      "is\030\003 \003(\t\022\024\n\014archive_uris\030\004 \003(\t\022C\n\nproper" +
      "ties\030\005 \003(\0132/.yandex.cloud.spark.v1.Spark" +
      "Job.PropertiesEntry\022\031\n\021main_jar_file_uri" +
      "\030\006 \001(\t\022\022\n\nmain_class\030\007 \001(\t\022\020\n\010packages\030\010" +
      " \003(\t\022\024\n\014repositories\030\t \003(\t\022\030\n\020exclude_pa" +
      "ckages\030\n \003(\t\0321\n\017PropertiesEntry\022\013\n\003key\030\001" +
      " \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\"\316\002\n\nPysparkJob\022\014" +
      "\n\004args\030\001 \003(\t\022\025\n\rjar_file_uris\030\002 \003(\t\022\021\n\tf" +
      "ile_uris\030\003 \003(\t\022\024\n\014archive_uris\030\004 \003(\t\022E\n\n" +
      "properties\030\005 \003(\01321.yandex.cloud.spark.v1" +
      ".PysparkJob.PropertiesEntry\022\034\n\024main_pyth" +
      "on_file_uri\030\006 \001(\t\022\030\n\020python_file_uris\030\007 " +
      "\003(\t\022\020\n\010packages\030\010 \003(\t\022\024\n\014repositories\030\t " +
      "\003(\t\022\030\n\020exclude_packages\030\n \003(\t\0321\n\017Propert" +
      "iesEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001" +
      "B\\\n\031yandex.cloud.api.spark.v1Z?github.co" +
      "m/yandex-cloud/go-genproto/yandex/cloud/" +
      "spark/v1;sparkb\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.TimestampProto.getDescriptor(),
        });
    internal_static_yandex_cloud_spark_v1_Job_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_yandex_cloud_spark_v1_Job_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_Job_descriptor,
        new java.lang.String[] { "Id", "ClusterId", "CreatedAt", "StartedAt", "FinishedAt", "Name", "CreatedBy", "Status", "SparkJob", "PysparkJob", "ApplicationInfo", "UiUrl", "JobSpec", });
    internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_yandex_cloud_spark_v1_ApplicationAttempt_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ApplicationAttempt_descriptor,
        new java.lang.String[] { "Id", "AmContainerId", });
    internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_yandex_cloud_spark_v1_ApplicationInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_ApplicationInfo_descriptor,
        new java.lang.String[] { "Id", "ApplicationAttempts", });
    internal_static_yandex_cloud_spark_v1_SparkJob_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_yandex_cloud_spark_v1_SparkJob_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_SparkJob_descriptor,
        new java.lang.String[] { "Args", "JarFileUris", "FileUris", "ArchiveUris", "Properties", "MainJarFileUri", "MainClass", "Packages", "Repositories", "ExcludePackages", });
    internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_descriptor =
      internal_static_yandex_cloud_spark_v1_SparkJob_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_SparkJob_PropertiesEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_yandex_cloud_spark_v1_PysparkJob_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor,
        new java.lang.String[] { "Args", "JarFileUris", "FileUris", "ArchiveUris", "Properties", "MainPythonFileUri", "PythonFileUris", "Packages", "Repositories", "ExcludePackages", });
    internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_descriptor =
      internal_static_yandex_cloud_spark_v1_PysparkJob_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_spark_v1_PysparkJob_PropertiesEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    com.google.protobuf.TimestampProto.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
