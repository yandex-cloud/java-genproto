// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yandex/cloud/mdb/kafka/v1/cluster.proto

package yandex.cloud.api.mdb.kafka.v1;

public final class ClusterOuterClass {
  private ClusterOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface ClusterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Cluster)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    java.lang.String getId();
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    com.google.protobuf.ByteString
        getIdBytes();

    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     * @return The folderId.
     */
    java.lang.String getFolderId();
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     * @return The bytes for folderId.
     */
    com.google.protobuf.ByteString
        getFolderIdBytes();

    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return Whether the createdAt field is set.
     */
    boolean hasCreatedAt();
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return The createdAt.
     */
    com.google.protobuf.Timestamp getCreatedAt();
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder();

    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     * @return The description.
     */
    java.lang.String getDescription();
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     * @return The bytes for description.
     */
    com.google.protobuf.ByteString
        getDescriptionBytes();

    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    int getLabelsCount();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    boolean containsLabels(
        java.lang.String key);
    /**
     * Use {@link #getLabelsMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, java.lang.String>
    getLabels();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    java.util.Map<java.lang.String, java.lang.String>
    getLabelsMap();
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    java.lang.String getLabelsOrDefault(
        java.lang.String key,
        java.lang.String defaultValue);
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    java.lang.String getLabelsOrThrow(
        java.lang.String key);

    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     * @return The enum numeric value on the wire for environment.
     */
    int getEnvironmentValue();
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     * @return The environment.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment();

    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> 
        getMonitoringList();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index);
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    int getMonitoringCount();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
        getMonitoringOrBuilderList();
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
        int index);

    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     * @return Whether the config field is set.
     */
    boolean hasConfig();
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     * @return The config.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig();
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     * @return The networkId.
     */
    java.lang.String getNetworkId();
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     * @return The bytes for networkId.
     */
    com.google.protobuf.ByteString
        getNetworkIdBytes();

    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     * @return The enum numeric value on the wire for health.
     */
    int getHealthValue();
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     * @return The health.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth();

    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     * @return The enum numeric value on the wire for status.
     */
    int getStatusValue();
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     * @return The status.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus();

    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @return A list containing the securityGroupIds.
     */
    java.util.List<java.lang.String>
        getSecurityGroupIdsList();
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @return The count of securityGroupIds.
     */
    int getSecurityGroupIdsCount();
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @param index The index of the element to return.
     * @return The securityGroupIds at the given index.
     */
    java.lang.String getSecurityGroupIds(int index);
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @param index The index of the value to return.
     * @return The bytes of the securityGroupIds at the given index.
     */
    com.google.protobuf.ByteString
        getSecurityGroupIdsBytes(int index);

    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @return A list containing the hostGroupIds.
     */
    java.util.List<java.lang.String>
        getHostGroupIdsList();
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @return The count of hostGroupIds.
     */
    int getHostGroupIdsCount();
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @param index The index of the element to return.
     * @return The hostGroupIds at the given index.
     */
    java.lang.String getHostGroupIds(int index);
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @param index The index of the value to return.
     * @return The bytes of the hostGroupIds at the given index.
     */
    com.google.protobuf.ByteString
        getHostGroupIdsBytes(int index);

    /**
     * <pre>
     * Deletion Protection inhibits deletion of the cluster
     * </pre>
     *
     * <code>bool deletion_protection = 15;</code>
     * @return The deletionProtection.
     */
    boolean getDeletionProtection();

    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     * @return Whether the maintenanceWindow field is set.
     */
    boolean hasMaintenanceWindow();
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     * @return The maintenanceWindow.
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow();
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder();

    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     * @return Whether the plannedOperation field is set.
     */
    boolean hasPlannedOperation();
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     * @return The plannedOperation.
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation();
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder();
  }
  /**
   * <pre>
   * An Apache Kafka® cluster resource.
   * For more information, see the [Concepts](/docs/managed-kafka/concepts) section of the documentation.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Cluster}
   */
  public static final class Cluster extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Cluster)
      ClusterOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Cluster.newBuilder() to construct.
    private Cluster(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Cluster() {
      id_ = "";
      folderId_ = "";
      name_ = "";
      description_ = "";
      environment_ = 0;
      monitoring_ = java.util.Collections.emptyList();
      networkId_ = "";
      health_ = 0;
      status_ = 0;
      securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Cluster();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Cluster(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              id_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              folderId_ = s;
              break;
            }
            case 26: {
              com.google.protobuf.Timestamp.Builder subBuilder = null;
              if (createdAt_ != null) {
                subBuilder = createdAt_.toBuilder();
              }
              createdAt_ = input.readMessage(com.google.protobuf.Timestamp.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(createdAt_);
                createdAt_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 42: {
              java.lang.String s = input.readStringRequireUtf8();

              description_ = s;
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                labels_ = com.google.protobuf.MapField.newMapField(
                    LabelsDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000001;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
              labels__ = input.readMessage(
                  LabelsDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              labels_.getMutableMap().put(
                  labels__.getKey(), labels__.getValue());
              break;
            }
            case 56: {
              int rawValue = input.readEnum();

              environment_ = rawValue;
              break;
            }
            case 66: {
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                monitoring_ = new java.util.ArrayList<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring>();
                mutable_bitField0_ |= 0x00000002;
              }
              monitoring_.add(
                  input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.parser(), extensionRegistry));
              break;
            }
            case 74: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder subBuilder = null;
              if (config_ != null) {
                subBuilder = config_.toBuilder();
              }
              config_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(config_);
                config_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              java.lang.String s = input.readStringRequireUtf8();

              networkId_ = s;
              break;
            }
            case 88: {
              int rawValue = input.readEnum();

              health_ = rawValue;
              break;
            }
            case 96: {
              int rawValue = input.readEnum();

              status_ = rawValue;
              break;
            }
            case 106: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000004) != 0)) {
                securityGroupIds_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000004;
              }
              securityGroupIds_.add(s);
              break;
            }
            case 114: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000008) != 0)) {
                hostGroupIds_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000008;
              }
              hostGroupIds_.add(s);
              break;
            }
            case 120: {

              deletionProtection_ = input.readBool();
              break;
            }
            case 130: {
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder subBuilder = null;
              if (maintenanceWindow_ != null) {
                subBuilder = maintenanceWindow_.toBuilder();
              }
              maintenanceWindow_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maintenanceWindow_);
                maintenanceWindow_ = subBuilder.buildPartial();
              }

              break;
            }
            case 138: {
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder subBuilder = null;
              if (plannedOperation_ != null) {
                subBuilder = plannedOperation_.toBuilder();
              }
              plannedOperation_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(plannedOperation_);
                plannedOperation_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          monitoring_ = java.util.Collections.unmodifiableList(monitoring_);
        }
        if (((mutable_bitField0_ & 0x00000004) != 0)) {
          securityGroupIds_ = securityGroupIds_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000008) != 0)) {
          hostGroupIds_ = hostGroupIds_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 6:
          return internalGetLabels();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Environment}
     */
    public enum Environment
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>ENVIRONMENT_UNSPECIFIED = 0;</code>
       */
      ENVIRONMENT_UNSPECIFIED(0),
      /**
       * <pre>
       * stable environment with a conservative update policy when only hotfixes are applied during regular maintenance.
       * </pre>
       *
       * <code>PRODUCTION = 1;</code>
       */
      PRODUCTION(1),
      /**
       * <pre>
       * environment with a more aggressive update policy when new versions are rolled out irrespective of backward compatibility.
       * </pre>
       *
       * <code>PRESTABLE = 2;</code>
       */
      PRESTABLE(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>ENVIRONMENT_UNSPECIFIED = 0;</code>
       */
      public static final int ENVIRONMENT_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * stable environment with a conservative update policy when only hotfixes are applied during regular maintenance.
       * </pre>
       *
       * <code>PRODUCTION = 1;</code>
       */
      public static final int PRODUCTION_VALUE = 1;
      /**
       * <pre>
       * environment with a more aggressive update policy when new versions are rolled out irrespective of backward compatibility.
       * </pre>
       *
       * <code>PRESTABLE = 2;</code>
       */
      public static final int PRESTABLE_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Environment valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Environment forNumber(int value) {
        switch (value) {
          case 0: return ENVIRONMENT_UNSPECIFIED;
          case 1: return PRODUCTION;
          case 2: return PRESTABLE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Environment>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Environment> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Environment>() {
              public Environment findValueByNumber(int number) {
                return Environment.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(0);
      }

      private static final Environment[] VALUES = values();

      public static Environment valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Environment(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Environment)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Health}
     */
    public enum Health
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * state of the cluster is unknown ([Host.health] of all hosts in the cluster is `UNKNOWN`).
       * </pre>
       *
       * <code>HEALTH_UNKNOWN = 0;</code>
       */
      HEALTH_UNKNOWN(0),
      /**
       * <pre>
       * cluster is alive and well ([Host.health] of all hosts in the cluster is `ALIVE`).
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      ALIVE(1),
      /**
       * <pre>
       * cluster is inoperable ([Host.health] of all hosts in the cluster is `DEAD`).
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      DEAD(2),
      /**
       * <pre>
       * cluster is in degraded state ([Host.health] of at least one of the hosts in the cluster is not `ALIVE`).
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      DEGRADED(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * state of the cluster is unknown ([Host.health] of all hosts in the cluster is `UNKNOWN`).
       * </pre>
       *
       * <code>HEALTH_UNKNOWN = 0;</code>
       */
      public static final int HEALTH_UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * cluster is alive and well ([Host.health] of all hosts in the cluster is `ALIVE`).
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      public static final int ALIVE_VALUE = 1;
      /**
       * <pre>
       * cluster is inoperable ([Host.health] of all hosts in the cluster is `DEAD`).
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      public static final int DEAD_VALUE = 2;
      /**
       * <pre>
       * cluster is in degraded state ([Host.health] of at least one of the hosts in the cluster is not `ALIVE`).
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      public static final int DEGRADED_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Health valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Health forNumber(int value) {
        switch (value) {
          case 0: return HEALTH_UNKNOWN;
          case 1: return ALIVE;
          case 2: return DEAD;
          case 3: return DEGRADED;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Health>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Health> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Health>() {
              public Health findValueByNumber(int number) {
                return Health.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(1);
      }

      private static final Health[] VALUES = values();

      public static Health valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Health(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Health)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Cluster.Status}
     */
    public enum Status
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * cluster state is unknown.
       * </pre>
       *
       * <code>STATUS_UNKNOWN = 0;</code>
       */
      STATUS_UNKNOWN(0),
      /**
       * <pre>
       * cluster is being created.
       * </pre>
       *
       * <code>CREATING = 1;</code>
       */
      CREATING(1),
      /**
       * <pre>
       * cluster is running normally.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      RUNNING(2),
      /**
       * <pre>
       * cluster encountered a problem and cannot operate.
       * </pre>
       *
       * <code>ERROR = 3;</code>
       */
      ERROR(3),
      /**
       * <pre>
       * cluster is being updated.
       * </pre>
       *
       * <code>UPDATING = 4;</code>
       */
      UPDATING(4),
      /**
       * <pre>
       * cluster is stopping.
       * </pre>
       *
       * <code>STOPPING = 5;</code>
       */
      STOPPING(5),
      /**
       * <pre>
       * cluster stopped.
       * </pre>
       *
       * <code>STOPPED = 6;</code>
       */
      STOPPED(6),
      /**
       * <pre>
       * cluster is starting.
       * </pre>
       *
       * <code>STARTING = 7;</code>
       */
      STARTING(7),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * cluster state is unknown.
       * </pre>
       *
       * <code>STATUS_UNKNOWN = 0;</code>
       */
      public static final int STATUS_UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * cluster is being created.
       * </pre>
       *
       * <code>CREATING = 1;</code>
       */
      public static final int CREATING_VALUE = 1;
      /**
       * <pre>
       * cluster is running normally.
       * </pre>
       *
       * <code>RUNNING = 2;</code>
       */
      public static final int RUNNING_VALUE = 2;
      /**
       * <pre>
       * cluster encountered a problem and cannot operate.
       * </pre>
       *
       * <code>ERROR = 3;</code>
       */
      public static final int ERROR_VALUE = 3;
      /**
       * <pre>
       * cluster is being updated.
       * </pre>
       *
       * <code>UPDATING = 4;</code>
       */
      public static final int UPDATING_VALUE = 4;
      /**
       * <pre>
       * cluster is stopping.
       * </pre>
       *
       * <code>STOPPING = 5;</code>
       */
      public static final int STOPPING_VALUE = 5;
      /**
       * <pre>
       * cluster stopped.
       * </pre>
       *
       * <code>STOPPED = 6;</code>
       */
      public static final int STOPPED_VALUE = 6;
      /**
       * <pre>
       * cluster is starting.
       * </pre>
       *
       * <code>STARTING = 7;</code>
       */
      public static final int STARTING_VALUE = 7;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Status valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Status forNumber(int value) {
        switch (value) {
          case 0: return STATUS_UNKNOWN;
          case 1: return CREATING;
          case 2: return RUNNING;
          case 3: return ERROR;
          case 4: return UPDATING;
          case 5: return STOPPING;
          case 6: return STOPPED;
          case 7: return STARTING;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Status>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Status> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Status>() {
              public Status findValueByNumber(int number) {
                return Status.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDescriptor().getEnumTypes().get(2);
      }

      private static final Status[] VALUES = values();

      public static Status valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Status(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Cluster.Status)
    }

    public static final int ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object id_;
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The id.
     */
    @java.lang.Override
    public java.lang.String getId() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        id_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * This ID is assigned at creation time.
     * </pre>
     *
     * <code>string id = 1;</code>
     * @return The bytes for id.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getIdBytes() {
      java.lang.Object ref = id_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        id_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int FOLDER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object folderId_;
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     * @return The folderId.
     */
    @java.lang.Override
    public java.lang.String getFolderId() {
      java.lang.Object ref = folderId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        folderId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the folder that the Apache Kafka® cluster belongs to.
     * </pre>
     *
     * <code>string folder_id = 2;</code>
     * @return The bytes for folderId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getFolderIdBytes() {
      java.lang.Object ref = folderId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        folderId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CREATED_AT_FIELD_NUMBER = 3;
    private com.google.protobuf.Timestamp createdAt_;
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return Whether the createdAt field is set.
     */
    @java.lang.Override
    public boolean hasCreatedAt() {
      return createdAt_ != null;
    }
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     * @return The createdAt.
     */
    @java.lang.Override
    public com.google.protobuf.Timestamp getCreatedAt() {
      return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
    }
    /**
     * <pre>
     * Creation timestamp.
     * </pre>
     *
     * <code>.google.protobuf.Timestamp created_at = 3;</code>
     */
    @java.lang.Override
    public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
      return getCreatedAt();
    }

    public static final int NAME_FIELD_NUMBER = 4;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the Apache Kafka® cluster.
     * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
     * </pre>
     *
     * <code>string name = 4;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DESCRIPTION_FIELD_NUMBER = 5;
    private volatile java.lang.Object description_;
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     * @return The description.
     */
    @java.lang.Override
    public java.lang.String getDescription() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        description_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Description of the Apache Kafka® cluster. 0-256 characters long.
     * </pre>
     *
     * <code>string description = 5;</code>
     * @return The bytes for description.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getDescriptionBytes() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        description_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LABELS_FIELD_NUMBER = 6;
    private static final class LabelsDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, java.lang.String> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, java.lang.String>newDefaultInstance(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> labels_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetLabels() {
      if (labels_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            LabelsDefaultEntryHolder.defaultEntry);
      }
      return labels_;
    }

    public int getLabelsCount() {
      return internalGetLabels().getMap().size();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */

    @java.lang.Override
    public boolean containsLabels(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetLabels().getMap().containsKey(key);
    }
    /**
     * Use {@link #getLabelsMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getLabels() {
      return getLabelsMap();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
      return internalGetLabels().getMap();
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    @java.lang.Override

    public java.lang.String getLabelsOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetLabels().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
     * A maximum of 64 labels per resource is allowed.
     * </pre>
     *
     * <code>map&lt;string, string&gt; labels = 6;</code>
     */
    @java.lang.Override

    public java.lang.String getLabelsOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetLabels().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int ENVIRONMENT_FIELD_NUMBER = 7;
    private int environment_;
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     * @return The enum numeric value on the wire for environment.
     */
    @java.lang.Override public int getEnvironmentValue() {
      return environment_;
    }
    /**
     * <pre>
     * Deployment environment of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
     * @return The environment.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.valueOf(environment_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.UNRECOGNIZED : result;
    }

    public static final int MONITORING_FIELD_NUMBER = 8;
    private java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> monitoring_;
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    @java.lang.Override
    public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> getMonitoringList() {
      return monitoring_;
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    @java.lang.Override
    public java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
        getMonitoringOrBuilderList() {
      return monitoring_;
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    @java.lang.Override
    public int getMonitoringCount() {
      return monitoring_.size();
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index) {
      return monitoring_.get(index);
    }
    /**
     * <pre>
     * Description of monitoring systems relevant to the Apache Kafka® cluster.
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
        int index) {
      return monitoring_.get(index);
    }

    public static final int CONFIG_FIELD_NUMBER = 9;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec config_;
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     * @return Whether the config field is set.
     */
    @java.lang.Override
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     * @return The config.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig() {
      return config_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Configuration of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder() {
      return getConfig();
    }

    public static final int NETWORK_ID_FIELD_NUMBER = 10;
    private volatile java.lang.Object networkId_;
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     * @return The networkId.
     */
    @java.lang.Override
    public java.lang.String getNetworkId() {
      java.lang.Object ref = networkId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        networkId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the network that the cluster belongs to.
     * </pre>
     *
     * <code>string network_id = 10;</code>
     * @return The bytes for networkId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNetworkIdBytes() {
      java.lang.Object ref = networkId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        networkId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HEALTH_FIELD_NUMBER = 11;
    private int health_;
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     * @return The enum numeric value on the wire for health.
     */
    @java.lang.Override public int getHealthValue() {
      return health_;
    }
    /**
     * <pre>
     * Aggregated cluster health.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
     * @return The health.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.valueOf(health_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.UNRECOGNIZED : result;
    }

    public static final int STATUS_FIELD_NUMBER = 12;
    private int status_;
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     * @return The enum numeric value on the wire for status.
     */
    @java.lang.Override public int getStatusValue() {
      return status_;
    }
    /**
     * <pre>
     * Current state of the cluster.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
     * @return The status.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.valueOf(status_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.UNRECOGNIZED : result;
    }

    public static final int SECURITY_GROUP_IDS_FIELD_NUMBER = 13;
    private com.google.protobuf.LazyStringList securityGroupIds_;
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @return A list containing the securityGroupIds.
     */
    public com.google.protobuf.ProtocolStringList
        getSecurityGroupIdsList() {
      return securityGroupIds_;
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @return The count of securityGroupIds.
     */
    public int getSecurityGroupIdsCount() {
      return securityGroupIds_.size();
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @param index The index of the element to return.
     * @return The securityGroupIds at the given index.
     */
    public java.lang.String getSecurityGroupIds(int index) {
      return securityGroupIds_.get(index);
    }
    /**
     * <pre>
     * User security groups
     * </pre>
     *
     * <code>repeated string security_group_ids = 13;</code>
     * @param index The index of the value to return.
     * @return The bytes of the securityGroupIds at the given index.
     */
    public com.google.protobuf.ByteString
        getSecurityGroupIdsBytes(int index) {
      return securityGroupIds_.getByteString(index);
    }

    public static final int HOST_GROUP_IDS_FIELD_NUMBER = 14;
    private com.google.protobuf.LazyStringList hostGroupIds_;
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @return A list containing the hostGroupIds.
     */
    public com.google.protobuf.ProtocolStringList
        getHostGroupIdsList() {
      return hostGroupIds_;
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @return The count of hostGroupIds.
     */
    public int getHostGroupIdsCount() {
      return hostGroupIds_.size();
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @param index The index of the element to return.
     * @return The hostGroupIds at the given index.
     */
    public java.lang.String getHostGroupIds(int index) {
      return hostGroupIds_.get(index);
    }
    /**
     * <pre>
     * Host groups hosting VMs of the cluster.
     * </pre>
     *
     * <code>repeated string host_group_ids = 14;</code>
     * @param index The index of the value to return.
     * @return The bytes of the hostGroupIds at the given index.
     */
    public com.google.protobuf.ByteString
        getHostGroupIdsBytes(int index) {
      return hostGroupIds_.getByteString(index);
    }

    public static final int DELETION_PROTECTION_FIELD_NUMBER = 15;
    private boolean deletionProtection_;
    /**
     * <pre>
     * Deletion Protection inhibits deletion of the cluster
     * </pre>
     *
     * <code>bool deletion_protection = 15;</code>
     * @return The deletionProtection.
     */
    @java.lang.Override
    public boolean getDeletionProtection() {
      return deletionProtection_;
    }

    public static final int MAINTENANCE_WINDOW_FIELD_NUMBER = 16;
    private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow maintenanceWindow_;
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     * @return Whether the maintenanceWindow field is set.
     */
    @java.lang.Override
    public boolean hasMaintenanceWindow() {
      return maintenanceWindow_ != null;
    }
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     * @return The maintenanceWindow.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow() {
      return maintenanceWindow_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
    }
    /**
     * <pre>
     * Window of maintenance operations.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder() {
      return getMaintenanceWindow();
    }

    public static final int PLANNED_OPERATION_FIELD_NUMBER = 17;
    private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation plannedOperation_;
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     * @return Whether the plannedOperation field is set.
     */
    @java.lang.Override
    public boolean hasPlannedOperation() {
      return plannedOperation_ != null;
    }
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     * @return The plannedOperation.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation() {
      return plannedOperation_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
    }
    /**
     * <pre>
     * Scheduled maintenance operation.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder() {
      return getPlannedOperation();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(folderId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, folderId_);
      }
      if (createdAt_ != null) {
        output.writeMessage(3, getCreatedAt());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(description_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, description_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetLabels(),
          LabelsDefaultEntryHolder.defaultEntry,
          6);
      if (environment_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.ENVIRONMENT_UNSPECIFIED.getNumber()) {
        output.writeEnum(7, environment_);
      }
      for (int i = 0; i < monitoring_.size(); i++) {
        output.writeMessage(8, monitoring_.get(i));
      }
      if (config_ != null) {
        output.writeMessage(9, getConfig());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(networkId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, networkId_);
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.HEALTH_UNKNOWN.getNumber()) {
        output.writeEnum(11, health_);
      }
      if (status_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.STATUS_UNKNOWN.getNumber()) {
        output.writeEnum(12, status_);
      }
      for (int i = 0; i < securityGroupIds_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 13, securityGroupIds_.getRaw(i));
      }
      for (int i = 0; i < hostGroupIds_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 14, hostGroupIds_.getRaw(i));
      }
      if (deletionProtection_ != false) {
        output.writeBool(15, deletionProtection_);
      }
      if (maintenanceWindow_ != null) {
        output.writeMessage(16, getMaintenanceWindow());
      }
      if (plannedOperation_ != null) {
        output.writeMessage(17, getPlannedOperation());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(id_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, id_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(folderId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, folderId_);
      }
      if (createdAt_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCreatedAt());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(description_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, description_);
      }
      for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
           : internalGetLabels().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
        labels__ = LabelsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(6, labels__);
      }
      if (environment_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.ENVIRONMENT_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, environment_);
      }
      for (int i = 0; i < monitoring_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, monitoring_.get(i));
      }
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getConfig());
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(networkId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, networkId_);
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.HEALTH_UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(11, health_);
      }
      if (status_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.STATUS_UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(12, status_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < securityGroupIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(securityGroupIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getSecurityGroupIdsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < hostGroupIds_.size(); i++) {
          dataSize += computeStringSizeNoTag(hostGroupIds_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getHostGroupIdsList().size();
      }
      if (deletionProtection_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(15, deletionProtection_);
      }
      if (maintenanceWindow_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, getMaintenanceWindow());
      }
      if (plannedOperation_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, getPlannedOperation());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) obj;

      if (!getId()
          .equals(other.getId())) return false;
      if (!getFolderId()
          .equals(other.getFolderId())) return false;
      if (hasCreatedAt() != other.hasCreatedAt()) return false;
      if (hasCreatedAt()) {
        if (!getCreatedAt()
            .equals(other.getCreatedAt())) return false;
      }
      if (!getName()
          .equals(other.getName())) return false;
      if (!getDescription()
          .equals(other.getDescription())) return false;
      if (!internalGetLabels().equals(
          other.internalGetLabels())) return false;
      if (environment_ != other.environment_) return false;
      if (!getMonitoringList()
          .equals(other.getMonitoringList())) return false;
      if (hasConfig() != other.hasConfig()) return false;
      if (hasConfig()) {
        if (!getConfig()
            .equals(other.getConfig())) return false;
      }
      if (!getNetworkId()
          .equals(other.getNetworkId())) return false;
      if (health_ != other.health_) return false;
      if (status_ != other.status_) return false;
      if (!getSecurityGroupIdsList()
          .equals(other.getSecurityGroupIdsList())) return false;
      if (!getHostGroupIdsList()
          .equals(other.getHostGroupIdsList())) return false;
      if (getDeletionProtection()
          != other.getDeletionProtection()) return false;
      if (hasMaintenanceWindow() != other.hasMaintenanceWindow()) return false;
      if (hasMaintenanceWindow()) {
        if (!getMaintenanceWindow()
            .equals(other.getMaintenanceWindow())) return false;
      }
      if (hasPlannedOperation() != other.hasPlannedOperation()) return false;
      if (hasPlannedOperation()) {
        if (!getPlannedOperation()
            .equals(other.getPlannedOperation())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ID_FIELD_NUMBER;
      hash = (53 * hash) + getId().hashCode();
      hash = (37 * hash) + FOLDER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getFolderId().hashCode();
      if (hasCreatedAt()) {
        hash = (37 * hash) + CREATED_AT_FIELD_NUMBER;
        hash = (53 * hash) + getCreatedAt().hashCode();
      }
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
      hash = (53 * hash) + getDescription().hashCode();
      if (!internalGetLabels().getMap().isEmpty()) {
        hash = (37 * hash) + LABELS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetLabels().hashCode();
      }
      hash = (37 * hash) + ENVIRONMENT_FIELD_NUMBER;
      hash = (53 * hash) + environment_;
      if (getMonitoringCount() > 0) {
        hash = (37 * hash) + MONITORING_FIELD_NUMBER;
        hash = (53 * hash) + getMonitoringList().hashCode();
      }
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + NETWORK_ID_FIELD_NUMBER;
      hash = (53 * hash) + getNetworkId().hashCode();
      hash = (37 * hash) + HEALTH_FIELD_NUMBER;
      hash = (53 * hash) + health_;
      hash = (37 * hash) + STATUS_FIELD_NUMBER;
      hash = (53 * hash) + status_;
      if (getSecurityGroupIdsCount() > 0) {
        hash = (37 * hash) + SECURITY_GROUP_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getSecurityGroupIdsList().hashCode();
      }
      if (getHostGroupIdsCount() > 0) {
        hash = (37 * hash) + HOST_GROUP_IDS_FIELD_NUMBER;
        hash = (53 * hash) + getHostGroupIdsList().hashCode();
      }
      hash = (37 * hash) + DELETION_PROTECTION_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getDeletionProtection());
      if (hasMaintenanceWindow()) {
        hash = (37 * hash) + MAINTENANCE_WINDOW_FIELD_NUMBER;
        hash = (53 * hash) + getMaintenanceWindow().hashCode();
      }
      if (hasPlannedOperation()) {
        hash = (37 * hash) + PLANNED_OPERATION_FIELD_NUMBER;
        hash = (53 * hash) + getPlannedOperation().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * An Apache Kafka® cluster resource.
     * For more information, see the [Concepts](/docs/managed-kafka/concepts) section of the documentation.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Cluster}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Cluster)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ClusterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 6:
            return internalGetLabels();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 6:
            return internalGetMutableLabels();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getMonitoringFieldBuilder();
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        id_ = "";

        folderId_ = "";

        if (createdAtBuilder_ == null) {
          createdAt_ = null;
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }
        name_ = "";

        description_ = "";

        internalGetMutableLabels().clear();
        environment_ = 0;

        if (monitoringBuilder_ == null) {
          monitoring_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          monitoringBuilder_.clear();
        }
        if (configBuilder_ == null) {
          config_ = null;
        } else {
          config_ = null;
          configBuilder_ = null;
        }
        networkId_ = "";

        health_ = 0;

        status_ = 0;

        securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        deletionProtection_ = false;

        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = null;
        } else {
          maintenanceWindow_ = null;
          maintenanceWindowBuilder_ = null;
        }
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = null;
        } else {
          plannedOperation_ = null;
          plannedOperationBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster(this);
        int from_bitField0_ = bitField0_;
        result.id_ = id_;
        result.folderId_ = folderId_;
        if (createdAtBuilder_ == null) {
          result.createdAt_ = createdAt_;
        } else {
          result.createdAt_ = createdAtBuilder_.build();
        }
        result.name_ = name_;
        result.description_ = description_;
        result.labels_ = internalGetLabels();
        result.labels_.makeImmutable();
        result.environment_ = environment_;
        if (monitoringBuilder_ == null) {
          if (((bitField0_ & 0x00000002) != 0)) {
            monitoring_ = java.util.Collections.unmodifiableList(monitoring_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.monitoring_ = monitoring_;
        } else {
          result.monitoring_ = monitoringBuilder_.build();
        }
        if (configBuilder_ == null) {
          result.config_ = config_;
        } else {
          result.config_ = configBuilder_.build();
        }
        result.networkId_ = networkId_;
        result.health_ = health_;
        result.status_ = status_;
        if (((bitField0_ & 0x00000004) != 0)) {
          securityGroupIds_ = securityGroupIds_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.securityGroupIds_ = securityGroupIds_;
        if (((bitField0_ & 0x00000008) != 0)) {
          hostGroupIds_ = hostGroupIds_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.hostGroupIds_ = hostGroupIds_;
        result.deletionProtection_ = deletionProtection_;
        if (maintenanceWindowBuilder_ == null) {
          result.maintenanceWindow_ = maintenanceWindow_;
        } else {
          result.maintenanceWindow_ = maintenanceWindowBuilder_.build();
        }
        if (plannedOperationBuilder_ == null) {
          result.plannedOperation_ = plannedOperation_;
        } else {
          result.plannedOperation_ = plannedOperationBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.getDefaultInstance()) return this;
        if (!other.getId().isEmpty()) {
          id_ = other.id_;
          onChanged();
        }
        if (!other.getFolderId().isEmpty()) {
          folderId_ = other.folderId_;
          onChanged();
        }
        if (other.hasCreatedAt()) {
          mergeCreatedAt(other.getCreatedAt());
        }
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getDescription().isEmpty()) {
          description_ = other.description_;
          onChanged();
        }
        internalGetMutableLabels().mergeFrom(
            other.internalGetLabels());
        if (other.environment_ != 0) {
          setEnvironmentValue(other.getEnvironmentValue());
        }
        if (monitoringBuilder_ == null) {
          if (!other.monitoring_.isEmpty()) {
            if (monitoring_.isEmpty()) {
              monitoring_ = other.monitoring_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureMonitoringIsMutable();
              monitoring_.addAll(other.monitoring_);
            }
            onChanged();
          }
        } else {
          if (!other.monitoring_.isEmpty()) {
            if (monitoringBuilder_.isEmpty()) {
              monitoringBuilder_.dispose();
              monitoringBuilder_ = null;
              monitoring_ = other.monitoring_;
              bitField0_ = (bitField0_ & ~0x00000002);
              monitoringBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getMonitoringFieldBuilder() : null;
            } else {
              monitoringBuilder_.addAllMessages(other.monitoring_);
            }
          }
        }
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (!other.getNetworkId().isEmpty()) {
          networkId_ = other.networkId_;
          onChanged();
        }
        if (other.health_ != 0) {
          setHealthValue(other.getHealthValue());
        }
        if (other.status_ != 0) {
          setStatusValue(other.getStatusValue());
        }
        if (!other.securityGroupIds_.isEmpty()) {
          if (securityGroupIds_.isEmpty()) {
            securityGroupIds_ = other.securityGroupIds_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureSecurityGroupIdsIsMutable();
            securityGroupIds_.addAll(other.securityGroupIds_);
          }
          onChanged();
        }
        if (!other.hostGroupIds_.isEmpty()) {
          if (hostGroupIds_.isEmpty()) {
            hostGroupIds_ = other.hostGroupIds_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureHostGroupIdsIsMutable();
            hostGroupIds_.addAll(other.hostGroupIds_);
          }
          onChanged();
        }
        if (other.getDeletionProtection() != false) {
          setDeletionProtection(other.getDeletionProtection());
        }
        if (other.hasMaintenanceWindow()) {
          mergeMaintenanceWindow(other.getMaintenanceWindow());
        }
        if (other.hasPlannedOperation()) {
          mergePlannedOperation(other.getPlannedOperation());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object id_ = "";
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The id.
       */
      public java.lang.String getId() {
        java.lang.Object ref = id_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          id_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return The bytes for id.
       */
      public com.google.protobuf.ByteString
          getIdBytes() {
        java.lang.Object ref = id_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          id_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The id to set.
       * @return This builder for chaining.
       */
      public Builder setId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearId() {
        
        id_ = getDefaultInstance().getId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * This ID is assigned at creation time.
       * </pre>
       *
       * <code>string id = 1;</code>
       * @param value The bytes for id to set.
       * @return This builder for chaining.
       */
      public Builder setIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        id_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object folderId_ = "";
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       * @return The folderId.
       */
      public java.lang.String getFolderId() {
        java.lang.Object ref = folderId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          folderId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       * @return The bytes for folderId.
       */
      public com.google.protobuf.ByteString
          getFolderIdBytes() {
        java.lang.Object ref = folderId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          folderId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       * @param value The folderId to set.
       * @return This builder for chaining.
       */
      public Builder setFolderId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        folderId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearFolderId() {
        
        folderId_ = getDefaultInstance().getFolderId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the folder that the Apache Kafka® cluster belongs to.
       * </pre>
       *
       * <code>string folder_id = 2;</code>
       * @param value The bytes for folderId to set.
       * @return This builder for chaining.
       */
      public Builder setFolderIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        folderId_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.Timestamp createdAt_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> createdAtBuilder_;
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       * @return Whether the createdAt field is set.
       */
      public boolean hasCreatedAt() {
        return createdAtBuilder_ != null || createdAt_ != null;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       * @return The createdAt.
       */
      public com.google.protobuf.Timestamp getCreatedAt() {
        if (createdAtBuilder_ == null) {
          return createdAt_ == null ? com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        } else {
          return createdAtBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          createdAt_ = value;
          onChanged();
        } else {
          createdAtBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder setCreatedAt(
          com.google.protobuf.Timestamp.Builder builderForValue) {
        if (createdAtBuilder_ == null) {
          createdAt_ = builderForValue.build();
          onChanged();
        } else {
          createdAtBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder mergeCreatedAt(com.google.protobuf.Timestamp value) {
        if (createdAtBuilder_ == null) {
          if (createdAt_ != null) {
            createdAt_ =
              com.google.protobuf.Timestamp.newBuilder(createdAt_).mergeFrom(value).buildPartial();
          } else {
            createdAt_ = value;
          }
          onChanged();
        } else {
          createdAtBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public Builder clearCreatedAt() {
        if (createdAtBuilder_ == null) {
          createdAt_ = null;
          onChanged();
        } else {
          createdAt_ = null;
          createdAtBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.Timestamp.Builder getCreatedAtBuilder() {
        
        onChanged();
        return getCreatedAtFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      public com.google.protobuf.TimestampOrBuilder getCreatedAtOrBuilder() {
        if (createdAtBuilder_ != null) {
          return createdAtBuilder_.getMessageOrBuilder();
        } else {
          return createdAt_ == null ?
              com.google.protobuf.Timestamp.getDefaultInstance() : createdAt_;
        }
      }
      /**
       * <pre>
       * Creation timestamp.
       * </pre>
       *
       * <code>.google.protobuf.Timestamp created_at = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder> 
          getCreatedAtFieldBuilder() {
        if (createdAtBuilder_ == null) {
          createdAtBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Timestamp, com.google.protobuf.Timestamp.Builder, com.google.protobuf.TimestampOrBuilder>(
                  getCreatedAt(),
                  getParentForChildren(),
                  isClean());
          createdAt_ = null;
        }
        return createdAtBuilder_;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the Apache Kafka® cluster.
       * The name must be unique within the folder. 1-63 characters long. Value must match the regular expression `[a-zA-Z0-9_-]*`.
       * </pre>
       *
       * <code>string name = 4;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object description_ = "";
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       * @return The description.
       */
      public java.lang.String getDescription() {
        java.lang.Object ref = description_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          description_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       * @return The bytes for description.
       */
      public com.google.protobuf.ByteString
          getDescriptionBytes() {
        java.lang.Object ref = description_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          description_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       * @param value The description to set.
       * @return This builder for chaining.
       */
      public Builder setDescription(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        description_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearDescription() {
        
        description_ = getDefaultInstance().getDescription();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the Apache Kafka® cluster. 0-256 characters long.
       * </pre>
       *
       * <code>string description = 5;</code>
       * @param value The bytes for description to set.
       * @return This builder for chaining.
       */
      public Builder setDescriptionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        description_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, java.lang.String> labels_;
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetLabels() {
        if (labels_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              LabelsDefaultEntryHolder.defaultEntry);
        }
        return labels_;
      }
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetMutableLabels() {
        onChanged();;
        if (labels_ == null) {
          labels_ = com.google.protobuf.MapField.newMapField(
              LabelsDefaultEntryHolder.defaultEntry);
        }
        if (!labels_.isMutable()) {
          labels_ = labels_.copy();
        }
        return labels_;
      }

      public int getLabelsCount() {
        return internalGetLabels().getMap().size();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      @java.lang.Override
      public boolean containsLabels(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        return internalGetLabels().getMap().containsKey(key);
      }
      /**
       * Use {@link #getLabelsMap()} instead.
       */
      @java.lang.Override
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String> getLabels() {
        return getLabelsMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */
      @java.lang.Override

      public java.util.Map<java.lang.String, java.lang.String> getLabelsMap() {
        return internalGetLabels().getMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */
      @java.lang.Override

      public java.lang.String getLabelsOrDefault(
          java.lang.String key,
          java.lang.String defaultValue) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetLabels().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */
      @java.lang.Override

      public java.lang.String getLabelsOrThrow(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetLabels().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearLabels() {
        internalGetMutableLabels().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public Builder removeLabels(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        internalGetMutableLabels().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String>
      getMutableLabels() {
        return internalGetMutableLabels().getMutableMap();
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */
      public Builder putLabels(
          java.lang.String key,
          java.lang.String value) {
        if (key == null) { throw new NullPointerException("map key"); }
        if (value == null) {
  throw new NullPointerException("map value");
}

        internalGetMutableLabels().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <pre>
       * Custom labels for the Apache Kafka® cluster as `key:value` pairs.
       * A maximum of 64 labels per resource is allowed.
       * </pre>
       *
       * <code>map&lt;string, string&gt; labels = 6;</code>
       */

      public Builder putAllLabels(
          java.util.Map<java.lang.String, java.lang.String> values) {
        internalGetMutableLabels().getMutableMap()
            .putAll(values);
        return this;
      }

      private int environment_ = 0;
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       * @return The enum numeric value on the wire for environment.
       */
      @java.lang.Override public int getEnvironmentValue() {
        return environment_;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       * @param value The enum numeric value on the wire for environment to set.
       * @return This builder for chaining.
       */
      public Builder setEnvironmentValue(int value) {
        
        environment_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       * @return The environment.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment getEnvironment() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.valueOf(environment_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       * @param value The environment to set.
       * @return This builder for chaining.
       */
      public Builder setEnvironment(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Environment value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        environment_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deployment environment of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Environment environment = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnvironment() {
        
        environment_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> monitoring_ =
        java.util.Collections.emptyList();
      private void ensureMonitoringIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          monitoring_ = new java.util.ArrayList<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring>(monitoring_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> monitoringBuilder_;

      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> getMonitoringList() {
        if (monitoringBuilder_ == null) {
          return java.util.Collections.unmodifiableList(monitoring_);
        } else {
          return monitoringBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public int getMonitoringCount() {
        if (monitoringBuilder_ == null) {
          return monitoring_.size();
        } else {
          return monitoringBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getMonitoring(int index) {
        if (monitoringBuilder_ == null) {
          return monitoring_.get(index);
        } else {
          return monitoringBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder setMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.set(index, value);
          onChanged();
        } else {
          monitoringBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder setMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.set(index, builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.add(value);
          onChanged();
        } else {
          monitoringBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring value) {
        if (monitoringBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMonitoringIsMutable();
          monitoring_.add(index, value);
          onChanged();
        } else {
          monitoringBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.add(builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addMonitoring(
          int index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder builderForValue) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.add(index, builderForValue.build());
          onChanged();
        } else {
          monitoringBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder addAllMonitoring(
          java.lang.Iterable<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring> values) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, monitoring_);
          onChanged();
        } else {
          monitoringBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder clearMonitoring() {
        if (monitoringBuilder_ == null) {
          monitoring_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          monitoringBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public Builder removeMonitoring(int index) {
        if (monitoringBuilder_ == null) {
          ensureMonitoringIsMutable();
          monitoring_.remove(index);
          onChanged();
        } else {
          monitoringBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder getMonitoringBuilder(
          int index) {
        return getMonitoringFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder getMonitoringOrBuilder(
          int index) {
        if (monitoringBuilder_ == null) {
          return monitoring_.get(index);  } else {
          return monitoringBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<? extends yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
           getMonitoringOrBuilderList() {
        if (monitoringBuilder_ != null) {
          return monitoringBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(monitoring_);
        }
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder addMonitoringBuilder() {
        return getMonitoringFieldBuilder().addBuilder(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance());
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder addMonitoringBuilder(
          int index) {
        return getMonitoringFieldBuilder().addBuilder(
            index, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance());
      }
      /**
       * <pre>
       * Description of monitoring systems relevant to the Apache Kafka® cluster.
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.Monitoring monitoring = 8;</code>
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder> 
           getMonitoringBuilderList() {
        return getMonitoringFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder> 
          getMonitoringFieldBuilder() {
        if (monitoringBuilder_ == null) {
          monitoringBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder>(
                  monitoring_,
                  ((bitField0_ & 0x00000002) != 0),
                  getParentForChildren(),
                  isClean());
          monitoring_ = null;
        }
        return monitoringBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec config_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder> configBuilder_;
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       * @return Whether the config field is set.
       */
      public boolean hasConfig() {
        return configBuilder_ != null || config_ != null;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       * @return The config.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder setConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
          onChanged();
        } else {
          configBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder setConfig(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
          onChanged();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder mergeConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec value) {
        if (configBuilder_ == null) {
          if (config_ != null) {
            config_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.newBuilder(config_).mergeFrom(value).buildPartial();
          } else {
            config_ = value;
          }
          onChanged();
        } else {
          configBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public Builder clearConfig() {
        if (configBuilder_ == null) {
          config_ = null;
          onChanged();
        } else {
          config_ = null;
          configBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder getConfigBuilder() {
        
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Configuration of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec config = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder> 
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private java.lang.Object networkId_ = "";
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       * @return The networkId.
       */
      public java.lang.String getNetworkId() {
        java.lang.Object ref = networkId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          networkId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       * @return The bytes for networkId.
       */
      public com.google.protobuf.ByteString
          getNetworkIdBytes() {
        java.lang.Object ref = networkId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          networkId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       * @param value The networkId to set.
       * @return This builder for chaining.
       */
      public Builder setNetworkId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        networkId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       * @return This builder for chaining.
       */
      public Builder clearNetworkId() {
        
        networkId_ = getDefaultInstance().getNetworkId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the network that the cluster belongs to.
       * </pre>
       *
       * <code>string network_id = 10;</code>
       * @param value The bytes for networkId to set.
       * @return This builder for chaining.
       */
      public Builder setNetworkIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        networkId_ = value;
        onChanged();
        return this;
      }

      private int health_ = 0;
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       * @return The enum numeric value on the wire for health.
       */
      @java.lang.Override public int getHealthValue() {
        return health_;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       * @param value The enum numeric value on the wire for health to set.
       * @return This builder for chaining.
       */
      public Builder setHealthValue(int value) {
        
        health_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       * @return The health.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health getHealth() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.valueOf(health_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       * @param value The health to set.
       * @return This builder for chaining.
       */
      public Builder setHealth(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Health value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        health_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated cluster health.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Health health = 11;</code>
       * @return This builder for chaining.
       */
      public Builder clearHealth() {
        
        health_ = 0;
        onChanged();
        return this;
      }

      private int status_ = 0;
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       * @return The enum numeric value on the wire for status.
       */
      @java.lang.Override public int getStatusValue() {
        return status_;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       * @param value The enum numeric value on the wire for status to set.
       * @return This builder for chaining.
       */
      public Builder setStatusValue(int value) {
        
        status_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       * @return The status.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status getStatus() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.valueOf(status_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       * @param value The status to set.
       * @return This builder for chaining.
       */
      public Builder setStatus(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster.Status value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        status_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Current state of the cluster.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Cluster.Status status = 12;</code>
       * @return This builder for chaining.
       */
      public Builder clearStatus() {
        
        status_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureSecurityGroupIdsIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          securityGroupIds_ = new com.google.protobuf.LazyStringArrayList(securityGroupIds_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @return A list containing the securityGroupIds.
       */
      public com.google.protobuf.ProtocolStringList
          getSecurityGroupIdsList() {
        return securityGroupIds_.getUnmodifiableView();
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @return The count of securityGroupIds.
       */
      public int getSecurityGroupIdsCount() {
        return securityGroupIds_.size();
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param index The index of the element to return.
       * @return The securityGroupIds at the given index.
       */
      public java.lang.String getSecurityGroupIds(int index) {
        return securityGroupIds_.get(index);
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param index The index of the value to return.
       * @return The bytes of the securityGroupIds at the given index.
       */
      public com.google.protobuf.ByteString
          getSecurityGroupIdsBytes(int index) {
        return securityGroupIds_.getByteString(index);
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param index The index to set the value at.
       * @param value The securityGroupIds to set.
       * @return This builder for chaining.
       */
      public Builder setSecurityGroupIds(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param value The securityGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addSecurityGroupIds(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param values The securityGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addAllSecurityGroupIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureSecurityGroupIdsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, securityGroupIds_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @return This builder for chaining.
       */
      public Builder clearSecurityGroupIds() {
        securityGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * User security groups
       * </pre>
       *
       * <code>repeated string security_group_ids = 13;</code>
       * @param value The bytes of the securityGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addSecurityGroupIdsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureSecurityGroupIdsIsMutable();
        securityGroupIds_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureHostGroupIdsIsMutable() {
        if (!((bitField0_ & 0x00000008) != 0)) {
          hostGroupIds_ = new com.google.protobuf.LazyStringArrayList(hostGroupIds_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @return A list containing the hostGroupIds.
       */
      public com.google.protobuf.ProtocolStringList
          getHostGroupIdsList() {
        return hostGroupIds_.getUnmodifiableView();
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @return The count of hostGroupIds.
       */
      public int getHostGroupIdsCount() {
        return hostGroupIds_.size();
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param index The index of the element to return.
       * @return The hostGroupIds at the given index.
       */
      public java.lang.String getHostGroupIds(int index) {
        return hostGroupIds_.get(index);
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param index The index of the value to return.
       * @return The bytes of the hostGroupIds at the given index.
       */
      public com.google.protobuf.ByteString
          getHostGroupIdsBytes(int index) {
        return hostGroupIds_.getByteString(index);
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param index The index to set the value at.
       * @param value The hostGroupIds to set.
       * @return This builder for chaining.
       */
      public Builder setHostGroupIds(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureHostGroupIdsIsMutable();
        hostGroupIds_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param value The hostGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addHostGroupIds(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureHostGroupIdsIsMutable();
        hostGroupIds_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param values The hostGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addAllHostGroupIds(
          java.lang.Iterable<java.lang.String> values) {
        ensureHostGroupIdsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, hostGroupIds_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @return This builder for chaining.
       */
      public Builder clearHostGroupIds() {
        hostGroupIds_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host groups hosting VMs of the cluster.
       * </pre>
       *
       * <code>repeated string host_group_ids = 14;</code>
       * @param value The bytes of the hostGroupIds to add.
       * @return This builder for chaining.
       */
      public Builder addHostGroupIdsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureHostGroupIdsIsMutable();
        hostGroupIds_.add(value);
        onChanged();
        return this;
      }

      private boolean deletionProtection_ ;
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       * @return The deletionProtection.
       */
      @java.lang.Override
      public boolean getDeletionProtection() {
        return deletionProtection_;
      }
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       * @param value The deletionProtection to set.
       * @return This builder for chaining.
       */
      public Builder setDeletionProtection(boolean value) {
        
        deletionProtection_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Deletion Protection inhibits deletion of the cluster
       * </pre>
       *
       * <code>bool deletion_protection = 15;</code>
       * @return This builder for chaining.
       */
      public Builder clearDeletionProtection() {
        
        deletionProtection_ = false;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow maintenanceWindow_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder> maintenanceWindowBuilder_;
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       * @return Whether the maintenanceWindow field is set.
       */
      public boolean hasMaintenanceWindow() {
        return maintenanceWindowBuilder_ != null || maintenanceWindow_ != null;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       * @return The maintenanceWindow.
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow getMaintenanceWindow() {
        if (maintenanceWindowBuilder_ == null) {
          return maintenanceWindow_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
        } else {
          return maintenanceWindowBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder setMaintenanceWindow(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow value) {
        if (maintenanceWindowBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maintenanceWindow_ = value;
          onChanged();
        } else {
          maintenanceWindowBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder setMaintenanceWindow(
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder builderForValue) {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = builderForValue.build();
          onChanged();
        } else {
          maintenanceWindowBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder mergeMaintenanceWindow(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow value) {
        if (maintenanceWindowBuilder_ == null) {
          if (maintenanceWindow_ != null) {
            maintenanceWindow_ =
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.newBuilder(maintenanceWindow_).mergeFrom(value).buildPartial();
          } else {
            maintenanceWindow_ = value;
          }
          onChanged();
        } else {
          maintenanceWindowBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public Builder clearMaintenanceWindow() {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindow_ = null;
          onChanged();
        } else {
          maintenanceWindow_ = null;
          maintenanceWindowBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder getMaintenanceWindowBuilder() {
        
        onChanged();
        return getMaintenanceWindowFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder getMaintenanceWindowOrBuilder() {
        if (maintenanceWindowBuilder_ != null) {
          return maintenanceWindowBuilder_.getMessageOrBuilder();
        } else {
          return maintenanceWindow_ == null ?
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.getDefaultInstance() : maintenanceWindow_;
        }
      }
      /**
       * <pre>
       * Window of maintenance operations.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceWindow maintenance_window = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder> 
          getMaintenanceWindowFieldBuilder() {
        if (maintenanceWindowBuilder_ == null) {
          maintenanceWindowBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindow.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceWindowOrBuilder>(
                  getMaintenanceWindow(),
                  getParentForChildren(),
                  isClean());
          maintenanceWindow_ = null;
        }
        return maintenanceWindowBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation plannedOperation_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder> plannedOperationBuilder_;
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       * @return Whether the plannedOperation field is set.
       */
      public boolean hasPlannedOperation() {
        return plannedOperationBuilder_ != null || plannedOperation_ != null;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       * @return The plannedOperation.
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation getPlannedOperation() {
        if (plannedOperationBuilder_ == null) {
          return plannedOperation_ == null ? yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
        } else {
          return plannedOperationBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder setPlannedOperation(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation value) {
        if (plannedOperationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          plannedOperation_ = value;
          onChanged();
        } else {
          plannedOperationBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder setPlannedOperation(
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder builderForValue) {
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = builderForValue.build();
          onChanged();
        } else {
          plannedOperationBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder mergePlannedOperation(yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation value) {
        if (plannedOperationBuilder_ == null) {
          if (plannedOperation_ != null) {
            plannedOperation_ =
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.newBuilder(plannedOperation_).mergeFrom(value).buildPartial();
          } else {
            plannedOperation_ = value;
          }
          onChanged();
        } else {
          plannedOperationBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public Builder clearPlannedOperation() {
        if (plannedOperationBuilder_ == null) {
          plannedOperation_ = null;
          onChanged();
        } else {
          plannedOperation_ = null;
          plannedOperationBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder getPlannedOperationBuilder() {
        
        onChanged();
        return getPlannedOperationFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder getPlannedOperationOrBuilder() {
        if (plannedOperationBuilder_ != null) {
          return plannedOperationBuilder_.getMessageOrBuilder();
        } else {
          return plannedOperation_ == null ?
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.getDefaultInstance() : plannedOperation_;
        }
      }
      /**
       * <pre>
       * Scheduled maintenance operation.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.MaintenanceOperation planned_operation = 17;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder> 
          getPlannedOperationFieldBuilder() {
        if (plannedOperationBuilder_ == null) {
          plannedOperationBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperation.Builder, yandex.cloud.api.mdb.kafka.v1.Maintenance.MaintenanceOperationOrBuilder>(
                  getPlannedOperation(),
                  getParentForChildren(),
                  isClean());
          plannedOperation_ = null;
        }
        return plannedOperationBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Cluster)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Cluster)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Cluster>
        PARSER = new com.google.protobuf.AbstractParser<Cluster>() {
      @java.lang.Override
      public Cluster parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Cluster(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Cluster> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Cluster> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Cluster getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface MonitoringOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Monitoring)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     * @return The description.
     */
    java.lang.String getDescription();
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     * @return The bytes for description.
     */
    com.google.protobuf.ByteString
        getDescriptionBytes();

    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     * @return The link.
     */
    java.lang.String getLink();
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     * @return The bytes for link.
     */
    com.google.protobuf.ByteString
        getLinkBytes();
  }
  /**
   * <pre>
   * Metadata of monitoring system.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Monitoring}
   */
  public static final class Monitoring extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Monitoring)
      MonitoringOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Monitoring.newBuilder() to construct.
    private Monitoring(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Monitoring() {
      name_ = "";
      description_ = "";
      link_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Monitoring();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Monitoring(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              description_ = s;
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              link_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder.class);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the monitoring system.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DESCRIPTION_FIELD_NUMBER = 2;
    private volatile java.lang.Object description_;
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     * @return The description.
     */
    @java.lang.Override
    public java.lang.String getDescription() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        description_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Description of the monitoring system.
     * </pre>
     *
     * <code>string description = 2;</code>
     * @return The bytes for description.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getDescriptionBytes() {
      java.lang.Object ref = description_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        description_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LINK_FIELD_NUMBER = 3;
    private volatile java.lang.Object link_;
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     * @return The link.
     */
    @java.lang.Override
    public java.lang.String getLink() {
      java.lang.Object ref = link_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        link_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Link to the monitoring system charts for the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string link = 3;</code>
     * @return The bytes for link.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getLinkBytes() {
      java.lang.Object ref = link_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        link_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(description_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, description_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(link_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, link_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(description_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, description_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(link_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, link_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) obj;

      if (!getName()
          .equals(other.getName())) return false;
      if (!getDescription()
          .equals(other.getDescription())) return false;
      if (!getLink()
          .equals(other.getLink())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DESCRIPTION_FIELD_NUMBER;
      hash = (53 * hash) + getDescription().hashCode();
      hash = (37 * hash) + LINK_FIELD_NUMBER;
      hash = (53 * hash) + getLink().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Metadata of monitoring system.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Monitoring}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Monitoring)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.MonitoringOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        description_ = "";

        link_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring(this);
        result.name_ = name_;
        result.description_ = description_;
        result.link_ = link_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getDescription().isEmpty()) {
          description_ = other.description_;
          onChanged();
        }
        if (!other.getLink().isEmpty()) {
          link_ = other.link_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the monitoring system.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object description_ = "";
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       * @return The description.
       */
      public java.lang.String getDescription() {
        java.lang.Object ref = description_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          description_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       * @return The bytes for description.
       */
      public com.google.protobuf.ByteString
          getDescriptionBytes() {
        java.lang.Object ref = description_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          description_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       * @param value The description to set.
       * @return This builder for chaining.
       */
      public Builder setDescription(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        description_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDescription() {
        
        description_ = getDefaultInstance().getDescription();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Description of the monitoring system.
       * </pre>
       *
       * <code>string description = 2;</code>
       * @param value The bytes for description to set.
       * @return This builder for chaining.
       */
      public Builder setDescriptionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        description_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object link_ = "";
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       * @return The link.
       */
      public java.lang.String getLink() {
        java.lang.Object ref = link_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          link_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       * @return The bytes for link.
       */
      public com.google.protobuf.ByteString
          getLinkBytes() {
        java.lang.Object ref = link_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          link_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       * @param value The link to set.
       * @return This builder for chaining.
       */
      public Builder setLink(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        link_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearLink() {
        
        link_ = getDefaultInstance().getLink();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Link to the monitoring system charts for the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string link = 3;</code>
       * @param value The bytes for link to set.
       * @return This builder for chaining.
       */
      public Builder setLinkBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        link_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Monitoring)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Monitoring)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Monitoring>
        PARSER = new com.google.protobuf.AbstractParser<Monitoring>() {
      @java.lang.Override
      public Monitoring parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Monitoring(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Monitoring> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Monitoring> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Monitoring getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ConfigSpecOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     * @return The version.
     */
    java.lang.String getVersion();
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     * @return The bytes for version.
     */
    com.google.protobuf.ByteString
        getVersionBytes();

    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     * @return Whether the kafka field is set.
     */
    boolean hasKafka();
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     * @return The kafka.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka();
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder();

    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     * @return Whether the zookeeper field is set.
     */
    boolean hasZookeeper();
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     * @return The zookeeper.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper();
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder();

    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @return A list containing the zoneId.
     */
    java.util.List<java.lang.String>
        getZoneIdList();
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @return The count of zoneId.
     */
    int getZoneIdCount();
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @param index The index of the element to return.
     * @return The zoneId at the given index.
     */
    java.lang.String getZoneId(int index);
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the zoneId at the given index.
     */
    com.google.protobuf.ByteString
        getZoneIdBytes(int index);

    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     * @return Whether the brokersCount field is set.
     */
    boolean hasBrokersCount();
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     * @return The brokersCount.
     */
    com.google.protobuf.Int64Value getBrokersCount();
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder();

    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the cluster.
     * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 6;</code>
     * @return The assignPublicIp.
     */
    boolean getAssignPublicIp();

    /**
     * <pre>
     * Allows to manage topics via AdminAPI
     * </pre>
     *
     * <code>bool unmanaged_topics = 7;</code>
     * @return The unmanagedTopics.
     */
    boolean getUnmanagedTopics();

    /**
     * <pre>
     * Enables managed schema registry on cluster
     * </pre>
     *
     * <code>bool schema_registry = 8;</code>
     * @return The schemaRegistry.
     */
    boolean getSchemaRegistry();

    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     * @return Whether the access field is set.
     */
    boolean hasAccess();
    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     * @return The access.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getAccess();
    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder getAccessOrBuilder();

    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     * @return Whether the restApiConfig field is set.
     */
    boolean hasRestApiConfig();
    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     * @return The restApiConfig.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getRestApiConfig();
    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder getRestApiConfigOrBuilder();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec}
   */
  public static final class ConfigSpec extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec)
      ConfigSpecOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ConfigSpec.newBuilder() to construct.
    private ConfigSpec(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ConfigSpec() {
      version_ = "";
      zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new ConfigSpec();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ConfigSpec(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              version_ = s;
              break;
            }
            case 18: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder subBuilder = null;
              if (kafka_ != null) {
                subBuilder = kafka_.toBuilder();
              }
              kafka_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(kafka_);
                kafka_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder subBuilder = null;
              if (zookeeper_ != null) {
                subBuilder = zookeeper_.toBuilder();
              }
              zookeeper_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(zookeeper_);
                zookeeper_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                zoneId_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              zoneId_.add(s);
              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (brokersCount_ != null) {
                subBuilder = brokersCount_.toBuilder();
              }
              brokersCount_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(brokersCount_);
                brokersCount_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {

              assignPublicIp_ = input.readBool();
              break;
            }
            case 56: {

              unmanagedTopics_ = input.readBool();
              break;
            }
            case 64: {

              schemaRegistry_ = input.readBool();
              break;
            }
            case 74: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder subBuilder = null;
              if (access_ != null) {
                subBuilder = access_.toBuilder();
              }
              access_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(access_);
                access_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder subBuilder = null;
              if (restApiConfig_ != null) {
                subBuilder = restApiConfig_.toBuilder();
              }
              restApiConfig_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(restApiConfig_);
                restApiConfig_ = subBuilder.buildPartial();
              }

              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          zoneId_ = zoneId_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder.class);
    }

    public interface KafkaOrBuilder extends
        // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return Whether the resources field is set.
       */
      boolean hasResources();
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return The resources.
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();

      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       * @return Whether the kafkaConfig28 field is set.
       */
      boolean hasKafkaConfig28();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       * @return The kafkaConfig28.
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder();

      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       * @return Whether the kafkaConfig3 field is set.
       */
      boolean hasKafkaConfig3();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       * @return The kafkaConfig3.
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getKafkaConfig3();
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder getKafkaConfig3OrBuilder();

      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.KafkaConfigCase getKafkaConfigCase();
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka}
     */
    public static final class Kafka extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
        KafkaOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Kafka.newBuilder() to construct.
      private Kafka(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Kafka() {
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Kafka();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Kafka(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
                if (resources_ != null) {
                  subBuilder = resources_.toBuilder();
                }
                resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(resources_);
                  resources_ = subBuilder.buildPartial();
                }

                break;
              }
              case 34: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder subBuilder = null;
                if (kafkaConfigCase_ == 4) {
                  subBuilder = ((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_).toBuilder();
                }
                kafkaConfig_ =
                    input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
                  kafkaConfig_ = subBuilder.buildPartial();
                }
                kafkaConfigCase_ = 4;
                break;
              }
              case 42: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder subBuilder = null;
                if (kafkaConfigCase_ == 5) {
                  subBuilder = ((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_).toBuilder();
                }
                kafkaConfig_ =
                    input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_);
                  kafkaConfig_ = subBuilder.buildPartial();
                }
                kafkaConfigCase_ = 5;
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder.class);
      }

      private int kafkaConfigCase_ = 0;
      private java.lang.Object kafkaConfig_;
      public enum KafkaConfigCase
          implements com.google.protobuf.Internal.EnumLite,
              com.google.protobuf.AbstractMessage.InternalOneOfEnum {
        KAFKA_CONFIG_2_8(4),
        KAFKA_CONFIG_3(5),
        KAFKACONFIG_NOT_SET(0);
        private final int value;
        private KafkaConfigCase(int value) {
          this.value = value;
        }
        /**
         * @param value The number of the enum to look for.
         * @return The enum associated with the given number.
         * @deprecated Use {@link #forNumber(int)} instead.
         */
        @java.lang.Deprecated
        public static KafkaConfigCase valueOf(int value) {
          return forNumber(value);
        }

        public static KafkaConfigCase forNumber(int value) {
          switch (value) {
            case 4: return KAFKA_CONFIG_2_8;
            case 5: return KAFKA_CONFIG_3;
            case 0: return KAFKACONFIG_NOT_SET;
            default: return null;
          }
        }
        public int getNumber() {
          return this.value;
        }
      };

      public KafkaConfigCase
      getKafkaConfigCase() {
        return KafkaConfigCase.forNumber(
            kafkaConfigCase_);
      }

      public static final int RESOURCES_FIELD_NUMBER = 1;
      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return Whether the resources field is set.
       */
      @java.lang.Override
      public boolean hasResources() {
        return resources_ != null;
      }
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return The resources.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
      }
      /**
       * <pre>
       * Resources allocated to Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        return getResources();
      }

      public static final int KAFKA_CONFIG_2_8_FIELD_NUMBER = 4;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       * @return Whether the kafkaConfig28 field is set.
       */
      @java.lang.Override
      public boolean hasKafkaConfig28() {
        return kafkaConfigCase_ == 4;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       * @return The kafkaConfig28.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28() {
        if (kafkaConfigCase_ == 4) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder() {
        if (kafkaConfigCase_ == 4) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }

      public static final int KAFKA_CONFIG_3_FIELD_NUMBER = 5;
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       * @return Whether the kafkaConfig3 field is set.
       */
      @java.lang.Override
      public boolean hasKafkaConfig3() {
        return kafkaConfigCase_ == 5;
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       * @return The kafkaConfig3.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getKafkaConfig3() {
        if (kafkaConfigCase_ == 5) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
      }
      /**
       * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder getKafkaConfig3OrBuilder() {
        if (kafkaConfigCase_ == 5) {
           return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_;
        }
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (resources_ != null) {
          output.writeMessage(1, getResources());
        }
        if (kafkaConfigCase_ == 4) {
          output.writeMessage(4, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 5) {
          output.writeMessage(5, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (resources_ != null) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getResources());
        }
        if (kafkaConfigCase_ == 4) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(4, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_);
        }
        if (kafkaConfigCase_ == 5) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(5, (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka)) {
          return super.equals(obj);
        }
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) obj;

        if (hasResources() != other.hasResources()) return false;
        if (hasResources()) {
          if (!getResources()
              .equals(other.getResources())) return false;
        }
        if (!getKafkaConfigCase().equals(other.getKafkaConfigCase())) return false;
        switch (kafkaConfigCase_) {
          case 4:
            if (!getKafkaConfig28()
                .equals(other.getKafkaConfig28())) return false;
            break;
          case 5:
            if (!getKafkaConfig3()
                .equals(other.getKafkaConfig3())) return false;
            break;
          case 0:
          default:
        }
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasResources()) {
          hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
          hash = (53 * hash) + getResources().hashCode();
        }
        switch (kafkaConfigCase_) {
          case 4:
            hash = (37 * hash) + KAFKA_CONFIG_2_8_FIELD_NUMBER;
            hash = (53 * hash) + getKafkaConfig28().hashCode();
            break;
          case 5:
            hash = (37 * hash) + KAFKA_CONFIG_3_FIELD_NUMBER;
            hash = (53 * hash) + getKafkaConfig3().hashCode();
            break;
          case 0:
          default:
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder.class);
        }

        // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          if (resourcesBuilder_ == null) {
            resources_ = null;
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }
          kafkaConfigCase_ = 0;
          kafkaConfig_ = null;
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstanceForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance();
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka build() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka buildPartial() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka(this);
          if (resourcesBuilder_ == null) {
            result.resources_ = resources_;
          } else {
            result.resources_ = resourcesBuilder_.build();
          }
          if (kafkaConfigCase_ == 4) {
            if (kafkaConfig28Builder_ == null) {
              result.kafkaConfig_ = kafkaConfig_;
            } else {
              result.kafkaConfig_ = kafkaConfig28Builder_.build();
            }
          }
          if (kafkaConfigCase_ == 5) {
            if (kafkaConfig3Builder_ == null) {
              result.kafkaConfig_ = kafkaConfig_;
            } else {
              result.kafkaConfig_ = kafkaConfig3Builder_.build();
            }
          }
          result.kafkaConfigCase_ = kafkaConfigCase_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) {
            return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka other) {
          if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance()) return this;
          if (other.hasResources()) {
            mergeResources(other.getResources());
          }
          switch (other.getKafkaConfigCase()) {
            case KAFKA_CONFIG_2_8: {
              mergeKafkaConfig28(other.getKafkaConfig28());
              break;
            }
            case KAFKA_CONFIG_3: {
              mergeKafkaConfig3(other.getKafkaConfig3());
              break;
            }
            case KAFKACONFIG_NOT_SET: {
              break;
            }
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int kafkaConfigCase_ = 0;
        private java.lang.Object kafkaConfig_;
        public KafkaConfigCase
            getKafkaConfigCase() {
          return KafkaConfigCase.forNumber(
              kafkaConfigCase_);
        }

        public Builder clearKafkaConfig() {
          kafkaConfigCase_ = 0;
          kafkaConfig_ = null;
          onChanged();
          return this;
        }


        private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         * @return Whether the resources field is set.
         */
        public boolean hasResources() {
          return resourcesBuilder_ != null || resources_ != null;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         * @return The resources.
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
          if (resourcesBuilder_ == null) {
            return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          } else {
            return resourcesBuilder_.getMessage();
          }
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            resources_ = value;
            onChanged();
          } else {
            resourcesBuilder_.setMessage(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
          if (resourcesBuilder_ == null) {
            resources_ = builderForValue.build();
            onChanged();
          } else {
            resourcesBuilder_.setMessage(builderForValue.build());
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (resources_ != null) {
              resources_ =
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
            } else {
              resources_ = value;
            }
            onChanged();
          } else {
            resourcesBuilder_.mergeFrom(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder clearResources() {
          if (resourcesBuilder_ == null) {
            resources_ = null;
            onChanged();
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
          
          onChanged();
          return getResourcesFieldBuilder().getBuilder();
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
          if (resourcesBuilder_ != null) {
            return resourcesBuilder_.getMessageOrBuilder();
          } else {
            return resources_ == null ?
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          }
        }
        /**
         * <pre>
         * Resources allocated to Kafka brokers.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
            getResourcesFieldBuilder() {
          if (resourcesBuilder_ == null) {
            resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                    getResources(),
                    getParentForChildren(),
                    isClean());
            resources_ = null;
          }
          return resourcesBuilder_;
        }

        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder> kafkaConfig28Builder_;
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         * @return Whether the kafkaConfig28 field is set.
         */
        @java.lang.Override
        public boolean hasKafkaConfig28() {
          return kafkaConfigCase_ == 4;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         * @return The kafkaConfig28.
         */
        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getKafkaConfig28() {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          } else {
            if (kafkaConfigCase_ == 4) {
              return kafkaConfig28Builder_.getMessage();
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder setKafkaConfig28(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 value) {
          if (kafkaConfig28Builder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            kafkaConfig_ = value;
            onChanged();
          } else {
            kafkaConfig28Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder setKafkaConfig28(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder builderForValue) {
          if (kafkaConfig28Builder_ == null) {
            kafkaConfig_ = builderForValue.build();
            onChanged();
          } else {
            kafkaConfig28Builder_.setMessage(builderForValue.build());
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder mergeKafkaConfig28(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 value) {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4 &&
                kafkaConfig_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance()) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.newBuilder((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_)
                  .mergeFrom(value).buildPartial();
            } else {
              kafkaConfig_ = value;
            }
            onChanged();
          } else {
            if (kafkaConfigCase_ == 4) {
              kafkaConfig28Builder_.mergeFrom(value);
            }
            kafkaConfig28Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 4;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        public Builder clearKafkaConfig28() {
          if (kafkaConfig28Builder_ == null) {
            if (kafkaConfigCase_ == 4) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
              onChanged();
            }
          } else {
            if (kafkaConfigCase_ == 4) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
            }
            kafkaConfig28Builder_.clear();
          }
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder getKafkaConfig28Builder() {
          return getKafkaConfig28FieldBuilder().getBuilder();
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder getKafkaConfig28OrBuilder() {
          if ((kafkaConfigCase_ == 4) && (kafkaConfig28Builder_ != null)) {
            return kafkaConfig28Builder_.getMessageOrBuilder();
          } else {
            if (kafkaConfigCase_ == 4) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig2_8 kafka_config_2_8 = 4 [json_name = "kafkaConfig_2_8"];</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder> 
            getKafkaConfig28FieldBuilder() {
          if (kafkaConfig28Builder_ == null) {
            if (!(kafkaConfigCase_ == 4)) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
            }
            kafkaConfig28Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder>(
                    (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) kafkaConfig_,
                    getParentForChildren(),
                    isClean());
            kafkaConfig_ = null;
          }
          kafkaConfigCase_ = 4;
          onChanged();;
          return kafkaConfig28Builder_;
        }

        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder> kafkaConfig3Builder_;
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         * @return Whether the kafkaConfig3 field is set.
         */
        @java.lang.Override
        public boolean hasKafkaConfig3() {
          return kafkaConfigCase_ == 5;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         * @return The kafkaConfig3.
         */
        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getKafkaConfig3() {
          if (kafkaConfig3Builder_ == null) {
            if (kafkaConfigCase_ == 5) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
          } else {
            if (kafkaConfigCase_ == 5) {
              return kafkaConfig3Builder_.getMessage();
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        public Builder setKafkaConfig3(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 value) {
          if (kafkaConfig3Builder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            kafkaConfig_ = value;
            onChanged();
          } else {
            kafkaConfig3Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 5;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        public Builder setKafkaConfig3(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder builderForValue) {
          if (kafkaConfig3Builder_ == null) {
            kafkaConfig_ = builderForValue.build();
            onChanged();
          } else {
            kafkaConfig3Builder_.setMessage(builderForValue.build());
          }
          kafkaConfigCase_ = 5;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        public Builder mergeKafkaConfig3(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 value) {
          if (kafkaConfig3Builder_ == null) {
            if (kafkaConfigCase_ == 5 &&
                kafkaConfig_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance()) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.newBuilder((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_)
                  .mergeFrom(value).buildPartial();
            } else {
              kafkaConfig_ = value;
            }
            onChanged();
          } else {
            if (kafkaConfigCase_ == 5) {
              kafkaConfig3Builder_.mergeFrom(value);
            }
            kafkaConfig3Builder_.setMessage(value);
          }
          kafkaConfigCase_ = 5;
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        public Builder clearKafkaConfig3() {
          if (kafkaConfig3Builder_ == null) {
            if (kafkaConfigCase_ == 5) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
              onChanged();
            }
          } else {
            if (kafkaConfigCase_ == 5) {
              kafkaConfigCase_ = 0;
              kafkaConfig_ = null;
            }
            kafkaConfig3Builder_.clear();
          }
          return this;
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder getKafkaConfig3Builder() {
          return getKafkaConfig3FieldBuilder().getBuilder();
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder getKafkaConfig3OrBuilder() {
          if ((kafkaConfigCase_ == 5) && (kafkaConfig3Builder_ != null)) {
            return kafkaConfig3Builder_.getMessageOrBuilder();
          } else {
            if (kafkaConfigCase_ == 5) {
              return (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_;
            }
            return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
          }
        }
        /**
         * <code>.yandex.cloud.mdb.kafka.v1.KafkaConfig3 kafka_config_3 = 5 [json_name = "kafkaConfig_3"];</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder> 
            getKafkaConfig3FieldBuilder() {
          if (kafkaConfig3Builder_ == null) {
            if (!(kafkaConfigCase_ == 5)) {
              kafkaConfig_ = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
            }
            kafkaConfig3Builder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder>(
                    (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) kafkaConfig_,
                    getParentForChildren(),
                    isClean());
            kafkaConfig_ = null;
          }
          kafkaConfigCase_ = 5;
          onChanged();;
          return kafkaConfig3Builder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
      }

      // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka)
      private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka();
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Kafka>
          PARSER = new com.google.protobuf.AbstractParser<Kafka>() {
        @java.lang.Override
        public Kafka parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Kafka(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Kafka> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Kafka> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface ZookeeperOrBuilder extends
        // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return Whether the resources field is set.
       */
      boolean hasResources();
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return The resources.
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper}
     */
    public static final class Zookeeper extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
        ZookeeperOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use Zookeeper.newBuilder() to construct.
      private Zookeeper(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Zookeeper() {
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new Zookeeper();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private Zookeeper(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
                if (resources_ != null) {
                  subBuilder = resources_.toBuilder();
                }
                resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(resources_);
                  resources_ = subBuilder.buildPartial();
                }

                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder.class);
      }

      public static final int RESOURCES_FIELD_NUMBER = 1;
      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return Whether the resources field is set.
       */
      @java.lang.Override
      public boolean hasResources() {
        return resources_ != null;
      }
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       * @return The resources.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
      }
      /**
       * <pre>
       * Resources allocated to ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        return getResources();
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (resources_ != null) {
          output.writeMessage(1, getResources());
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (resources_ != null) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, getResources());
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper)) {
          return super.equals(obj);
        }
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) obj;

        if (hasResources() != other.hasResources()) return false;
        if (hasResources()) {
          if (!getResources()
              .equals(other.getResources())) return false;
        }
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        if (hasResources()) {
          hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
          hash = (53 * hash) + getResources().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder.class);
        }

        // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          if (resourcesBuilder_ == null) {
            resources_ = null;
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }
          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstanceForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance();
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper build() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper buildPartial() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper(this);
          if (resourcesBuilder_ == null) {
            result.resources_ = resources_;
          } else {
            result.resources_ = resourcesBuilder_.build();
          }
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) {
            return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper other) {
          if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance()) return this;
          if (other.hasResources()) {
            mergeResources(other.getResources());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         * @return Whether the resources field is set.
         */
        public boolean hasResources() {
          return resourcesBuilder_ != null || resources_ != null;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         * @return The resources.
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
          if (resourcesBuilder_ == null) {
            return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          } else {
            return resourcesBuilder_.getMessage();
          }
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            resources_ = value;
            onChanged();
          } else {
            resourcesBuilder_.setMessage(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder setResources(
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
          if (resourcesBuilder_ == null) {
            resources_ = builderForValue.build();
            onChanged();
          } else {
            resourcesBuilder_.setMessage(builderForValue.build());
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
          if (resourcesBuilder_ == null) {
            if (resources_ != null) {
              resources_ =
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
            } else {
              resources_ = value;
            }
            onChanged();
          } else {
            resourcesBuilder_.mergeFrom(value);
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public Builder clearResources() {
          if (resourcesBuilder_ == null) {
            resources_ = null;
            onChanged();
          } else {
            resources_ = null;
            resourcesBuilder_ = null;
          }

          return this;
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
          
          onChanged();
          return getResourcesFieldBuilder().getBuilder();
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
          if (resourcesBuilder_ != null) {
            return resourcesBuilder_.getMessageOrBuilder();
          } else {
            return resources_ == null ?
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
          }
        }
        /**
         * <pre>
         * Resources allocated to ZooKeeper hosts.
         * </pre>
         *
         * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 1;</code>
         */
        private com.google.protobuf.SingleFieldBuilderV3<
            yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
            getResourcesFieldBuilder() {
          if (resourcesBuilder_ == null) {
            resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                    getResources(),
                    getParentForChildren(),
                    isClean());
            resources_ = null;
          }
          return resourcesBuilder_;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
      }

      // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper)
      private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper();
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Zookeeper>
          PARSER = new com.google.protobuf.AbstractParser<Zookeeper>() {
        @java.lang.Override
        public Zookeeper parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new Zookeeper(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Zookeeper> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<Zookeeper> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface RestAPIConfigOrBuilder extends
        // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       * Is REST API enabled for this cluster.
       * </pre>
       *
       * <code>bool enabled = 1;</code>
       * @return The enabled.
       */
      boolean getEnabled();
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig}
     */
    public static final class RestAPIConfig extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig)
        RestAPIConfigOrBuilder {
    private static final long serialVersionUID = 0L;
      // Use RestAPIConfig.newBuilder() to construct.
      private RestAPIConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private RestAPIConfig() {
      }

      @java.lang.Override
      @SuppressWarnings({"unused"})
      protected java.lang.Object newInstance(
          UnusedPrivateParameter unused) {
        return new RestAPIConfig();
      }

      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return this.unknownFields;
      }
      private RestAPIConfig(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {

                enabled_ = input.readBool();
                break;
              }
              default: {
                if (!parseUnknownField(
                    input, unknownFields, extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder.class);
      }

      public static final int ENABLED_FIELD_NUMBER = 1;
      private boolean enabled_;
      /**
       * <pre>
       * Is REST API enabled for this cluster.
       * </pre>
       *
       * <code>bool enabled = 1;</code>
       * @return The enabled.
       */
      @java.lang.Override
      public boolean getEnabled() {
        return enabled_;
      }

      private byte memoizedIsInitialized = -1;
      @java.lang.Override
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      @java.lang.Override
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (enabled_ != false) {
          output.writeBool(1, enabled_);
        }
        unknownFields.writeTo(output);
      }

      @java.lang.Override
      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (enabled_ != false) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(1, enabled_);
        }
        size += unknownFields.getSerializedSize();
        memoizedSize = size;
        return size;
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig)) {
          return super.equals(obj);
        }
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig) obj;

        if (getEnabled()
            != other.getEnabled()) return false;
        if (!unknownFields.equals(other.unknownFields)) return false;
        return true;
      }

      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptor().hashCode();
        hash = (37 * hash) + ENABLED_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getEnabled());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          java.nio.ByteBuffer data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          java.nio.ByteBuffer data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      @java.lang.Override
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      @java.lang.Override
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig)
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor;
        }

        @java.lang.Override
        protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder.class);
        }

        // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        @java.lang.Override
        public Builder clear() {
          super.clear();
          enabled_ = false;

          return this;
        }

        @java.lang.Override
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getDefaultInstanceForType() {
          return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.getDefaultInstance();
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig build() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        @java.lang.Override
        public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig buildPartial() {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig(this);
          result.enabled_ = enabled_;
          onBuilt();
          return result;
        }

        @java.lang.Override
        public Builder clone() {
          return super.clone();
        }
        @java.lang.Override
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.setField(field, value);
        }
        @java.lang.Override
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return super.clearField(field);
        }
        @java.lang.Override
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return super.clearOneof(oneof);
        }
        @java.lang.Override
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, java.lang.Object value) {
          return super.setRepeatedField(field, index, value);
        }
        @java.lang.Override
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            java.lang.Object value) {
          return super.addRepeatedField(field, value);
        }
        @java.lang.Override
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig) {
            return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig other) {
          if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.getDefaultInstance()) return this;
          if (other.getEnabled() != false) {
            setEnabled(other.getEnabled());
          }
          this.mergeUnknownFields(other.unknownFields);
          onChanged();
          return this;
        }

        @java.lang.Override
        public final boolean isInitialized() {
          return true;
        }

        @java.lang.Override
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private boolean enabled_ ;
        /**
         * <pre>
         * Is REST API enabled for this cluster.
         * </pre>
         *
         * <code>bool enabled = 1;</code>
         * @return The enabled.
         */
        @java.lang.Override
        public boolean getEnabled() {
          return enabled_;
        }
        /**
         * <pre>
         * Is REST API enabled for this cluster.
         * </pre>
         *
         * <code>bool enabled = 1;</code>
         * @param value The enabled to set.
         * @return This builder for chaining.
         */
        public Builder setEnabled(boolean value) {
          
          enabled_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         * Is REST API enabled for this cluster.
         * </pre>
         *
         * <code>bool enabled = 1;</code>
         * @return This builder for chaining.
         */
        public Builder clearEnabled() {
          
          enabled_ = false;
          onChanged();
          return this;
        }
        @java.lang.Override
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.setUnknownFields(unknownFields);
        }

        @java.lang.Override
        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return super.mergeUnknownFields(unknownFields);
        }


        // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig)
      }

      // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig)
      private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig();
      }

      public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<RestAPIConfig>
          PARSER = new com.google.protobuf.AbstractParser<RestAPIConfig>() {
        @java.lang.Override
        public RestAPIConfig parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new RestAPIConfig(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<RestAPIConfig> parser() {
        return PARSER;
      }

      @java.lang.Override
      public com.google.protobuf.Parser<RestAPIConfig> getParserForType() {
        return PARSER;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int VERSION_FIELD_NUMBER = 1;
    private volatile java.lang.Object version_;
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     * @return The version.
     */
    @java.lang.Override
    public java.lang.String getVersion() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        version_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
     * </pre>
     *
     * <code>string version = 1;</code>
     * @return The bytes for version.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getVersionBytes() {
      java.lang.Object ref = version_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        version_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int KAFKA_FIELD_NUMBER = 2;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka kafka_;
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     * @return Whether the kafka field is set.
     */
    @java.lang.Override
    public boolean hasKafka() {
      return kafka_ != null;
    }
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     * @return The kafka.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka() {
      return kafka_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
    }
    /**
     * <pre>
     * Configuration and resource allocation for Kafka brokers.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder() {
      return getKafka();
    }

    public static final int ZOOKEEPER_FIELD_NUMBER = 3;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper zookeeper_;
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     * @return Whether the zookeeper field is set.
     */
    @java.lang.Override
    public boolean hasZookeeper() {
      return zookeeper_ != null;
    }
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     * @return The zookeeper.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper() {
      return zookeeper_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
    }
    /**
     * <pre>
     * Configuration and resource allocation for ZooKeeper hosts.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder() {
      return getZookeeper();
    }

    public static final int ZONE_ID_FIELD_NUMBER = 4;
    private com.google.protobuf.LazyStringList zoneId_;
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @return A list containing the zoneId.
     */
    public com.google.protobuf.ProtocolStringList
        getZoneIdList() {
      return zoneId_;
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @return The count of zoneId.
     */
    public int getZoneIdCount() {
      return zoneId_.size();
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @param index The index of the element to return.
     * @return The zoneId at the given index.
     */
    public java.lang.String getZoneId(int index) {
      return zoneId_.get(index);
    }
    /**
     * <pre>
     * IDs of availability zones where Kafka brokers reside.
     * </pre>
     *
     * <code>repeated string zone_id = 4;</code>
     * @param index The index of the value to return.
     * @return The bytes of the zoneId at the given index.
     */
    public com.google.protobuf.ByteString
        getZoneIdBytes(int index) {
      return zoneId_.getByteString(index);
    }

    public static final int BROKERS_COUNT_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value brokersCount_;
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     * @return Whether the brokersCount field is set.
     */
    @java.lang.Override
    public boolean hasBrokersCount() {
      return brokersCount_ != null;
    }
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     * @return The brokersCount.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getBrokersCount() {
      return brokersCount_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
    }
    /**
     * <pre>
     * The number of Kafka brokers deployed in each availability zone.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder() {
      return getBrokersCount();
    }

    public static final int ASSIGN_PUBLIC_IP_FIELD_NUMBER = 6;
    private boolean assignPublicIp_;
    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the cluster.
     * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 6;</code>
     * @return The assignPublicIp.
     */
    @java.lang.Override
    public boolean getAssignPublicIp() {
      return assignPublicIp_;
    }

    public static final int UNMANAGED_TOPICS_FIELD_NUMBER = 7;
    private boolean unmanagedTopics_;
    /**
     * <pre>
     * Allows to manage topics via AdminAPI
     * </pre>
     *
     * <code>bool unmanaged_topics = 7;</code>
     * @return The unmanagedTopics.
     */
    @java.lang.Override
    public boolean getUnmanagedTopics() {
      return unmanagedTopics_;
    }

    public static final int SCHEMA_REGISTRY_FIELD_NUMBER = 8;
    private boolean schemaRegistry_;
    /**
     * <pre>
     * Enables managed schema registry on cluster
     * </pre>
     *
     * <code>bool schema_registry = 8;</code>
     * @return The schemaRegistry.
     */
    @java.lang.Override
    public boolean getSchemaRegistry() {
      return schemaRegistry_;
    }

    public static final int ACCESS_FIELD_NUMBER = 9;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access access_;
    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     * @return Whether the access field is set.
     */
    @java.lang.Override
    public boolean hasAccess() {
      return access_ != null;
    }
    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     * @return The access.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getAccess() {
      return access_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.getDefaultInstance() : access_;
    }
    /**
     * <pre>
     * Access policy for external services.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder getAccessOrBuilder() {
      return getAccess();
    }

    public static final int REST_API_CONFIG_FIELD_NUMBER = 10;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig restApiConfig_;
    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     * @return Whether the restApiConfig field is set.
     */
    @java.lang.Override
    public boolean hasRestApiConfig() {
      return restApiConfig_ != null;
    }
    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     * @return The restApiConfig.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getRestApiConfig() {
      return restApiConfig_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.getDefaultInstance() : restApiConfig_;
    }
    /**
     * <pre>
     * Configuration of REST API.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder getRestApiConfigOrBuilder() {
      return getRestApiConfig();
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(version_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, version_);
      }
      if (kafka_ != null) {
        output.writeMessage(2, getKafka());
      }
      if (zookeeper_ != null) {
        output.writeMessage(3, getZookeeper());
      }
      for (int i = 0; i < zoneId_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, zoneId_.getRaw(i));
      }
      if (brokersCount_ != null) {
        output.writeMessage(5, getBrokersCount());
      }
      if (assignPublicIp_ != false) {
        output.writeBool(6, assignPublicIp_);
      }
      if (unmanagedTopics_ != false) {
        output.writeBool(7, unmanagedTopics_);
      }
      if (schemaRegistry_ != false) {
        output.writeBool(8, schemaRegistry_);
      }
      if (access_ != null) {
        output.writeMessage(9, getAccess());
      }
      if (restApiConfig_ != null) {
        output.writeMessage(10, getRestApiConfig());
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(version_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, version_);
      }
      if (kafka_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getKafka());
      }
      if (zookeeper_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getZookeeper());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < zoneId_.size(); i++) {
          dataSize += computeStringSizeNoTag(zoneId_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getZoneIdList().size();
      }
      if (brokersCount_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getBrokersCount());
      }
      if (assignPublicIp_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, assignPublicIp_);
      }
      if (unmanagedTopics_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, unmanagedTopics_);
      }
      if (schemaRegistry_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, schemaRegistry_);
      }
      if (access_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getAccess());
      }
      if (restApiConfig_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getRestApiConfig());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) obj;

      if (!getVersion()
          .equals(other.getVersion())) return false;
      if (hasKafka() != other.hasKafka()) return false;
      if (hasKafka()) {
        if (!getKafka()
            .equals(other.getKafka())) return false;
      }
      if (hasZookeeper() != other.hasZookeeper()) return false;
      if (hasZookeeper()) {
        if (!getZookeeper()
            .equals(other.getZookeeper())) return false;
      }
      if (!getZoneIdList()
          .equals(other.getZoneIdList())) return false;
      if (hasBrokersCount() != other.hasBrokersCount()) return false;
      if (hasBrokersCount()) {
        if (!getBrokersCount()
            .equals(other.getBrokersCount())) return false;
      }
      if (getAssignPublicIp()
          != other.getAssignPublicIp()) return false;
      if (getUnmanagedTopics()
          != other.getUnmanagedTopics()) return false;
      if (getSchemaRegistry()
          != other.getSchemaRegistry()) return false;
      if (hasAccess() != other.hasAccess()) return false;
      if (hasAccess()) {
        if (!getAccess()
            .equals(other.getAccess())) return false;
      }
      if (hasRestApiConfig() != other.hasRestApiConfig()) return false;
      if (hasRestApiConfig()) {
        if (!getRestApiConfig()
            .equals(other.getRestApiConfig())) return false;
      }
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + VERSION_FIELD_NUMBER;
      hash = (53 * hash) + getVersion().hashCode();
      if (hasKafka()) {
        hash = (37 * hash) + KAFKA_FIELD_NUMBER;
        hash = (53 * hash) + getKafka().hashCode();
      }
      if (hasZookeeper()) {
        hash = (37 * hash) + ZOOKEEPER_FIELD_NUMBER;
        hash = (53 * hash) + getZookeeper().hashCode();
      }
      if (getZoneIdCount() > 0) {
        hash = (37 * hash) + ZONE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getZoneIdList().hashCode();
      }
      if (hasBrokersCount()) {
        hash = (37 * hash) + BROKERS_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getBrokersCount().hashCode();
      }
      hash = (37 * hash) + ASSIGN_PUBLIC_IP_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAssignPublicIp());
      hash = (37 * hash) + UNMANAGED_TOPICS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getUnmanagedTopics());
      hash = (37 * hash) + SCHEMA_REGISTRY_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getSchemaRegistry());
      if (hasAccess()) {
        hash = (37 * hash) + ACCESS_FIELD_NUMBER;
        hash = (53 * hash) + getAccess().hashCode();
      }
      if (hasRestApiConfig()) {
        hash = (37 * hash) + REST_API_CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getRestApiConfig().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.ConfigSpec}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.ConfigSpec)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpecOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        version_ = "";

        if (kafkaBuilder_ == null) {
          kafka_ = null;
        } else {
          kafka_ = null;
          kafkaBuilder_ = null;
        }
        if (zookeeperBuilder_ == null) {
          zookeeper_ = null;
        } else {
          zookeeper_ = null;
          zookeeperBuilder_ = null;
        }
        zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (brokersCountBuilder_ == null) {
          brokersCount_ = null;
        } else {
          brokersCount_ = null;
          brokersCountBuilder_ = null;
        }
        assignPublicIp_ = false;

        unmanagedTopics_ = false;

        schemaRegistry_ = false;

        if (accessBuilder_ == null) {
          access_ = null;
        } else {
          access_ = null;
          accessBuilder_ = null;
        }
        if (restApiConfigBuilder_ == null) {
          restApiConfig_ = null;
        } else {
          restApiConfig_ = null;
          restApiConfigBuilder_ = null;
        }
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec(this);
        int from_bitField0_ = bitField0_;
        result.version_ = version_;
        if (kafkaBuilder_ == null) {
          result.kafka_ = kafka_;
        } else {
          result.kafka_ = kafkaBuilder_.build();
        }
        if (zookeeperBuilder_ == null) {
          result.zookeeper_ = zookeeper_;
        } else {
          result.zookeeper_ = zookeeperBuilder_.build();
        }
        if (((bitField0_ & 0x00000001) != 0)) {
          zoneId_ = zoneId_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.zoneId_ = zoneId_;
        if (brokersCountBuilder_ == null) {
          result.brokersCount_ = brokersCount_;
        } else {
          result.brokersCount_ = brokersCountBuilder_.build();
        }
        result.assignPublicIp_ = assignPublicIp_;
        result.unmanagedTopics_ = unmanagedTopics_;
        result.schemaRegistry_ = schemaRegistry_;
        if (accessBuilder_ == null) {
          result.access_ = access_;
        } else {
          result.access_ = accessBuilder_.build();
        }
        if (restApiConfigBuilder_ == null) {
          result.restApiConfig_ = restApiConfig_;
        } else {
          result.restApiConfig_ = restApiConfigBuilder_.build();
        }
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.getDefaultInstance()) return this;
        if (!other.getVersion().isEmpty()) {
          version_ = other.version_;
          onChanged();
        }
        if (other.hasKafka()) {
          mergeKafka(other.getKafka());
        }
        if (other.hasZookeeper()) {
          mergeZookeeper(other.getZookeeper());
        }
        if (!other.zoneId_.isEmpty()) {
          if (zoneId_.isEmpty()) {
            zoneId_ = other.zoneId_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureZoneIdIsMutable();
            zoneId_.addAll(other.zoneId_);
          }
          onChanged();
        }
        if (other.hasBrokersCount()) {
          mergeBrokersCount(other.getBrokersCount());
        }
        if (other.getAssignPublicIp() != false) {
          setAssignPublicIp(other.getAssignPublicIp());
        }
        if (other.getUnmanagedTopics() != false) {
          setUnmanagedTopics(other.getUnmanagedTopics());
        }
        if (other.getSchemaRegistry() != false) {
          setSchemaRegistry(other.getSchemaRegistry());
        }
        if (other.hasAccess()) {
          mergeAccess(other.getAccess());
        }
        if (other.hasRestApiConfig()) {
          mergeRestApiConfig(other.getRestApiConfig());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object version_ = "";
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       * @return The version.
       */
      public java.lang.String getVersion() {
        java.lang.Object ref = version_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          version_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       * @return The bytes for version.
       */
      public com.google.protobuf.ByteString
          getVersionBytes() {
        java.lang.Object ref = version_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          version_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       * @param value The version to set.
       * @return This builder for chaining.
       */
      public Builder setVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearVersion() {
        
        version_ = getDefaultInstance().getVersion();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Version of Apache Kafka® used in the cluster. Possible values: `2.1`, `2.6`.
       * </pre>
       *
       * <code>string version = 1;</code>
       * @param value The bytes for version to set.
       * @return This builder for chaining.
       */
      public Builder setVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        version_ = value;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka kafka_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder> kafkaBuilder_;
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       * @return Whether the kafka field is set.
       */
      public boolean hasKafka() {
        return kafkaBuilder_ != null || kafka_ != null;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       * @return The kafka.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka getKafka() {
        if (kafkaBuilder_ == null) {
          return kafka_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
        } else {
          return kafkaBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder setKafka(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka value) {
        if (kafkaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          kafka_ = value;
          onChanged();
        } else {
          kafkaBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder setKafka(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder builderForValue) {
        if (kafkaBuilder_ == null) {
          kafka_ = builderForValue.build();
          onChanged();
        } else {
          kafkaBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder mergeKafka(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka value) {
        if (kafkaBuilder_ == null) {
          if (kafka_ != null) {
            kafka_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.newBuilder(kafka_).mergeFrom(value).buildPartial();
          } else {
            kafka_ = value;
          }
          onChanged();
        } else {
          kafkaBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public Builder clearKafka() {
        if (kafkaBuilder_ == null) {
          kafka_ = null;
          onChanged();
        } else {
          kafka_ = null;
          kafkaBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder getKafkaBuilder() {
        
        onChanged();
        return getKafkaFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder getKafkaOrBuilder() {
        if (kafkaBuilder_ != null) {
          return kafkaBuilder_.getMessageOrBuilder();
        } else {
          return kafka_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.getDefaultInstance() : kafka_;
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for Kafka brokers.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Kafka kafka = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder> 
          getKafkaFieldBuilder() {
        if (kafkaBuilder_ == null) {
          kafkaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Kafka.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.KafkaOrBuilder>(
                  getKafka(),
                  getParentForChildren(),
                  isClean());
          kafka_ = null;
        }
        return kafkaBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper zookeeper_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder> zookeeperBuilder_;
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       * @return Whether the zookeeper field is set.
       */
      public boolean hasZookeeper() {
        return zookeeperBuilder_ != null || zookeeper_ != null;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       * @return The zookeeper.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper getZookeeper() {
        if (zookeeperBuilder_ == null) {
          return zookeeper_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
        } else {
          return zookeeperBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder setZookeeper(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper value) {
        if (zookeeperBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          zookeeper_ = value;
          onChanged();
        } else {
          zookeeperBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder setZookeeper(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder builderForValue) {
        if (zookeeperBuilder_ == null) {
          zookeeper_ = builderForValue.build();
          onChanged();
        } else {
          zookeeperBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder mergeZookeeper(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper value) {
        if (zookeeperBuilder_ == null) {
          if (zookeeper_ != null) {
            zookeeper_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.newBuilder(zookeeper_).mergeFrom(value).buildPartial();
          } else {
            zookeeper_ = value;
          }
          onChanged();
        } else {
          zookeeperBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public Builder clearZookeeper() {
        if (zookeeperBuilder_ == null) {
          zookeeper_ = null;
          onChanged();
        } else {
          zookeeper_ = null;
          zookeeperBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder getZookeeperBuilder() {
        
        onChanged();
        return getZookeeperFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder getZookeeperOrBuilder() {
        if (zookeeperBuilder_ != null) {
          return zookeeperBuilder_.getMessageOrBuilder();
        } else {
          return zookeeper_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.getDefaultInstance() : zookeeper_;
        }
      }
      /**
       * <pre>
       * Configuration and resource allocation for ZooKeeper hosts.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.Zookeeper zookeeper = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder> 
          getZookeeperFieldBuilder() {
        if (zookeeperBuilder_ == null) {
          zookeeperBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.Zookeeper.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.ZookeeperOrBuilder>(
                  getZookeeper(),
                  getParentForChildren(),
                  isClean());
          zookeeper_ = null;
        }
        return zookeeperBuilder_;
      }

      private com.google.protobuf.LazyStringList zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureZoneIdIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          zoneId_ = new com.google.protobuf.LazyStringArrayList(zoneId_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @return A list containing the zoneId.
       */
      public com.google.protobuf.ProtocolStringList
          getZoneIdList() {
        return zoneId_.getUnmodifiableView();
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @return The count of zoneId.
       */
      public int getZoneIdCount() {
        return zoneId_.size();
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param index The index of the element to return.
       * @return The zoneId at the given index.
       */
      public java.lang.String getZoneId(int index) {
        return zoneId_.get(index);
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param index The index of the value to return.
       * @return The bytes of the zoneId at the given index.
       */
      public com.google.protobuf.ByteString
          getZoneIdBytes(int index) {
        return zoneId_.getByteString(index);
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param index The index to set the value at.
       * @param value The zoneId to set.
       * @return This builder for chaining.
       */
      public Builder setZoneId(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureZoneIdIsMutable();
        zoneId_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param value The zoneId to add.
       * @return This builder for chaining.
       */
      public Builder addZoneId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureZoneIdIsMutable();
        zoneId_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param values The zoneId to add.
       * @return This builder for chaining.
       */
      public Builder addAllZoneId(
          java.lang.Iterable<java.lang.String> values) {
        ensureZoneIdIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, zoneId_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearZoneId() {
        zoneId_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * IDs of availability zones where Kafka brokers reside.
       * </pre>
       *
       * <code>repeated string zone_id = 4;</code>
       * @param value The bytes of the zoneId to add.
       * @return This builder for chaining.
       */
      public Builder addZoneIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureZoneIdIsMutable();
        zoneId_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value brokersCount_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> brokersCountBuilder_;
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       * @return Whether the brokersCount field is set.
       */
      public boolean hasBrokersCount() {
        return brokersCountBuilder_ != null || brokersCount_ != null;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       * @return The brokersCount.
       */
      public com.google.protobuf.Int64Value getBrokersCount() {
        if (brokersCountBuilder_ == null) {
          return brokersCount_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
        } else {
          return brokersCountBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder setBrokersCount(com.google.protobuf.Int64Value value) {
        if (brokersCountBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          brokersCount_ = value;
          onChanged();
        } else {
          brokersCountBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder setBrokersCount(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (brokersCountBuilder_ == null) {
          brokersCount_ = builderForValue.build();
          onChanged();
        } else {
          brokersCountBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder mergeBrokersCount(com.google.protobuf.Int64Value value) {
        if (brokersCountBuilder_ == null) {
          if (brokersCount_ != null) {
            brokersCount_ =
              com.google.protobuf.Int64Value.newBuilder(brokersCount_).mergeFrom(value).buildPartial();
          } else {
            brokersCount_ = value;
          }
          onChanged();
        } else {
          brokersCountBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public Builder clearBrokersCount() {
        if (brokersCountBuilder_ == null) {
          brokersCount_ = null;
          onChanged();
        } else {
          brokersCount_ = null;
          brokersCountBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getBrokersCountBuilder() {
        
        onChanged();
        return getBrokersCountFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getBrokersCountOrBuilder() {
        if (brokersCountBuilder_ != null) {
          return brokersCountBuilder_.getMessageOrBuilder();
        } else {
          return brokersCount_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : brokersCount_;
        }
      }
      /**
       * <pre>
       * The number of Kafka brokers deployed in each availability zone.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value brokers_count = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getBrokersCountFieldBuilder() {
        if (brokersCountBuilder_ == null) {
          brokersCountBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getBrokersCount(),
                  getParentForChildren(),
                  isClean());
          brokersCount_ = null;
        }
        return brokersCountBuilder_;
      }

      private boolean assignPublicIp_ ;
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       * @return The assignPublicIp.
       */
      @java.lang.Override
      public boolean getAssignPublicIp() {
        return assignPublicIp_;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       * @param value The assignPublicIp to set.
       * @return This builder for chaining.
       */
      public Builder setAssignPublicIp(boolean value) {
        
        assignPublicIp_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the cluster.
       * If the value is `true`, then Apache Kafka® cluster is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssignPublicIp() {
        
        assignPublicIp_ = false;
        onChanged();
        return this;
      }

      private boolean unmanagedTopics_ ;
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       * @return The unmanagedTopics.
       */
      @java.lang.Override
      public boolean getUnmanagedTopics() {
        return unmanagedTopics_;
      }
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       * @param value The unmanagedTopics to set.
       * @return This builder for chaining.
       */
      public Builder setUnmanagedTopics(boolean value) {
        
        unmanagedTopics_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Allows to manage topics via AdminAPI
       * </pre>
       *
       * <code>bool unmanaged_topics = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearUnmanagedTopics() {
        
        unmanagedTopics_ = false;
        onChanged();
        return this;
      }

      private boolean schemaRegistry_ ;
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       * @return The schemaRegistry.
       */
      @java.lang.Override
      public boolean getSchemaRegistry() {
        return schemaRegistry_;
      }
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       * @param value The schemaRegistry to set.
       * @return This builder for chaining.
       */
      public Builder setSchemaRegistry(boolean value) {
        
        schemaRegistry_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Enables managed schema registry on cluster
       * </pre>
       *
       * <code>bool schema_registry = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearSchemaRegistry() {
        
        schemaRegistry_ = false;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access access_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder> accessBuilder_;
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       * @return Whether the access field is set.
       */
      public boolean hasAccess() {
        return accessBuilder_ != null || access_ != null;
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       * @return The access.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getAccess() {
        if (accessBuilder_ == null) {
          return access_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.getDefaultInstance() : access_;
        } else {
          return accessBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public Builder setAccess(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access value) {
        if (accessBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          access_ = value;
          onChanged();
        } else {
          accessBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public Builder setAccess(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder builderForValue) {
        if (accessBuilder_ == null) {
          access_ = builderForValue.build();
          onChanged();
        } else {
          accessBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public Builder mergeAccess(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access value) {
        if (accessBuilder_ == null) {
          if (access_ != null) {
            access_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.newBuilder(access_).mergeFrom(value).buildPartial();
          } else {
            access_ = value;
          }
          onChanged();
        } else {
          accessBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public Builder clearAccess() {
        if (accessBuilder_ == null) {
          access_ = null;
          onChanged();
        } else {
          access_ = null;
          accessBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder getAccessBuilder() {
        
        onChanged();
        return getAccessFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder getAccessOrBuilder() {
        if (accessBuilder_ != null) {
          return accessBuilder_.getMessageOrBuilder();
        } else {
          return access_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.getDefaultInstance() : access_;
        }
      }
      /**
       * <pre>
       * Access policy for external services.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Access access = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder> 
          getAccessFieldBuilder() {
        if (accessBuilder_ == null) {
          accessBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder>(
                  getAccess(),
                  getParentForChildren(),
                  isClean());
          access_ = null;
        }
        return accessBuilder_;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig restApiConfig_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder> restApiConfigBuilder_;
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       * @return Whether the restApiConfig field is set.
       */
      public boolean hasRestApiConfig() {
        return restApiConfigBuilder_ != null || restApiConfig_ != null;
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       * @return The restApiConfig.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig getRestApiConfig() {
        if (restApiConfigBuilder_ == null) {
          return restApiConfig_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.getDefaultInstance() : restApiConfig_;
        } else {
          return restApiConfigBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public Builder setRestApiConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig value) {
        if (restApiConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          restApiConfig_ = value;
          onChanged();
        } else {
          restApiConfigBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public Builder setRestApiConfig(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder builderForValue) {
        if (restApiConfigBuilder_ == null) {
          restApiConfig_ = builderForValue.build();
          onChanged();
        } else {
          restApiConfigBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public Builder mergeRestApiConfig(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig value) {
        if (restApiConfigBuilder_ == null) {
          if (restApiConfig_ != null) {
            restApiConfig_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.newBuilder(restApiConfig_).mergeFrom(value).buildPartial();
          } else {
            restApiConfig_ = value;
          }
          onChanged();
        } else {
          restApiConfigBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public Builder clearRestApiConfig() {
        if (restApiConfigBuilder_ == null) {
          restApiConfig_ = null;
          onChanged();
        } else {
          restApiConfig_ = null;
          restApiConfigBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder getRestApiConfigBuilder() {
        
        onChanged();
        return getRestApiConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder getRestApiConfigOrBuilder() {
        if (restApiConfigBuilder_ != null) {
          return restApiConfigBuilder_.getMessageOrBuilder();
        } else {
          return restApiConfig_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.getDefaultInstance() : restApiConfig_;
        }
      }
      /**
       * <pre>
       * Configuration of REST API.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.ConfigSpec.RestAPIConfig rest_api_config = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder> 
          getRestApiConfigFieldBuilder() {
        if (restApiConfigBuilder_ == null) {
          restApiConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfig.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec.RestAPIConfigOrBuilder>(
                  getRestApiConfig(),
                  getParentForChildren(),
                  isClean());
          restApiConfig_ = null;
        }
        return restApiConfigBuilder_;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.ConfigSpec)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ConfigSpec>
        PARSER = new com.google.protobuf.AbstractParser<ConfigSpec>() {
      @java.lang.Override
      public ConfigSpec parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ConfigSpec(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ConfigSpec> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ConfigSpec> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ConfigSpec getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourcesOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Resources)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     * @return The resourcePresetId.
     */
    java.lang.String getResourcePresetId();
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     * @return The bytes for resourcePresetId.
     */
    com.google.protobuf.ByteString
        getResourcePresetIdBytes();

    /**
     * <pre>
     * Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.
     * </pre>
     *
     * <code>int64 disk_size = 2;</code>
     * @return The diskSize.
     */
    long getDiskSize();

    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     * @return The diskTypeId.
     */
    java.lang.String getDiskTypeId();
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     * @return The bytes for diskTypeId.
     */
    com.google.protobuf.ByteString
        getDiskTypeIdBytes();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Resources}
   */
  public static final class Resources extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Resources)
      ResourcesOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Resources.newBuilder() to construct.
    private Resources(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Resources() {
      resourcePresetId_ = "";
      diskTypeId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Resources();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Resources(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              resourcePresetId_ = s;
              break;
            }
            case 16: {

              diskSize_ = input.readInt64();
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              diskTypeId_ = s;
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder.class);
    }

    public static final int RESOURCE_PRESET_ID_FIELD_NUMBER = 1;
    private volatile java.lang.Object resourcePresetId_;
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     * @return The resourcePresetId.
     */
    @java.lang.Override
    public java.lang.String getResourcePresetId() {
      java.lang.Object ref = resourcePresetId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        resourcePresetId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the preset for computational resources available to a host (CPU, memory, etc.).
     * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
     * </pre>
     *
     * <code>string resource_preset_id = 1;</code>
     * @return The bytes for resourcePresetId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getResourcePresetIdBytes() {
      java.lang.Object ref = resourcePresetId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourcePresetId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DISK_SIZE_FIELD_NUMBER = 2;
    private long diskSize_;
    /**
     * <pre>
     * Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.
     * </pre>
     *
     * <code>int64 disk_size = 2;</code>
     * @return The diskSize.
     */
    @java.lang.Override
    public long getDiskSize() {
      return diskSize_;
    }

    public static final int DISK_TYPE_ID_FIELD_NUMBER = 3;
    private volatile java.lang.Object diskTypeId_;
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     * @return The diskTypeId.
     */
    @java.lang.Override
    public java.lang.String getDiskTypeId() {
      java.lang.Object ref = diskTypeId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        diskTypeId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Type of the storage environment for the host.
     * </pre>
     *
     * <code>string disk_type_id = 3;</code>
     * @return The bytes for diskTypeId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getDiskTypeIdBytes() {
      java.lang.Object ref = diskTypeId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diskTypeId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(resourcePresetId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, resourcePresetId_);
      }
      if (diskSize_ != 0L) {
        output.writeInt64(2, diskSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(diskTypeId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, diskTypeId_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(resourcePresetId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, resourcePresetId_);
      }
      if (diskSize_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, diskSize_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(diskTypeId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, diskTypeId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) obj;

      if (!getResourcePresetId()
          .equals(other.getResourcePresetId())) return false;
      if (getDiskSize()
          != other.getDiskSize()) return false;
      if (!getDiskTypeId()
          .equals(other.getDiskTypeId())) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + RESOURCE_PRESET_ID_FIELD_NUMBER;
      hash = (53 * hash) + getResourcePresetId().hashCode();
      hash = (37 * hash) + DISK_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getDiskSize());
      hash = (37 * hash) + DISK_TYPE_ID_FIELD_NUMBER;
      hash = (53 * hash) + getDiskTypeId().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Resources}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Resources)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        resourcePresetId_ = "";

        diskSize_ = 0L;

        diskTypeId_ = "";

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources(this);
        result.resourcePresetId_ = resourcePresetId_;
        result.diskSize_ = diskSize_;
        result.diskTypeId_ = diskTypeId_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance()) return this;
        if (!other.getResourcePresetId().isEmpty()) {
          resourcePresetId_ = other.resourcePresetId_;
          onChanged();
        }
        if (other.getDiskSize() != 0L) {
          setDiskSize(other.getDiskSize());
        }
        if (!other.getDiskTypeId().isEmpty()) {
          diskTypeId_ = other.diskTypeId_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object resourcePresetId_ = "";
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       * @return The resourcePresetId.
       */
      public java.lang.String getResourcePresetId() {
        java.lang.Object ref = resourcePresetId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          resourcePresetId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       * @return The bytes for resourcePresetId.
       */
      public com.google.protobuf.ByteString
          getResourcePresetIdBytes() {
        java.lang.Object ref = resourcePresetId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourcePresetId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       * @param value The resourcePresetId to set.
       * @return This builder for chaining.
       */
      public Builder setResourcePresetId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        resourcePresetId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearResourcePresetId() {
        
        resourcePresetId_ = getDefaultInstance().getResourcePresetId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the preset for computational resources available to a host (CPU, memory, etc.).
       * All available presets are listed in the [documentation](/docs/managed-kafka/concepts/instance-types).
       * </pre>
       *
       * <code>string resource_preset_id = 1;</code>
       * @param value The bytes for resourcePresetId to set.
       * @return This builder for chaining.
       */
      public Builder setResourcePresetIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        resourcePresetId_ = value;
        onChanged();
        return this;
      }

      private long diskSize_ ;
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       * @return The diskSize.
       */
      @java.lang.Override
      public long getDiskSize() {
        return diskSize_;
      }
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       * @param value The diskSize to set.
       * @return This builder for chaining.
       */
      public Builder setDiskSize(long value) {
        
        diskSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Volume of the storage available to a host, in bytes. Must be greater than 2 * partition segment size in bytes * partitions count, so each partition can have one active segment file and one closed segment file that can be deleted.
       * </pre>
       *
       * <code>int64 disk_size = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearDiskSize() {
        
        diskSize_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object diskTypeId_ = "";
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       * @return The diskTypeId.
       */
      public java.lang.String getDiskTypeId() {
        java.lang.Object ref = diskTypeId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          diskTypeId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       * @return The bytes for diskTypeId.
       */
      public com.google.protobuf.ByteString
          getDiskTypeIdBytes() {
        java.lang.Object ref = diskTypeId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diskTypeId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       * @param value The diskTypeId to set.
       * @return This builder for chaining.
       */
      public Builder setDiskTypeId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        diskTypeId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearDiskTypeId() {
        
        diskTypeId_ = getDefaultInstance().getDiskTypeId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Type of the storage environment for the host.
       * </pre>
       *
       * <code>string disk_type_id = 3;</code>
       * @param value The bytes for diskTypeId to set.
       * @return This builder for chaining.
       */
      public Builder setDiskTypeIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        diskTypeId_ = value;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Resources)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Resources)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Resources>
        PARSER = new com.google.protobuf.AbstractParser<Resources>() {
      @java.lang.Override
      public Resources parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Resources(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Resources> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Resources> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KafkaConfig2_8OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The enum numeric value on the wire for compressionType.
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The compressionType.
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return Whether the logFlushIntervalMessages field is set.
     */
    boolean hasLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return The logFlushIntervalMessages.
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return Whether the logFlushIntervalMs field is set.
     */
    boolean hasLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return The logFlushIntervalMs.
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder();

    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return Whether the logFlushSchedulerIntervalMs field is set.
     */
    boolean hasLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return The logFlushSchedulerIntervalMs.
     */
    com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder();

    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return Whether the logRetentionBytes field is set.
     */
    boolean hasLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return The logRetentionBytes.
     */
    com.google.protobuf.Int64Value getLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return Whether the logRetentionHours field is set.
     */
    boolean hasLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return The logRetentionHours.
     */
    com.google.protobuf.Int64Value getLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder();

    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return Whether the logRetentionMinutes field is set.
     */
    boolean hasLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return The logRetentionMinutes.
     */
    com.google.protobuf.Int64Value getLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return Whether the logRetentionMs field is set.
     */
    boolean hasLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return The logRetentionMs.
     */
    com.google.protobuf.Int64Value getLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder();

    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return Whether the logSegmentBytes field is set.
     */
    boolean hasLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return The logSegmentBytes.
     */
    com.google.protobuf.Int64Value getLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder();

    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return Whether the logPreallocate field is set.
     */
    boolean hasLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return The logPreallocate.
     */
    com.google.protobuf.BoolValue getLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder();

    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return Whether the socketSendBufferBytes field is set.
     */
    boolean hasSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return The socketSendBufferBytes.
     */
    com.google.protobuf.Int64Value getSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder();

    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return Whether the socketReceiveBufferBytes field is set.
     */
    boolean hasSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return The socketReceiveBufferBytes.
     */
    com.google.protobuf.Int64Value getSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder();

    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return Whether the autoCreateTopicsEnable field is set.
     */
    boolean hasAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return The autoCreateTopicsEnable.
     */
    com.google.protobuf.BoolValue getAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder();

    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return Whether the numPartitions field is set.
     */
    boolean hasNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return The numPartitions.
     */
    com.google.protobuf.Int64Value getNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder();

    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return Whether the defaultReplicationFactor field is set.
     */
    boolean hasDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return The defaultReplicationFactor.
     */
    com.google.protobuf.Int64Value getDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder();

    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return Whether the messageMaxBytes field is set.
     */
    boolean hasMessageMaxBytes();
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return The messageMaxBytes.
     */
    com.google.protobuf.Int64Value getMessageMaxBytes();
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder();

    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return Whether the replicaFetchMaxBytes field is set.
     */
    boolean hasReplicaFetchMaxBytes();
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return The replicaFetchMaxBytes.
     */
    com.google.protobuf.Int64Value getReplicaFetchMaxBytes();
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder();

    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return A list containing the sslCipherSuites.
     */
    java.util.List<java.lang.String>
        getSslCipherSuitesList();
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return The count of sslCipherSuites.
     */
    int getSslCipherSuitesCount();
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the element to return.
     * @return The sslCipherSuites at the given index.
     */
    java.lang.String getSslCipherSuites(int index);
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the value to return.
     * @return The bytes of the sslCipherSuites at the given index.
     */
    com.google.protobuf.ByteString
        getSslCipherSuitesBytes(int index);

    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return Whether the offsetsRetentionMinutes field is set.
     */
    boolean hasOffsetsRetentionMinutes();
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return The offsetsRetentionMinutes.
     */
    com.google.protobuf.Int64Value getOffsetsRetentionMinutes();
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the saslEnabledMechanisms.
     */
    java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return The count of saslEnabledMechanisms.
     */
    int getSaslEnabledMechanismsCount();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the element to return.
     * @return The saslEnabledMechanisms at the given index.
     */
    yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index);
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
     */
    java.util.List<java.lang.Integer>
    getSaslEnabledMechanismsValueList();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the value to return.
     * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
     */
    int getSaslEnabledMechanismsValue(int index);
  }
  /**
   * <pre>
   * Kafka version 2.8 broker configuration.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_8}
   */
  public static final class KafkaConfig2_8 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
      KafkaConfig2_8OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KafkaConfig2_8.newBuilder() to construct.
    private KafkaConfig2_8(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KafkaConfig2_8() {
      compressionType_ = 0;
      sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      saslEnabledMechanisms_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new KafkaConfig2_8();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KafkaConfig2_8(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMessages_ != null) {
                subBuilder = logFlushIntervalMessages_.toBuilder();
              }
              logFlushIntervalMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMessages_);
                logFlushIntervalMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMs_ != null) {
                subBuilder = logFlushIntervalMs_.toBuilder();
              }
              logFlushIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMs_);
                logFlushIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushSchedulerIntervalMs_ != null) {
                subBuilder = logFlushSchedulerIntervalMs_.toBuilder();
              }
              logFlushSchedulerIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushSchedulerIntervalMs_);
                logFlushSchedulerIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionBytes_ != null) {
                subBuilder = logRetentionBytes_.toBuilder();
              }
              logRetentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionBytes_);
                logRetentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionHours_ != null) {
                subBuilder = logRetentionHours_.toBuilder();
              }
              logRetentionHours_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionHours_);
                logRetentionHours_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMinutes_ != null) {
                subBuilder = logRetentionMinutes_.toBuilder();
              }
              logRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMinutes_);
                logRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMs_ != null) {
                subBuilder = logRetentionMs_.toBuilder();
              }
              logRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMs_);
                logRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logSegmentBytes_ != null) {
                subBuilder = logSegmentBytes_.toBuilder();
              }
              logSegmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logSegmentBytes_);
                logSegmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (logPreallocate_ != null) {
                subBuilder = logPreallocate_.toBuilder();
              }
              logPreallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logPreallocate_);
                logPreallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketSendBufferBytes_ != null) {
                subBuilder = socketSendBufferBytes_.toBuilder();
              }
              socketSendBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketSendBufferBytes_);
                socketSendBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketReceiveBufferBytes_ != null) {
                subBuilder = socketReceiveBufferBytes_.toBuilder();
              }
              socketReceiveBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketReceiveBufferBytes_);
                socketReceiveBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (autoCreateTopicsEnable_ != null) {
                subBuilder = autoCreateTopicsEnable_.toBuilder();
              }
              autoCreateTopicsEnable_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(autoCreateTopicsEnable_);
                autoCreateTopicsEnable_ = subBuilder.buildPartial();
              }

              break;
            }
            case 114: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (numPartitions_ != null) {
                subBuilder = numPartitions_.toBuilder();
              }
              numPartitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(numPartitions_);
                numPartitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 122: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (defaultReplicationFactor_ != null) {
                subBuilder = defaultReplicationFactor_.toBuilder();
              }
              defaultReplicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultReplicationFactor_);
                defaultReplicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            case 130: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (messageMaxBytes_ != null) {
                subBuilder = messageMaxBytes_.toBuilder();
              }
              messageMaxBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(messageMaxBytes_);
                messageMaxBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 138: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (replicaFetchMaxBytes_ != null) {
                subBuilder = replicaFetchMaxBytes_.toBuilder();
              }
              replicaFetchMaxBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(replicaFetchMaxBytes_);
                replicaFetchMaxBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 146: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                sslCipherSuites_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              sslCipherSuites_.add(s);
              break;
            }
            case 154: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (offsetsRetentionMinutes_ != null) {
                subBuilder = offsetsRetentionMinutes_.toBuilder();
              }
              offsetsRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(offsetsRetentionMinutes_);
                offsetsRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 160: {
              int rawValue = input.readEnum();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000002;
              }
              saslEnabledMechanisms_.add(rawValue);
              break;
            }
            case 162: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                  saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                saslEnabledMechanisms_.add(rawValue);
              }
              input.popLimit(oldLimit);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = sslCipherSuites_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder.class);
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 1;
    private int compressionType_;
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The enum numeric value on the wire for compressionType.
     */
    @java.lang.Override public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The compressionType.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value logFlushIntervalMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return Whether the logFlushIntervalMessages field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return The logFlushIntervalMessages.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
      return getLogFlushIntervalMessages();
    }

    public static final int LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value logFlushIntervalMs_;
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return Whether the logFlushIntervalMs field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushIntervalMs() {
      return logFlushIntervalMs_ != null;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return The logFlushIntervalMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
      return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
      return getLogFlushIntervalMs();
    }

    public static final int LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return Whether the logFlushSchedulerIntervalMs field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ != null;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return The logFlushSchedulerIntervalMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
      return getLogFlushSchedulerIntervalMs();
    }

    public static final int LOG_RETENTION_BYTES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value logRetentionBytes_;
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return Whether the logRetentionBytes field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionBytes() {
      return logRetentionBytes_ != null;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return The logRetentionBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionBytes() {
      return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
      return getLogRetentionBytes();
    }

    public static final int LOG_RETENTION_HOURS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value logRetentionHours_;
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return Whether the logRetentionHours field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionHours() {
      return logRetentionHours_ != null;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return The logRetentionHours.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionHours() {
      return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
      return getLogRetentionHours();
    }

    public static final int LOG_RETENTION_MINUTES_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value logRetentionMinutes_;
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return Whether the logRetentionMinutes field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionMinutes() {
      return logRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return The logRetentionMinutes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionMinutes() {
      return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
      return getLogRetentionMinutes();
    }

    public static final int LOG_RETENTION_MS_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value logRetentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return Whether the logRetentionMs field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionMs() {
      return logRetentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return The logRetentionMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionMs() {
      return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
      return getLogRetentionMs();
    }

    public static final int LOG_SEGMENT_BYTES_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value logSegmentBytes_;
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return Whether the logSegmentBytes field is set.
     */
    @java.lang.Override
    public boolean hasLogSegmentBytes() {
      return logSegmentBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return The logSegmentBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogSegmentBytes() {
      return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
      return getLogSegmentBytes();
    }

    public static final int LOG_PREALLOCATE_FIELD_NUMBER = 10;
    private com.google.protobuf.BoolValue logPreallocate_;
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return Whether the logPreallocate field is set.
     */
    @java.lang.Override
    public boolean hasLogPreallocate() {
      return logPreallocate_ != null;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return The logPreallocate.
     */
    @java.lang.Override
    public com.google.protobuf.BoolValue getLogPreallocate() {
      return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    @java.lang.Override
    public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
      return getLogPreallocate();
    }

    public static final int SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value socketSendBufferBytes_;
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return Whether the socketSendBufferBytes field is set.
     */
    @java.lang.Override
    public boolean hasSocketSendBufferBytes() {
      return socketSendBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return The socketSendBufferBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
      return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
      return getSocketSendBufferBytes();
    }

    public static final int SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return Whether the socketReceiveBufferBytes field is set.
     */
    @java.lang.Override
    public boolean hasSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return The socketReceiveBufferBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
      return getSocketReceiveBufferBytes();
    }

    public static final int AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return Whether the autoCreateTopicsEnable field is set.
     */
    @java.lang.Override
    public boolean hasAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ != null;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return The autoCreateTopicsEnable.
     */
    @java.lang.Override
    public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    @java.lang.Override
    public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
      return getAutoCreateTopicsEnable();
    }

    public static final int NUM_PARTITIONS_FIELD_NUMBER = 14;
    private com.google.protobuf.Int64Value numPartitions_;
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return Whether the numPartitions field is set.
     */
    @java.lang.Override
    public boolean hasNumPartitions() {
      return numPartitions_ != null;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return The numPartitions.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getNumPartitions() {
      return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
      return getNumPartitions();
    }

    public static final int DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER = 15;
    private com.google.protobuf.Int64Value defaultReplicationFactor_;
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return Whether the defaultReplicationFactor field is set.
     */
    @java.lang.Override
    public boolean hasDefaultReplicationFactor() {
      return defaultReplicationFactor_ != null;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return The defaultReplicationFactor.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
      return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
      return getDefaultReplicationFactor();
    }

    public static final int MESSAGE_MAX_BYTES_FIELD_NUMBER = 16;
    private com.google.protobuf.Int64Value messageMaxBytes_;
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return Whether the messageMaxBytes field is set.
     */
    @java.lang.Override
    public boolean hasMessageMaxBytes() {
      return messageMaxBytes_ != null;
    }
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return The messageMaxBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getMessageMaxBytes() {
      return messageMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
    }
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder() {
      return getMessageMaxBytes();
    }

    public static final int REPLICA_FETCH_MAX_BYTES_FIELD_NUMBER = 17;
    private com.google.protobuf.Int64Value replicaFetchMaxBytes_;
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return Whether the replicaFetchMaxBytes field is set.
     */
    @java.lang.Override
    public boolean hasReplicaFetchMaxBytes() {
      return replicaFetchMaxBytes_ != null;
    }
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return The replicaFetchMaxBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getReplicaFetchMaxBytes() {
      return replicaFetchMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
    }
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder() {
      return getReplicaFetchMaxBytes();
    }

    public static final int SSL_CIPHER_SUITES_FIELD_NUMBER = 18;
    private com.google.protobuf.LazyStringList sslCipherSuites_;
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return A list containing the sslCipherSuites.
     */
    public com.google.protobuf.ProtocolStringList
        getSslCipherSuitesList() {
      return sslCipherSuites_;
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return The count of sslCipherSuites.
     */
    public int getSslCipherSuitesCount() {
      return sslCipherSuites_.size();
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the element to return.
     * @return The sslCipherSuites at the given index.
     */
    public java.lang.String getSslCipherSuites(int index) {
      return sslCipherSuites_.get(index);
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the value to return.
     * @return The bytes of the sslCipherSuites at the given index.
     */
    public com.google.protobuf.ByteString
        getSslCipherSuitesBytes(int index) {
      return sslCipherSuites_.getByteString(index);
    }

    public static final int OFFSETS_RETENTION_MINUTES_FIELD_NUMBER = 19;
    private com.google.protobuf.Int64Value offsetsRetentionMinutes_;
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return Whether the offsetsRetentionMinutes field is set.
     */
    @java.lang.Override
    public boolean hasOffsetsRetentionMinutes() {
      return offsetsRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return The offsetsRetentionMinutes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getOffsetsRetentionMinutes() {
      return offsetsRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
    }
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder() {
      return getOffsetsRetentionMinutes();
    }

    public static final int SASL_ENABLED_MECHANISMS_FIELD_NUMBER = 20;
    private java.util.List<java.lang.Integer> saslEnabledMechanisms_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> saslEnabledMechanisms_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>() {
              public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism convert(java.lang.Integer from) {
                @SuppressWarnings("deprecation")
                yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism result = yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism.valueOf(from);
                return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism.UNRECOGNIZED : result;
              }
            };
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the saslEnabledMechanisms.
     */
    @java.lang.Override
    public java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>(saslEnabledMechanisms_, saslEnabledMechanisms_converter_);
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return The count of saslEnabledMechanisms.
     */
    @java.lang.Override
    public int getSaslEnabledMechanismsCount() {
      return saslEnabledMechanisms_.size();
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the element to return.
     * @return The saslEnabledMechanisms at the given index.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index) {
      return saslEnabledMechanisms_converter_.convert(saslEnabledMechanisms_.get(index));
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
     */
    @java.lang.Override
    public java.util.List<java.lang.Integer>
    getSaslEnabledMechanismsValueList() {
      return saslEnabledMechanisms_;
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the value to return.
     * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
     */
    @java.lang.Override
    public int getSaslEnabledMechanismsValue(int index) {
      return saslEnabledMechanisms_.get(index);
    }
    private int saslEnabledMechanismsMemoizedSerializedSize;

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        output.writeMessage(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        output.writeMessage(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        output.writeMessage(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        output.writeMessage(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        output.writeMessage(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        output.writeMessage(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        output.writeMessage(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        output.writeMessage(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        output.writeMessage(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        output.writeMessage(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        output.writeMessage(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        output.writeMessage(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        output.writeMessage(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        output.writeMessage(15, getDefaultReplicationFactor());
      }
      if (messageMaxBytes_ != null) {
        output.writeMessage(16, getMessageMaxBytes());
      }
      if (replicaFetchMaxBytes_ != null) {
        output.writeMessage(17, getReplicaFetchMaxBytes());
      }
      for (int i = 0; i < sslCipherSuites_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 18, sslCipherSuites_.getRaw(i));
      }
      if (offsetsRetentionMinutes_ != null) {
        output.writeMessage(19, getOffsetsRetentionMinutes());
      }
      if (getSaslEnabledMechanismsList().size() > 0) {
        output.writeUInt32NoTag(162);
        output.writeUInt32NoTag(saslEnabledMechanismsMemoizedSerializedSize);
      }
      for (int i = 0; i < saslEnabledMechanisms_.size(); i++) {
        output.writeEnumNoTag(saslEnabledMechanisms_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDefaultReplicationFactor());
      }
      if (messageMaxBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, getMessageMaxBytes());
      }
      if (replicaFetchMaxBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, getReplicaFetchMaxBytes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < sslCipherSuites_.size(); i++) {
          dataSize += computeStringSizeNoTag(sslCipherSuites_.getRaw(i));
        }
        size += dataSize;
        size += 2 * getSslCipherSuitesList().size();
      }
      if (offsetsRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, getOffsetsRetentionMinutes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < saslEnabledMechanisms_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(saslEnabledMechanisms_.get(i));
        }
        size += dataSize;
        if (!getSaslEnabledMechanismsList().isEmpty()) {  size += 2;
          size += com.google.protobuf.CodedOutputStream
            .computeUInt32SizeNoTag(dataSize);
        }saslEnabledMechanismsMemoizedSerializedSize = dataSize;
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) obj;

      if (compressionType_ != other.compressionType_) return false;
      if (hasLogFlushIntervalMessages() != other.hasLogFlushIntervalMessages()) return false;
      if (hasLogFlushIntervalMessages()) {
        if (!getLogFlushIntervalMessages()
            .equals(other.getLogFlushIntervalMessages())) return false;
      }
      if (hasLogFlushIntervalMs() != other.hasLogFlushIntervalMs()) return false;
      if (hasLogFlushIntervalMs()) {
        if (!getLogFlushIntervalMs()
            .equals(other.getLogFlushIntervalMs())) return false;
      }
      if (hasLogFlushSchedulerIntervalMs() != other.hasLogFlushSchedulerIntervalMs()) return false;
      if (hasLogFlushSchedulerIntervalMs()) {
        if (!getLogFlushSchedulerIntervalMs()
            .equals(other.getLogFlushSchedulerIntervalMs())) return false;
      }
      if (hasLogRetentionBytes() != other.hasLogRetentionBytes()) return false;
      if (hasLogRetentionBytes()) {
        if (!getLogRetentionBytes()
            .equals(other.getLogRetentionBytes())) return false;
      }
      if (hasLogRetentionHours() != other.hasLogRetentionHours()) return false;
      if (hasLogRetentionHours()) {
        if (!getLogRetentionHours()
            .equals(other.getLogRetentionHours())) return false;
      }
      if (hasLogRetentionMinutes() != other.hasLogRetentionMinutes()) return false;
      if (hasLogRetentionMinutes()) {
        if (!getLogRetentionMinutes()
            .equals(other.getLogRetentionMinutes())) return false;
      }
      if (hasLogRetentionMs() != other.hasLogRetentionMs()) return false;
      if (hasLogRetentionMs()) {
        if (!getLogRetentionMs()
            .equals(other.getLogRetentionMs())) return false;
      }
      if (hasLogSegmentBytes() != other.hasLogSegmentBytes()) return false;
      if (hasLogSegmentBytes()) {
        if (!getLogSegmentBytes()
            .equals(other.getLogSegmentBytes())) return false;
      }
      if (hasLogPreallocate() != other.hasLogPreallocate()) return false;
      if (hasLogPreallocate()) {
        if (!getLogPreallocate()
            .equals(other.getLogPreallocate())) return false;
      }
      if (hasSocketSendBufferBytes() != other.hasSocketSendBufferBytes()) return false;
      if (hasSocketSendBufferBytes()) {
        if (!getSocketSendBufferBytes()
            .equals(other.getSocketSendBufferBytes())) return false;
      }
      if (hasSocketReceiveBufferBytes() != other.hasSocketReceiveBufferBytes()) return false;
      if (hasSocketReceiveBufferBytes()) {
        if (!getSocketReceiveBufferBytes()
            .equals(other.getSocketReceiveBufferBytes())) return false;
      }
      if (hasAutoCreateTopicsEnable() != other.hasAutoCreateTopicsEnable()) return false;
      if (hasAutoCreateTopicsEnable()) {
        if (!getAutoCreateTopicsEnable()
            .equals(other.getAutoCreateTopicsEnable())) return false;
      }
      if (hasNumPartitions() != other.hasNumPartitions()) return false;
      if (hasNumPartitions()) {
        if (!getNumPartitions()
            .equals(other.getNumPartitions())) return false;
      }
      if (hasDefaultReplicationFactor() != other.hasDefaultReplicationFactor()) return false;
      if (hasDefaultReplicationFactor()) {
        if (!getDefaultReplicationFactor()
            .equals(other.getDefaultReplicationFactor())) return false;
      }
      if (hasMessageMaxBytes() != other.hasMessageMaxBytes()) return false;
      if (hasMessageMaxBytes()) {
        if (!getMessageMaxBytes()
            .equals(other.getMessageMaxBytes())) return false;
      }
      if (hasReplicaFetchMaxBytes() != other.hasReplicaFetchMaxBytes()) return false;
      if (hasReplicaFetchMaxBytes()) {
        if (!getReplicaFetchMaxBytes()
            .equals(other.getReplicaFetchMaxBytes())) return false;
      }
      if (!getSslCipherSuitesList()
          .equals(other.getSslCipherSuitesList())) return false;
      if (hasOffsetsRetentionMinutes() != other.hasOffsetsRetentionMinutes()) return false;
      if (hasOffsetsRetentionMinutes()) {
        if (!getOffsetsRetentionMinutes()
            .equals(other.getOffsetsRetentionMinutes())) return false;
      }
      if (!saslEnabledMechanisms_.equals(other.saslEnabledMechanisms_)) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasLogFlushIntervalMessages()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMessages().hashCode();
      }
      if (hasLogFlushIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMs().hashCode();
      }
      if (hasLogFlushSchedulerIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushSchedulerIntervalMs().hashCode();
      }
      if (hasLogRetentionBytes()) {
        hash = (37 * hash) + LOG_RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionBytes().hashCode();
      }
      if (hasLogRetentionHours()) {
        hash = (37 * hash) + LOG_RETENTION_HOURS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionHours().hashCode();
      }
      if (hasLogRetentionMinutes()) {
        hash = (37 * hash) + LOG_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMinutes().hashCode();
      }
      if (hasLogRetentionMs()) {
        hash = (37 * hash) + LOG_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMs().hashCode();
      }
      if (hasLogSegmentBytes()) {
        hash = (37 * hash) + LOG_SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogSegmentBytes().hashCode();
      }
      if (hasLogPreallocate()) {
        hash = (37 * hash) + LOG_PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getLogPreallocate().hashCode();
      }
      if (hasSocketSendBufferBytes()) {
        hash = (37 * hash) + SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketSendBufferBytes().hashCode();
      }
      if (hasSocketReceiveBufferBytes()) {
        hash = (37 * hash) + SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketReceiveBufferBytes().hashCode();
      }
      if (hasAutoCreateTopicsEnable()) {
        hash = (37 * hash) + AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + getAutoCreateTopicsEnable().hashCode();
      }
      if (hasNumPartitions()) {
        hash = (37 * hash) + NUM_PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumPartitions().hashCode();
      }
      if (hasDefaultReplicationFactor()) {
        hash = (37 * hash) + DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultReplicationFactor().hashCode();
      }
      if (hasMessageMaxBytes()) {
        hash = (37 * hash) + MESSAGE_MAX_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getMessageMaxBytes().hashCode();
      }
      if (hasReplicaFetchMaxBytes()) {
        hash = (37 * hash) + REPLICA_FETCH_MAX_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getReplicaFetchMaxBytes().hashCode();
      }
      if (getSslCipherSuitesCount() > 0) {
        hash = (37 * hash) + SSL_CIPHER_SUITES_FIELD_NUMBER;
        hash = (53 * hash) + getSslCipherSuitesList().hashCode();
      }
      if (hasOffsetsRetentionMinutes()) {
        hash = (37 * hash) + OFFSETS_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getOffsetsRetentionMinutes().hashCode();
      }
      if (getSaslEnabledMechanismsCount() > 0) {
        hash = (37 * hash) + SASL_ENABLED_MECHANISMS_FIELD_NUMBER;
        hash = (53 * hash) + saslEnabledMechanisms_.hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Kafka version 2.8 broker configuration.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig2_8}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        compressionType_ = 0;

        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = null;
        } else {
          messageMaxBytes_ = null;
          messageMaxBytesBuilder_ = null;
        }
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = null;
        } else {
          replicaFetchMaxBytes_ = null;
          replicaFetchMaxBytesBuilder_ = null;
        }
        sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = null;
        } else {
          offsetsRetentionMinutes_ = null;
          offsetsRetentionMinutesBuilder_ = null;
        }
        saslEnabledMechanisms_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8(this);
        int from_bitField0_ = bitField0_;
        result.compressionType_ = compressionType_;
        if (logFlushIntervalMessagesBuilder_ == null) {
          result.logFlushIntervalMessages_ = logFlushIntervalMessages_;
        } else {
          result.logFlushIntervalMessages_ = logFlushIntervalMessagesBuilder_.build();
        }
        if (logFlushIntervalMsBuilder_ == null) {
          result.logFlushIntervalMs_ = logFlushIntervalMs_;
        } else {
          result.logFlushIntervalMs_ = logFlushIntervalMsBuilder_.build();
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMs_;
        } else {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMsBuilder_.build();
        }
        if (logRetentionBytesBuilder_ == null) {
          result.logRetentionBytes_ = logRetentionBytes_;
        } else {
          result.logRetentionBytes_ = logRetentionBytesBuilder_.build();
        }
        if (logRetentionHoursBuilder_ == null) {
          result.logRetentionHours_ = logRetentionHours_;
        } else {
          result.logRetentionHours_ = logRetentionHoursBuilder_.build();
        }
        if (logRetentionMinutesBuilder_ == null) {
          result.logRetentionMinutes_ = logRetentionMinutes_;
        } else {
          result.logRetentionMinutes_ = logRetentionMinutesBuilder_.build();
        }
        if (logRetentionMsBuilder_ == null) {
          result.logRetentionMs_ = logRetentionMs_;
        } else {
          result.logRetentionMs_ = logRetentionMsBuilder_.build();
        }
        if (logSegmentBytesBuilder_ == null) {
          result.logSegmentBytes_ = logSegmentBytes_;
        } else {
          result.logSegmentBytes_ = logSegmentBytesBuilder_.build();
        }
        if (logPreallocateBuilder_ == null) {
          result.logPreallocate_ = logPreallocate_;
        } else {
          result.logPreallocate_ = logPreallocateBuilder_.build();
        }
        if (socketSendBufferBytesBuilder_ == null) {
          result.socketSendBufferBytes_ = socketSendBufferBytes_;
        } else {
          result.socketSendBufferBytes_ = socketSendBufferBytesBuilder_.build();
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytes_;
        } else {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytesBuilder_.build();
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnable_;
        } else {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnableBuilder_.build();
        }
        if (numPartitionsBuilder_ == null) {
          result.numPartitions_ = numPartitions_;
        } else {
          result.numPartitions_ = numPartitionsBuilder_.build();
        }
        if (defaultReplicationFactorBuilder_ == null) {
          result.defaultReplicationFactor_ = defaultReplicationFactor_;
        } else {
          result.defaultReplicationFactor_ = defaultReplicationFactorBuilder_.build();
        }
        if (messageMaxBytesBuilder_ == null) {
          result.messageMaxBytes_ = messageMaxBytes_;
        } else {
          result.messageMaxBytes_ = messageMaxBytesBuilder_.build();
        }
        if (replicaFetchMaxBytesBuilder_ == null) {
          result.replicaFetchMaxBytes_ = replicaFetchMaxBytes_;
        } else {
          result.replicaFetchMaxBytes_ = replicaFetchMaxBytesBuilder_.build();
        }
        if (((bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = sslCipherSuites_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.sslCipherSuites_ = sslCipherSuites_;
        if (offsetsRetentionMinutesBuilder_ == null) {
          result.offsetsRetentionMinutes_ = offsetsRetentionMinutes_;
        } else {
          result.offsetsRetentionMinutes_ = offsetsRetentionMinutesBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.saslEnabledMechanisms_ = saslEnabledMechanisms_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8.getDefaultInstance()) return this;
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasLogFlushIntervalMessages()) {
          mergeLogFlushIntervalMessages(other.getLogFlushIntervalMessages());
        }
        if (other.hasLogFlushIntervalMs()) {
          mergeLogFlushIntervalMs(other.getLogFlushIntervalMs());
        }
        if (other.hasLogFlushSchedulerIntervalMs()) {
          mergeLogFlushSchedulerIntervalMs(other.getLogFlushSchedulerIntervalMs());
        }
        if (other.hasLogRetentionBytes()) {
          mergeLogRetentionBytes(other.getLogRetentionBytes());
        }
        if (other.hasLogRetentionHours()) {
          mergeLogRetentionHours(other.getLogRetentionHours());
        }
        if (other.hasLogRetentionMinutes()) {
          mergeLogRetentionMinutes(other.getLogRetentionMinutes());
        }
        if (other.hasLogRetentionMs()) {
          mergeLogRetentionMs(other.getLogRetentionMs());
        }
        if (other.hasLogSegmentBytes()) {
          mergeLogSegmentBytes(other.getLogSegmentBytes());
        }
        if (other.hasLogPreallocate()) {
          mergeLogPreallocate(other.getLogPreallocate());
        }
        if (other.hasSocketSendBufferBytes()) {
          mergeSocketSendBufferBytes(other.getSocketSendBufferBytes());
        }
        if (other.hasSocketReceiveBufferBytes()) {
          mergeSocketReceiveBufferBytes(other.getSocketReceiveBufferBytes());
        }
        if (other.hasAutoCreateTopicsEnable()) {
          mergeAutoCreateTopicsEnable(other.getAutoCreateTopicsEnable());
        }
        if (other.hasNumPartitions()) {
          mergeNumPartitions(other.getNumPartitions());
        }
        if (other.hasDefaultReplicationFactor()) {
          mergeDefaultReplicationFactor(other.getDefaultReplicationFactor());
        }
        if (other.hasMessageMaxBytes()) {
          mergeMessageMaxBytes(other.getMessageMaxBytes());
        }
        if (other.hasReplicaFetchMaxBytes()) {
          mergeReplicaFetchMaxBytes(other.getReplicaFetchMaxBytes());
        }
        if (!other.sslCipherSuites_.isEmpty()) {
          if (sslCipherSuites_.isEmpty()) {
            sslCipherSuites_ = other.sslCipherSuites_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureSslCipherSuitesIsMutable();
            sslCipherSuites_.addAll(other.sslCipherSuites_);
          }
          onChanged();
        }
        if (other.hasOffsetsRetentionMinutes()) {
          mergeOffsetsRetentionMinutes(other.getOffsetsRetentionMinutes());
        }
        if (!other.saslEnabledMechanisms_.isEmpty()) {
          if (saslEnabledMechanisms_.isEmpty()) {
            saslEnabledMechanisms_ = other.saslEnabledMechanisms_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureSaslEnabledMechanismsIsMutable();
            saslEnabledMechanisms_.addAll(other.saslEnabledMechanisms_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int compressionType_ = 0;
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return The enum numeric value on the wire for compressionType.
       */
      @java.lang.Override public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @param value The enum numeric value on the wire for compressionType to set.
       * @return This builder for chaining.
       */
      public Builder setCompressionTypeValue(int value) {
        
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return The compressionType.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @param value The compressionType to set.
       * @return This builder for chaining.
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMessages_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       * @return Whether the logFlushIntervalMessages field is set.
       */
      public boolean hasLogFlushIntervalMessages() {
        return logFlushIntervalMessagesBuilder_ != null || logFlushIntervalMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       * @return The logFlushIntervalMessages.
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        } else {
          return logFlushIntervalMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMessages_ = value;
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder mergeLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (logFlushIntervalMessages_ != null) {
            logFlushIntervalMessages_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMessages_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMessages_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder clearLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
          onChanged();
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMessagesBuilder() {
        
        onChanged();
        return getLogFlushIntervalMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
        if (logFlushIntervalMessagesBuilder_ != null) {
          return logFlushIntervalMessagesBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMessagesFieldBuilder() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMessages(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMessages_ = null;
        }
        return logFlushIntervalMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMsBuilder_;
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       * @return Whether the logFlushIntervalMs field is set.
       */
      public boolean hasLogFlushIntervalMs() {
        return logFlushIntervalMsBuilder_ != null || logFlushIntervalMs_ != null;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       * @return The logFlushIntervalMs.
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        } else {
          return logFlushIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMs_ = value;
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder mergeLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (logFlushIntervalMs_ != null) {
            logFlushIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder clearLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
          onChanged();
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
        if (logFlushIntervalMsBuilder_ != null) {
          return logFlushIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMsFieldBuilder() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMs_ = null;
        }
        return logFlushIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushSchedulerIntervalMsBuilder_;
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       * @return Whether the logFlushSchedulerIntervalMs field is set.
       */
      public boolean hasLogFlushSchedulerIntervalMs() {
        return logFlushSchedulerIntervalMsBuilder_ != null || logFlushSchedulerIntervalMs_ != null;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       * @return The logFlushSchedulerIntervalMs.
       */
      public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        } else {
          return logFlushSchedulerIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushSchedulerIntervalMs_ = value;
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder mergeLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (logFlushSchedulerIntervalMs_ != null) {
            logFlushSchedulerIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushSchedulerIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushSchedulerIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder clearLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
          onChanged();
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushSchedulerIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushSchedulerIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ != null) {
          return logFlushSchedulerIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushSchedulerIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushSchedulerIntervalMsFieldBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushSchedulerIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushSchedulerIntervalMs_ = null;
        }
        return logFlushSchedulerIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionBytesBuilder_;
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       * @return Whether the logRetentionBytes field is set.
       */
      public boolean hasLogRetentionBytes() {
        return logRetentionBytesBuilder_ != null || logRetentionBytes_ != null;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       * @return The logRetentionBytes.
       */
      public com.google.protobuf.Int64Value getLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        } else {
          return logRetentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionBytes_ = value;
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder mergeLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (logRetentionBytes_ != null) {
            logRetentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionBytes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionBytes_ = value;
          }
          onChanged();
        } else {
          logRetentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder clearLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
          onChanged();
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionBytesBuilder() {
        
        onChanged();
        return getLogRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
        if (logRetentionBytesBuilder_ != null) {
          return logRetentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig2_8.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionBytesFieldBuilder() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          logRetentionBytes_ = null;
        }
        return logRetentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionHours_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionHoursBuilder_;
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       * @return Whether the logRetentionHours field is set.
       */
      public boolean hasLogRetentionHours() {
        return logRetentionHoursBuilder_ != null || logRetentionHours_ != null;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       * @return The logRetentionHours.
       */
      public com.google.protobuf.Int64Value getLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        } else {
          return logRetentionHoursBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionHours_ = value;
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder mergeLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (logRetentionHours_ != null) {
            logRetentionHours_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionHours_).mergeFrom(value).buildPartial();
          } else {
            logRetentionHours_ = value;
          }
          onChanged();
        } else {
          logRetentionHoursBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder clearLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
          onChanged();
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionHoursBuilder() {
        
        onChanged();
        return getLogRetentionHoursFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
        if (logRetentionHoursBuilder_ != null) {
          return logRetentionHoursBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionHours_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionHoursFieldBuilder() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHoursBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionHours(),
                  getParentForChildren(),
                  isClean());
          logRetentionHours_ = null;
        }
        return logRetentionHoursBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMinutes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMinutesBuilder_;
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       * @return Whether the logRetentionMinutes field is set.
       */
      public boolean hasLogRetentionMinutes() {
        return logRetentionMinutesBuilder_ != null || logRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       * @return The logRetentionMinutes.
       */
      public com.google.protobuf.Int64Value getLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        } else {
          return logRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMinutes_ = value;
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder mergeLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (logRetentionMinutes_ != null) {
            logRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          logRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder clearLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
          onChanged();
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMinutesBuilder() {
        
        onChanged();
        return getLogRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
        if (logRetentionMinutesBuilder_ != null) {
          return logRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMinutesFieldBuilder() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          logRetentionMinutes_ = null;
        }
        return logRetentionMinutesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       * @return Whether the logRetentionMs field is set.
       */
      public boolean hasLogRetentionMs() {
        return logRetentionMsBuilder_ != null || logRetentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       * @return The logRetentionMs.
       */
      public com.google.protobuf.Int64Value getLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        } else {
          return logRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMs_ = value;
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder mergeLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (logRetentionMs_ != null) {
            logRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMs_ = value;
          }
          onChanged();
        } else {
          logRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder clearLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
          onChanged();
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMsBuilder() {
        
        onChanged();
        return getLogRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
        if (logRetentionMsBuilder_ != null) {
          return logRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMsFieldBuilder() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMs(),
                  getParentForChildren(),
                  isClean());
          logRetentionMs_ = null;
        }
        return logRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value logSegmentBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logSegmentBytesBuilder_;
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       * @return Whether the logSegmentBytes field is set.
       */
      public boolean hasLogSegmentBytes() {
        return logSegmentBytesBuilder_ != null || logSegmentBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       * @return The logSegmentBytes.
       */
      public com.google.protobuf.Int64Value getLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        } else {
          return logSegmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logSegmentBytes_ = value;
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder mergeLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (logSegmentBytes_ != null) {
            logSegmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logSegmentBytes_).mergeFrom(value).buildPartial();
          } else {
            logSegmentBytes_ = value;
          }
          onChanged();
        } else {
          logSegmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder clearLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
          onChanged();
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogSegmentBytesBuilder() {
        
        onChanged();
        return getLogSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
        if (logSegmentBytesBuilder_ != null) {
          return logSegmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return logSegmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogSegmentBytesFieldBuilder() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          logSegmentBytes_ = null;
        }
        return logSegmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue logPreallocate_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> logPreallocateBuilder_;
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       * @return Whether the logPreallocate field is set.
       */
      public boolean hasLogPreallocate() {
        return logPreallocateBuilder_ != null || logPreallocate_ != null;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       * @return The logPreallocate.
       */
      public com.google.protobuf.BoolValue getLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        } else {
          return logPreallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logPreallocate_ = value;
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = builderForValue.build();
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder mergeLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (logPreallocate_ != null) {
            logPreallocate_ =
              com.google.protobuf.BoolValue.newBuilder(logPreallocate_).mergeFrom(value).buildPartial();
          } else {
            logPreallocate_ = value;
          }
          onChanged();
        } else {
          logPreallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder clearLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
          onChanged();
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue.Builder getLogPreallocateBuilder() {
        
        onChanged();
        return getLogPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
        if (logPreallocateBuilder_ != null) {
          return logPreallocateBuilder_.getMessageOrBuilder();
        } else {
          return logPreallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig2_8.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getLogPreallocateFieldBuilder() {
        if (logPreallocateBuilder_ == null) {
          logPreallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getLogPreallocate(),
                  getParentForChildren(),
                  isClean());
          logPreallocate_ = null;
        }
        return logPreallocateBuilder_;
      }

      private com.google.protobuf.Int64Value socketSendBufferBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketSendBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       * @return Whether the socketSendBufferBytes field is set.
       */
      public boolean hasSocketSendBufferBytes() {
        return socketSendBufferBytesBuilder_ != null || socketSendBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       * @return The socketSendBufferBytes.
       */
      public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        } else {
          return socketSendBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketSendBufferBytes_ = value;
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder mergeSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (socketSendBufferBytes_ != null) {
            socketSendBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketSendBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketSendBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder clearSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
          onChanged();
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketSendBufferBytesBuilder() {
        
        onChanged();
        return getSocketSendBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
        if (socketSendBufferBytesBuilder_ != null) {
          return socketSendBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketSendBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketSendBufferBytesFieldBuilder() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketSendBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketSendBufferBytes_ = null;
        }
        return socketSendBufferBytesBuilder_;
      }

      private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketReceiveBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       * @return Whether the socketReceiveBufferBytes field is set.
       */
      public boolean hasSocketReceiveBufferBytes() {
        return socketReceiveBufferBytesBuilder_ != null || socketReceiveBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       * @return The socketReceiveBufferBytes.
       */
      public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        } else {
          return socketReceiveBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketReceiveBufferBytes_ = value;
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder mergeSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (socketReceiveBufferBytes_ != null) {
            socketReceiveBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketReceiveBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketReceiveBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder clearSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
          onChanged();
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketReceiveBufferBytesBuilder() {
        
        onChanged();
        return getSocketReceiveBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
        if (socketReceiveBufferBytesBuilder_ != null) {
          return socketReceiveBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketReceiveBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketReceiveBufferBytesFieldBuilder() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketReceiveBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketReceiveBufferBytes_ = null;
        }
        return socketReceiveBufferBytesBuilder_;
      }

      private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> autoCreateTopicsEnableBuilder_;
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       * @return Whether the autoCreateTopicsEnable field is set.
       */
      public boolean hasAutoCreateTopicsEnable() {
        return autoCreateTopicsEnableBuilder_ != null || autoCreateTopicsEnable_ != null;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       * @return The autoCreateTopicsEnable.
       */
      public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        } else {
          return autoCreateTopicsEnableBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          autoCreateTopicsEnable_ = value;
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = builderForValue.build();
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder mergeAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (autoCreateTopicsEnable_ != null) {
            autoCreateTopicsEnable_ =
              com.google.protobuf.BoolValue.newBuilder(autoCreateTopicsEnable_).mergeFrom(value).buildPartial();
          } else {
            autoCreateTopicsEnable_ = value;
          }
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder clearAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
          onChanged();
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getAutoCreateTopicsEnableBuilder() {
        
        onChanged();
        return getAutoCreateTopicsEnableFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
        if (autoCreateTopicsEnableBuilder_ != null) {
          return autoCreateTopicsEnableBuilder_.getMessageOrBuilder();
        } else {
          return autoCreateTopicsEnable_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getAutoCreateTopicsEnableFieldBuilder() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getAutoCreateTopicsEnable(),
                  getParentForChildren(),
                  isClean());
          autoCreateTopicsEnable_ = null;
        }
        return autoCreateTopicsEnableBuilder_;
      }

      private com.google.protobuf.Int64Value numPartitions_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> numPartitionsBuilder_;
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       * @return Whether the numPartitions field is set.
       */
      public boolean hasNumPartitions() {
        return numPartitionsBuilder_ != null || numPartitions_ != null;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       * @return The numPartitions.
       */
      public com.google.protobuf.Int64Value getNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        } else {
          return numPartitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          numPartitions_ = value;
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = builderForValue.build();
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder mergeNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (numPartitions_ != null) {
            numPartitions_ =
              com.google.protobuf.Int64Value.newBuilder(numPartitions_).mergeFrom(value).buildPartial();
          } else {
            numPartitions_ = value;
          }
          onChanged();
        } else {
          numPartitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder clearNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
          onChanged();
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value.Builder getNumPartitionsBuilder() {
        
        onChanged();
        return getNumPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
        if (numPartitionsBuilder_ != null) {
          return numPartitionsBuilder_.getMessageOrBuilder();
        } else {
          return numPartitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getNumPartitionsFieldBuilder() {
        if (numPartitionsBuilder_ == null) {
          numPartitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getNumPartitions(),
                  getParentForChildren(),
                  isClean());
          numPartitions_ = null;
        }
        return numPartitionsBuilder_;
      }

      private com.google.protobuf.Int64Value defaultReplicationFactor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> defaultReplicationFactorBuilder_;
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       * @return Whether the defaultReplicationFactor field is set.
       */
      public boolean hasDefaultReplicationFactor() {
        return defaultReplicationFactorBuilder_ != null || defaultReplicationFactor_ != null;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       * @return The defaultReplicationFactor.
       */
      public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        } else {
          return defaultReplicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultReplicationFactor_ = value;
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder mergeDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (defaultReplicationFactor_ != null) {
            defaultReplicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(defaultReplicationFactor_).mergeFrom(value).buildPartial();
          } else {
            defaultReplicationFactor_ = value;
          }
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder clearDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
          onChanged();
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDefaultReplicationFactorBuilder() {
        
        onChanged();
        return getDefaultReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
        if (defaultReplicationFactorBuilder_ != null) {
          return defaultReplicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return defaultReplicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDefaultReplicationFactorFieldBuilder() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDefaultReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          defaultReplicationFactor_ = null;
        }
        return defaultReplicationFactorBuilder_;
      }

      private com.google.protobuf.Int64Value messageMaxBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> messageMaxBytesBuilder_;
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       * @return Whether the messageMaxBytes field is set.
       */
      public boolean hasMessageMaxBytes() {
        return messageMaxBytesBuilder_ != null || messageMaxBytes_ != null;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       * @return The messageMaxBytes.
       */
      public com.google.protobuf.Int64Value getMessageMaxBytes() {
        if (messageMaxBytesBuilder_ == null) {
          return messageMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
        } else {
          return messageMaxBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder setMessageMaxBytes(com.google.protobuf.Int64Value value) {
        if (messageMaxBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          messageMaxBytes_ = value;
          onChanged();
        } else {
          messageMaxBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder setMessageMaxBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = builderForValue.build();
          onChanged();
        } else {
          messageMaxBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder mergeMessageMaxBytes(com.google.protobuf.Int64Value value) {
        if (messageMaxBytesBuilder_ == null) {
          if (messageMaxBytes_ != null) {
            messageMaxBytes_ =
              com.google.protobuf.Int64Value.newBuilder(messageMaxBytes_).mergeFrom(value).buildPartial();
          } else {
            messageMaxBytes_ = value;
          }
          onChanged();
        } else {
          messageMaxBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder clearMessageMaxBytes() {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = null;
          onChanged();
        } else {
          messageMaxBytes_ = null;
          messageMaxBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMessageMaxBytesBuilder() {
        
        onChanged();
        return getMessageMaxBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder() {
        if (messageMaxBytesBuilder_ != null) {
          return messageMaxBytesBuilder_.getMessageOrBuilder();
        } else {
          return messageMaxBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMessageMaxBytesFieldBuilder() {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMessageMaxBytes(),
                  getParentForChildren(),
                  isClean());
          messageMaxBytes_ = null;
        }
        return messageMaxBytesBuilder_;
      }

      private com.google.protobuf.Int64Value replicaFetchMaxBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> replicaFetchMaxBytesBuilder_;
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       * @return Whether the replicaFetchMaxBytes field is set.
       */
      public boolean hasReplicaFetchMaxBytes() {
        return replicaFetchMaxBytesBuilder_ != null || replicaFetchMaxBytes_ != null;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       * @return The replicaFetchMaxBytes.
       */
      public com.google.protobuf.Int64Value getReplicaFetchMaxBytes() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          return replicaFetchMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
        } else {
          return replicaFetchMaxBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder setReplicaFetchMaxBytes(com.google.protobuf.Int64Value value) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          replicaFetchMaxBytes_ = value;
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder setReplicaFetchMaxBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = builderForValue.build();
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder mergeReplicaFetchMaxBytes(com.google.protobuf.Int64Value value) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          if (replicaFetchMaxBytes_ != null) {
            replicaFetchMaxBytes_ =
              com.google.protobuf.Int64Value.newBuilder(replicaFetchMaxBytes_).mergeFrom(value).buildPartial();
          } else {
            replicaFetchMaxBytes_ = value;
          }
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder clearReplicaFetchMaxBytes() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = null;
          onChanged();
        } else {
          replicaFetchMaxBytes_ = null;
          replicaFetchMaxBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public com.google.protobuf.Int64Value.Builder getReplicaFetchMaxBytesBuilder() {
        
        onChanged();
        return getReplicaFetchMaxBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder() {
        if (replicaFetchMaxBytesBuilder_ != null) {
          return replicaFetchMaxBytesBuilder_.getMessageOrBuilder();
        } else {
          return replicaFetchMaxBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
        }
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getReplicaFetchMaxBytesFieldBuilder() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getReplicaFetchMaxBytes(),
                  getParentForChildren(),
                  isClean());
          replicaFetchMaxBytes_ = null;
        }
        return replicaFetchMaxBytesBuilder_;
      }

      private com.google.protobuf.LazyStringList sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureSslCipherSuitesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = new com.google.protobuf.LazyStringArrayList(sslCipherSuites_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return A list containing the sslCipherSuites.
       */
      public com.google.protobuf.ProtocolStringList
          getSslCipherSuitesList() {
        return sslCipherSuites_.getUnmodifiableView();
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return The count of sslCipherSuites.
       */
      public int getSslCipherSuitesCount() {
        return sslCipherSuites_.size();
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index of the element to return.
       * @return The sslCipherSuites at the given index.
       */
      public java.lang.String getSslCipherSuites(int index) {
        return sslCipherSuites_.get(index);
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index of the value to return.
       * @return The bytes of the sslCipherSuites at the given index.
       */
      public com.google.protobuf.ByteString
          getSslCipherSuitesBytes(int index) {
        return sslCipherSuites_.getByteString(index);
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index to set the value at.
       * @param value The sslCipherSuites to set.
       * @return This builder for chaining.
       */
      public Builder setSslCipherSuites(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param value The sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addSslCipherSuites(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param values The sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addAllSslCipherSuites(
          java.lang.Iterable<java.lang.String> values) {
        ensureSslCipherSuitesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, sslCipherSuites_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return This builder for chaining.
       */
      public Builder clearSslCipherSuites() {
        sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param value The bytes of the sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addSslCipherSuitesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value offsetsRetentionMinutes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> offsetsRetentionMinutesBuilder_;
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       * @return Whether the offsetsRetentionMinutes field is set.
       */
      public boolean hasOffsetsRetentionMinutes() {
        return offsetsRetentionMinutesBuilder_ != null || offsetsRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       * @return The offsetsRetentionMinutes.
       */
      public com.google.protobuf.Int64Value getOffsetsRetentionMinutes() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          return offsetsRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
        } else {
          return offsetsRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder setOffsetsRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          offsetsRetentionMinutes_ = value;
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder setOffsetsRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder mergeOffsetsRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          if (offsetsRetentionMinutes_ != null) {
            offsetsRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(offsetsRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            offsetsRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder clearOffsetsRetentionMinutes() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = null;
          onChanged();
        } else {
          offsetsRetentionMinutes_ = null;
          offsetsRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public com.google.protobuf.Int64Value.Builder getOffsetsRetentionMinutesBuilder() {
        
        onChanged();
        return getOffsetsRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder() {
        if (offsetsRetentionMinutesBuilder_ != null) {
          return offsetsRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return offsetsRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getOffsetsRetentionMinutesFieldBuilder() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getOffsetsRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          offsetsRetentionMinutes_ = null;
        }
        return offsetsRetentionMinutesBuilder_;
      }

      private java.util.List<java.lang.Integer> saslEnabledMechanisms_ =
        java.util.Collections.emptyList();
      private void ensureSaslEnabledMechanismsIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>(saslEnabledMechanisms_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return A list containing the saslEnabledMechanisms.
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>(saslEnabledMechanisms_, saslEnabledMechanisms_converter_);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return The count of saslEnabledMechanisms.
       */
      public int getSaslEnabledMechanismsCount() {
        return saslEnabledMechanisms_.size();
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the element to return.
       * @return The saslEnabledMechanisms at the given index.
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index) {
        return saslEnabledMechanisms_converter_.convert(saslEnabledMechanisms_.get(index));
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index to set the value at.
       * @param value The saslEnabledMechanisms to set.
       * @return This builder for chaining.
       */
      public Builder setSaslEnabledMechanisms(
          int index, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param value The saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addSaslEnabledMechanisms(yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param values The saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addAllSaslEnabledMechanisms(
          java.lang.Iterable<? extends yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> values) {
        ensureSaslEnabledMechanismsIsMutable();
        for (yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value : values) {
          saslEnabledMechanisms_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return This builder for chaining.
       */
      public Builder clearSaslEnabledMechanisms() {
        saslEnabledMechanisms_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
       */
      public java.util.List<java.lang.Integer>
      getSaslEnabledMechanismsValueList() {
        return java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the value to return.
       * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
       */
      public int getSaslEnabledMechanismsValue(int index) {
        return saslEnabledMechanisms_.get(index);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the value to return.
       * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
       * @return This builder for chaining.
       */
      public Builder setSaslEnabledMechanismsValue(
          int index, int value) {
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param value The enum numeric value on the wire for saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addSaslEnabledMechanismsValue(int value) {
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param values The enum numeric values on the wire for saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addAllSaslEnabledMechanismsValue(
          java.lang.Iterable<java.lang.Integer> values) {
        ensureSaslEnabledMechanismsIsMutable();
        for (int value : values) {
          saslEnabledMechanisms_.add(value);
        }
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig2_8)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<KafkaConfig2_8>
        PARSER = new com.google.protobuf.AbstractParser<KafkaConfig2_8>() {
      @java.lang.Override
      public KafkaConfig2_8 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KafkaConfig2_8(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KafkaConfig2_8> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KafkaConfig2_8> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig2_8 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface KafkaConfig3OrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.KafkaConfig3)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The enum numeric value on the wire for compressionType.
     */
    int getCompressionTypeValue();
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The compressionType.
     */
    yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType();

    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return Whether the logFlushIntervalMessages field is set.
     */
    boolean hasLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return The logFlushIntervalMessages.
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMessages();
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder();

    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return Whether the logFlushIntervalMs field is set.
     */
    boolean hasLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return The logFlushIntervalMs.
     */
    com.google.protobuf.Int64Value getLogFlushIntervalMs();
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder();

    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return Whether the logFlushSchedulerIntervalMs field is set.
     */
    boolean hasLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return The logFlushSchedulerIntervalMs.
     */
    com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs();
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder();

    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return Whether the logRetentionBytes field is set.
     */
    boolean hasLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return The logRetentionBytes.
     */
    com.google.protobuf.Int64Value getLogRetentionBytes();
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder();

    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return Whether the logRetentionHours field is set.
     */
    boolean hasLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return The logRetentionHours.
     */
    com.google.protobuf.Int64Value getLogRetentionHours();
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder();

    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return Whether the logRetentionMinutes field is set.
     */
    boolean hasLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return The logRetentionMinutes.
     */
    com.google.protobuf.Int64Value getLogRetentionMinutes();
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return Whether the logRetentionMs field is set.
     */
    boolean hasLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return The logRetentionMs.
     */
    com.google.protobuf.Int64Value getLogRetentionMs();
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder();

    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return Whether the logSegmentBytes field is set.
     */
    boolean hasLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return The logSegmentBytes.
     */
    com.google.protobuf.Int64Value getLogSegmentBytes();
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder();

    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return Whether the logPreallocate field is set.
     */
    boolean hasLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return The logPreallocate.
     */
    com.google.protobuf.BoolValue getLogPreallocate();
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder();

    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return Whether the socketSendBufferBytes field is set.
     */
    boolean hasSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return The socketSendBufferBytes.
     */
    com.google.protobuf.Int64Value getSocketSendBufferBytes();
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder();

    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return Whether the socketReceiveBufferBytes field is set.
     */
    boolean hasSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return The socketReceiveBufferBytes.
     */
    com.google.protobuf.Int64Value getSocketReceiveBufferBytes();
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder();

    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return Whether the autoCreateTopicsEnable field is set.
     */
    boolean hasAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return The autoCreateTopicsEnable.
     */
    com.google.protobuf.BoolValue getAutoCreateTopicsEnable();
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder();

    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return Whether the numPartitions field is set.
     */
    boolean hasNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return The numPartitions.
     */
    com.google.protobuf.Int64Value getNumPartitions();
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder();

    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return Whether the defaultReplicationFactor field is set.
     */
    boolean hasDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return The defaultReplicationFactor.
     */
    com.google.protobuf.Int64Value getDefaultReplicationFactor();
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder();

    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return Whether the messageMaxBytes field is set.
     */
    boolean hasMessageMaxBytes();
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return The messageMaxBytes.
     */
    com.google.protobuf.Int64Value getMessageMaxBytes();
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder();

    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return Whether the replicaFetchMaxBytes field is set.
     */
    boolean hasReplicaFetchMaxBytes();
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return The replicaFetchMaxBytes.
     */
    com.google.protobuf.Int64Value getReplicaFetchMaxBytes();
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder();

    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return A list containing the sslCipherSuites.
     */
    java.util.List<java.lang.String>
        getSslCipherSuitesList();
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return The count of sslCipherSuites.
     */
    int getSslCipherSuitesCount();
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the element to return.
     * @return The sslCipherSuites at the given index.
     */
    java.lang.String getSslCipherSuites(int index);
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the value to return.
     * @return The bytes of the sslCipherSuites at the given index.
     */
    com.google.protobuf.ByteString
        getSslCipherSuitesBytes(int index);

    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return Whether the offsetsRetentionMinutes field is set.
     */
    boolean hasOffsetsRetentionMinutes();
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return The offsetsRetentionMinutes.
     */
    com.google.protobuf.Int64Value getOffsetsRetentionMinutes();
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     */
    com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder();

    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the saslEnabledMechanisms.
     */
    java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return The count of saslEnabledMechanisms.
     */
    int getSaslEnabledMechanismsCount();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the element to return.
     * @return The saslEnabledMechanisms at the given index.
     */
    yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index);
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
     */
    java.util.List<java.lang.Integer>
    getSaslEnabledMechanismsValueList();
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the value to return.
     * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
     */
    int getSaslEnabledMechanismsValue(int index);
  }
  /**
   * <pre>
   * Kafka version 3.x broker configuration.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig3}
   */
  public static final class KafkaConfig3 extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig3)
      KafkaConfig3OrBuilder {
  private static final long serialVersionUID = 0L;
    // Use KafkaConfig3.newBuilder() to construct.
    private KafkaConfig3(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private KafkaConfig3() {
      compressionType_ = 0;
      sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      saslEnabledMechanisms_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new KafkaConfig3();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private KafkaConfig3(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              int rawValue = input.readEnum();

              compressionType_ = rawValue;
              break;
            }
            case 18: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMessages_ != null) {
                subBuilder = logFlushIntervalMessages_.toBuilder();
              }
              logFlushIntervalMessages_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMessages_);
                logFlushIntervalMessages_ = subBuilder.buildPartial();
              }

              break;
            }
            case 26: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushIntervalMs_ != null) {
                subBuilder = logFlushIntervalMs_.toBuilder();
              }
              logFlushIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushIntervalMs_);
                logFlushIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logFlushSchedulerIntervalMs_ != null) {
                subBuilder = logFlushSchedulerIntervalMs_.toBuilder();
              }
              logFlushSchedulerIntervalMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logFlushSchedulerIntervalMs_);
                logFlushSchedulerIntervalMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionBytes_ != null) {
                subBuilder = logRetentionBytes_.toBuilder();
              }
              logRetentionBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionBytes_);
                logRetentionBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionHours_ != null) {
                subBuilder = logRetentionHours_.toBuilder();
              }
              logRetentionHours_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionHours_);
                logRetentionHours_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMinutes_ != null) {
                subBuilder = logRetentionMinutes_.toBuilder();
              }
              logRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMinutes_);
                logRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 66: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logRetentionMs_ != null) {
                subBuilder = logRetentionMs_.toBuilder();
              }
              logRetentionMs_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logRetentionMs_);
                logRetentionMs_ = subBuilder.buildPartial();
              }

              break;
            }
            case 74: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (logSegmentBytes_ != null) {
                subBuilder = logSegmentBytes_.toBuilder();
              }
              logSegmentBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logSegmentBytes_);
                logSegmentBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 82: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (logPreallocate_ != null) {
                subBuilder = logPreallocate_.toBuilder();
              }
              logPreallocate_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logPreallocate_);
                logPreallocate_ = subBuilder.buildPartial();
              }

              break;
            }
            case 90: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketSendBufferBytes_ != null) {
                subBuilder = socketSendBufferBytes_.toBuilder();
              }
              socketSendBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketSendBufferBytes_);
                socketSendBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 98: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (socketReceiveBufferBytes_ != null) {
                subBuilder = socketReceiveBufferBytes_.toBuilder();
              }
              socketReceiveBufferBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(socketReceiveBufferBytes_);
                socketReceiveBufferBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              com.google.protobuf.BoolValue.Builder subBuilder = null;
              if (autoCreateTopicsEnable_ != null) {
                subBuilder = autoCreateTopicsEnable_.toBuilder();
              }
              autoCreateTopicsEnable_ = input.readMessage(com.google.protobuf.BoolValue.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(autoCreateTopicsEnable_);
                autoCreateTopicsEnable_ = subBuilder.buildPartial();
              }

              break;
            }
            case 114: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (numPartitions_ != null) {
                subBuilder = numPartitions_.toBuilder();
              }
              numPartitions_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(numPartitions_);
                numPartitions_ = subBuilder.buildPartial();
              }

              break;
            }
            case 122: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (defaultReplicationFactor_ != null) {
                subBuilder = defaultReplicationFactor_.toBuilder();
              }
              defaultReplicationFactor_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultReplicationFactor_);
                defaultReplicationFactor_ = subBuilder.buildPartial();
              }

              break;
            }
            case 130: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (messageMaxBytes_ != null) {
                subBuilder = messageMaxBytes_.toBuilder();
              }
              messageMaxBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(messageMaxBytes_);
                messageMaxBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 138: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (replicaFetchMaxBytes_ != null) {
                subBuilder = replicaFetchMaxBytes_.toBuilder();
              }
              replicaFetchMaxBytes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(replicaFetchMaxBytes_);
                replicaFetchMaxBytes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 146: {
              java.lang.String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) != 0)) {
                sslCipherSuites_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              sslCipherSuites_.add(s);
              break;
            }
            case 154: {
              com.google.protobuf.Int64Value.Builder subBuilder = null;
              if (offsetsRetentionMinutes_ != null) {
                subBuilder = offsetsRetentionMinutes_.toBuilder();
              }
              offsetsRetentionMinutes_ = input.readMessage(com.google.protobuf.Int64Value.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(offsetsRetentionMinutes_);
                offsetsRetentionMinutes_ = subBuilder.buildPartial();
              }

              break;
            }
            case 160: {
              int rawValue = input.readEnum();
              if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000002;
              }
              saslEnabledMechanisms_.add(rawValue);
              break;
            }
            case 162: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                if (!((mutable_bitField0_ & 0x00000002) != 0)) {
                  saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                saslEnabledMechanisms_.add(rawValue);
              }
              input.popLimit(oldLimit);
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = sslCipherSuites_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder.class);
    }

    public static final int COMPRESSION_TYPE_FIELD_NUMBER = 1;
    private int compressionType_;
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The enum numeric value on the wire for compressionType.
     */
    @java.lang.Override public int getCompressionTypeValue() {
      return compressionType_;
    }
    /**
     * <pre>
     * Cluster topics compression type.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
     * @return The compressionType.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
    }

    public static final int LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER = 2;
    private com.google.protobuf.Int64Value logFlushIntervalMessages_;
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return Whether the logFlushIntervalMessages field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ != null;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     * @return The logFlushIntervalMessages.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
      return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
    }
    /**
     * <pre>
     * The number of messages accumulated on a log partition before messages are flushed to disk.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
      return getLogFlushIntervalMessages();
    }

    public static final int LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER = 3;
    private com.google.protobuf.Int64Value logFlushIntervalMs_;
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return Whether the logFlushIntervalMs field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushIntervalMs() {
      return logFlushIntervalMs_ != null;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     * @return The logFlushIntervalMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
      return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
    }
    /**
     * <pre>
     * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
     * If not set, the value of [log_flush_scheduler_interval_ms] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
      return getLogFlushIntervalMs();
    }

    public static final int LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER = 4;
    private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return Whether the logFlushSchedulerIntervalMs field is set.
     */
    @java.lang.Override
    public boolean hasLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ != null;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     * @return The logFlushSchedulerIntervalMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
      return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
    }
    /**
     * <pre>
     * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
     * This check is done by the log flusher.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
      return getLogFlushSchedulerIntervalMs();
    }

    public static final int LOG_RETENTION_BYTES_FIELD_NUMBER = 5;
    private com.google.protobuf.Int64Value logRetentionBytes_;
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return Whether the logRetentionBytes field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionBytes() {
      return logRetentionBytes_ != null;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     * @return The logRetentionBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionBytes() {
      return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
    }
    /**
     * <pre>
     * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
     * This setting is helpful if you need to control the size of a log due to limited disk space.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
      return getLogRetentionBytes();
    }

    public static final int LOG_RETENTION_HOURS_FIELD_NUMBER = 6;
    private com.google.protobuf.Int64Value logRetentionHours_;
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return Whether the logRetentionHours field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionHours() {
      return logRetentionHours_ != null;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     * @return The logRetentionHours.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionHours() {
      return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
    }
    /**
     * <pre>
     * The number of hours to keep a log segment file before deleting it.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
      return getLogRetentionHours();
    }

    public static final int LOG_RETENTION_MINUTES_FIELD_NUMBER = 7;
    private com.google.protobuf.Int64Value logRetentionMinutes_;
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return Whether the logRetentionMinutes field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionMinutes() {
      return logRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     * @return The logRetentionMinutes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionMinutes() {
      return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
    }
    /**
     * <pre>
     * The number of minutes to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_hours] is used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
      return getLogRetentionMinutes();
    }

    public static final int LOG_RETENTION_MS_FIELD_NUMBER = 8;
    private com.google.protobuf.Int64Value logRetentionMs_;
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return Whether the logRetentionMs field is set.
     */
    @java.lang.Override
    public boolean hasLogRetentionMs() {
      return logRetentionMs_ != null;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     * @return The logRetentionMs.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogRetentionMs() {
      return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
    }
    /**
     * <pre>
     * The number of milliseconds to keep a log segment file before deleting it.
     * If not set, the value of [log_retention_minutes] is used.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
      return getLogRetentionMs();
    }

    public static final int LOG_SEGMENT_BYTES_FIELD_NUMBER = 9;
    private com.google.protobuf.Int64Value logSegmentBytes_;
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return Whether the logSegmentBytes field is set.
     */
    @java.lang.Override
    public boolean hasLogSegmentBytes() {
      return logSegmentBytes_ != null;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     * @return The logSegmentBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getLogSegmentBytes() {
      return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
    }
    /**
     * <pre>
     * The maximum size of a single log file.
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
      return getLogSegmentBytes();
    }

    public static final int LOG_PREALLOCATE_FIELD_NUMBER = 10;
    private com.google.protobuf.BoolValue logPreallocate_;
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return Whether the logPreallocate field is set.
     */
    @java.lang.Override
    public boolean hasLogPreallocate() {
      return logPreallocate_ != null;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     * @return The logPreallocate.
     */
    @java.lang.Override
    public com.google.protobuf.BoolValue getLogPreallocate() {
      return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
    }
    /**
     * <pre>
     * Should pre allocate file when create new segment?
     * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
     * </pre>
     *
     * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
     */
    @java.lang.Override
    public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
      return getLogPreallocate();
    }

    public static final int SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER = 11;
    private com.google.protobuf.Int64Value socketSendBufferBytes_;
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return Whether the socketSendBufferBytes field is set.
     */
    @java.lang.Override
    public boolean hasSocketSendBufferBytes() {
      return socketSendBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     * @return The socketSendBufferBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
      return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
    }
    /**
     * <pre>
     * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
      return getSocketSendBufferBytes();
    }

    public static final int SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER = 12;
    private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return Whether the socketReceiveBufferBytes field is set.
     */
    @java.lang.Override
    public boolean hasSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ != null;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     * @return The socketReceiveBufferBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
      return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
    }
    /**
     * <pre>
     * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
      return getSocketReceiveBufferBytes();
    }

    public static final int AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER = 13;
    private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return Whether the autoCreateTopicsEnable field is set.
     */
    @java.lang.Override
    public boolean hasAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ != null;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     * @return The autoCreateTopicsEnable.
     */
    @java.lang.Override
    public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
      return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
    }
    /**
     * <pre>
     * Enable auto creation of topic on the server
     * </pre>
     *
     * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
     */
    @java.lang.Override
    public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
      return getAutoCreateTopicsEnable();
    }

    public static final int NUM_PARTITIONS_FIELD_NUMBER = 14;
    private com.google.protobuf.Int64Value numPartitions_;
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return Whether the numPartitions field is set.
     */
    @java.lang.Override
    public boolean hasNumPartitions() {
      return numPartitions_ != null;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     * @return The numPartitions.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getNumPartitions() {
      return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
    }
    /**
     * <pre>
     * Default number of partitions per topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
      return getNumPartitions();
    }

    public static final int DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER = 15;
    private com.google.protobuf.Int64Value defaultReplicationFactor_;
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return Whether the defaultReplicationFactor field is set.
     */
    @java.lang.Override
    public boolean hasDefaultReplicationFactor() {
      return defaultReplicationFactor_ != null;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     * @return The defaultReplicationFactor.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
      return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
    }
    /**
     * <pre>
     * Default replication factor of the topic on the whole cluster
     * </pre>
     *
     * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
      return getDefaultReplicationFactor();
    }

    public static final int MESSAGE_MAX_BYTES_FIELD_NUMBER = 16;
    private com.google.protobuf.Int64Value messageMaxBytes_;
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return Whether the messageMaxBytes field is set.
     */
    @java.lang.Override
    public boolean hasMessageMaxBytes() {
      return messageMaxBytes_ != null;
    }
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     * @return The messageMaxBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getMessageMaxBytes() {
      return messageMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
    }
    /**
     * <pre>
     * The largest record batch size allowed by Kafka. Default value: 1048588.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder() {
      return getMessageMaxBytes();
    }

    public static final int REPLICA_FETCH_MAX_BYTES_FIELD_NUMBER = 17;
    private com.google.protobuf.Int64Value replicaFetchMaxBytes_;
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return Whether the replicaFetchMaxBytes field is set.
     */
    @java.lang.Override
    public boolean hasReplicaFetchMaxBytes() {
      return replicaFetchMaxBytes_ != null;
    }
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     * @return The replicaFetchMaxBytes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getReplicaFetchMaxBytes() {
      return replicaFetchMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
    }
    /**
     * <pre>
     * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder() {
      return getReplicaFetchMaxBytes();
    }

    public static final int SSL_CIPHER_SUITES_FIELD_NUMBER = 18;
    private com.google.protobuf.LazyStringList sslCipherSuites_;
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return A list containing the sslCipherSuites.
     */
    public com.google.protobuf.ProtocolStringList
        getSslCipherSuitesList() {
      return sslCipherSuites_;
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @return The count of sslCipherSuites.
     */
    public int getSslCipherSuitesCount() {
      return sslCipherSuites_.size();
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the element to return.
     * @return The sslCipherSuites at the given index.
     */
    public java.lang.String getSslCipherSuites(int index) {
      return sslCipherSuites_.get(index);
    }
    /**
     * <pre>
     * A list of cipher suites.
     * </pre>
     *
     * <code>repeated string ssl_cipher_suites = 18;</code>
     * @param index The index of the value to return.
     * @return The bytes of the sslCipherSuites at the given index.
     */
    public com.google.protobuf.ByteString
        getSslCipherSuitesBytes(int index) {
      return sslCipherSuites_.getByteString(index);
    }

    public static final int OFFSETS_RETENTION_MINUTES_FIELD_NUMBER = 19;
    private com.google.protobuf.Int64Value offsetsRetentionMinutes_;
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return Whether the offsetsRetentionMinutes field is set.
     */
    @java.lang.Override
    public boolean hasOffsetsRetentionMinutes() {
      return offsetsRetentionMinutes_ != null;
    }
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     * @return The offsetsRetentionMinutes.
     */
    @java.lang.Override
    public com.google.protobuf.Int64Value getOffsetsRetentionMinutes() {
      return offsetsRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
    }
    /**
     * <pre>
     * Offset storage time after a consumer group loses all its consumers. Default: 10080.
     * </pre>
     *
     * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
     */
    @java.lang.Override
    public com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder() {
      return getOffsetsRetentionMinutes();
    }

    public static final int SASL_ENABLED_MECHANISMS_FIELD_NUMBER = 20;
    private java.util.List<java.lang.Integer> saslEnabledMechanisms_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> saslEnabledMechanisms_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>() {
              public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism convert(java.lang.Integer from) {
                @SuppressWarnings("deprecation")
                yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism result = yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism.valueOf(from);
                return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism.UNRECOGNIZED : result;
              }
            };
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the saslEnabledMechanisms.
     */
    @java.lang.Override
    public java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>(saslEnabledMechanisms_, saslEnabledMechanisms_converter_);
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return The count of saslEnabledMechanisms.
     */
    @java.lang.Override
    public int getSaslEnabledMechanismsCount() {
      return saslEnabledMechanisms_.size();
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the element to return.
     * @return The saslEnabledMechanisms at the given index.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index) {
      return saslEnabledMechanisms_converter_.convert(saslEnabledMechanisms_.get(index));
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
     */
    @java.lang.Override
    public java.util.List<java.lang.Integer>
    getSaslEnabledMechanismsValueList() {
      return saslEnabledMechanisms_;
    }
    /**
     * <pre>
     * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
     * </pre>
     *
     * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
     * @param index The index of the value to return.
     * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
     */
    @java.lang.Override
    public int getSaslEnabledMechanismsValue(int index) {
      return saslEnabledMechanisms_.get(index);
    }
    private int saslEnabledMechanismsMemoizedSerializedSize;

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        output.writeMessage(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        output.writeMessage(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        output.writeMessage(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        output.writeMessage(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        output.writeMessage(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        output.writeMessage(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        output.writeMessage(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        output.writeMessage(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        output.writeMessage(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        output.writeMessage(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        output.writeMessage(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        output.writeMessage(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        output.writeMessage(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        output.writeMessage(15, getDefaultReplicationFactor());
      }
      if (messageMaxBytes_ != null) {
        output.writeMessage(16, getMessageMaxBytes());
      }
      if (replicaFetchMaxBytes_ != null) {
        output.writeMessage(17, getReplicaFetchMaxBytes());
      }
      for (int i = 0; i < sslCipherSuites_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 18, sslCipherSuites_.getRaw(i));
      }
      if (offsetsRetentionMinutes_ != null) {
        output.writeMessage(19, getOffsetsRetentionMinutes());
      }
      if (getSaslEnabledMechanismsList().size() > 0) {
        output.writeUInt32NoTag(162);
        output.writeUInt32NoTag(saslEnabledMechanismsMemoizedSerializedSize);
      }
      for (int i = 0; i < saslEnabledMechanisms_.size(); i++) {
        output.writeEnumNoTag(saslEnabledMechanisms_.get(i));
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (compressionType_ != yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.COMPRESSION_TYPE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, compressionType_);
      }
      if (logFlushIntervalMessages_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getLogFlushIntervalMessages());
      }
      if (logFlushIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getLogFlushIntervalMs());
      }
      if (logFlushSchedulerIntervalMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getLogFlushSchedulerIntervalMs());
      }
      if (logRetentionBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getLogRetentionBytes());
      }
      if (logRetentionHours_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getLogRetentionHours());
      }
      if (logRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getLogRetentionMinutes());
      }
      if (logRetentionMs_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, getLogRetentionMs());
      }
      if (logSegmentBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getLogSegmentBytes());
      }
      if (logPreallocate_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, getLogPreallocate());
      }
      if (socketSendBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, getSocketSendBufferBytes());
      }
      if (socketReceiveBufferBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getSocketReceiveBufferBytes());
      }
      if (autoCreateTopicsEnable_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, getAutoCreateTopicsEnable());
      }
      if (numPartitions_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getNumPartitions());
      }
      if (defaultReplicationFactor_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getDefaultReplicationFactor());
      }
      if (messageMaxBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, getMessageMaxBytes());
      }
      if (replicaFetchMaxBytes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, getReplicaFetchMaxBytes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < sslCipherSuites_.size(); i++) {
          dataSize += computeStringSizeNoTag(sslCipherSuites_.getRaw(i));
        }
        size += dataSize;
        size += 2 * getSslCipherSuitesList().size();
      }
      if (offsetsRetentionMinutes_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, getOffsetsRetentionMinutes());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < saslEnabledMechanisms_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(saslEnabledMechanisms_.get(i));
        }
        size += dataSize;
        if (!getSaslEnabledMechanismsList().isEmpty()) {  size += 2;
          size += com.google.protobuf.CodedOutputStream
            .computeUInt32SizeNoTag(dataSize);
        }saslEnabledMechanismsMemoizedSerializedSize = dataSize;
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) obj;

      if (compressionType_ != other.compressionType_) return false;
      if (hasLogFlushIntervalMessages() != other.hasLogFlushIntervalMessages()) return false;
      if (hasLogFlushIntervalMessages()) {
        if (!getLogFlushIntervalMessages()
            .equals(other.getLogFlushIntervalMessages())) return false;
      }
      if (hasLogFlushIntervalMs() != other.hasLogFlushIntervalMs()) return false;
      if (hasLogFlushIntervalMs()) {
        if (!getLogFlushIntervalMs()
            .equals(other.getLogFlushIntervalMs())) return false;
      }
      if (hasLogFlushSchedulerIntervalMs() != other.hasLogFlushSchedulerIntervalMs()) return false;
      if (hasLogFlushSchedulerIntervalMs()) {
        if (!getLogFlushSchedulerIntervalMs()
            .equals(other.getLogFlushSchedulerIntervalMs())) return false;
      }
      if (hasLogRetentionBytes() != other.hasLogRetentionBytes()) return false;
      if (hasLogRetentionBytes()) {
        if (!getLogRetentionBytes()
            .equals(other.getLogRetentionBytes())) return false;
      }
      if (hasLogRetentionHours() != other.hasLogRetentionHours()) return false;
      if (hasLogRetentionHours()) {
        if (!getLogRetentionHours()
            .equals(other.getLogRetentionHours())) return false;
      }
      if (hasLogRetentionMinutes() != other.hasLogRetentionMinutes()) return false;
      if (hasLogRetentionMinutes()) {
        if (!getLogRetentionMinutes()
            .equals(other.getLogRetentionMinutes())) return false;
      }
      if (hasLogRetentionMs() != other.hasLogRetentionMs()) return false;
      if (hasLogRetentionMs()) {
        if (!getLogRetentionMs()
            .equals(other.getLogRetentionMs())) return false;
      }
      if (hasLogSegmentBytes() != other.hasLogSegmentBytes()) return false;
      if (hasLogSegmentBytes()) {
        if (!getLogSegmentBytes()
            .equals(other.getLogSegmentBytes())) return false;
      }
      if (hasLogPreallocate() != other.hasLogPreallocate()) return false;
      if (hasLogPreallocate()) {
        if (!getLogPreallocate()
            .equals(other.getLogPreallocate())) return false;
      }
      if (hasSocketSendBufferBytes() != other.hasSocketSendBufferBytes()) return false;
      if (hasSocketSendBufferBytes()) {
        if (!getSocketSendBufferBytes()
            .equals(other.getSocketSendBufferBytes())) return false;
      }
      if (hasSocketReceiveBufferBytes() != other.hasSocketReceiveBufferBytes()) return false;
      if (hasSocketReceiveBufferBytes()) {
        if (!getSocketReceiveBufferBytes()
            .equals(other.getSocketReceiveBufferBytes())) return false;
      }
      if (hasAutoCreateTopicsEnable() != other.hasAutoCreateTopicsEnable()) return false;
      if (hasAutoCreateTopicsEnable()) {
        if (!getAutoCreateTopicsEnable()
            .equals(other.getAutoCreateTopicsEnable())) return false;
      }
      if (hasNumPartitions() != other.hasNumPartitions()) return false;
      if (hasNumPartitions()) {
        if (!getNumPartitions()
            .equals(other.getNumPartitions())) return false;
      }
      if (hasDefaultReplicationFactor() != other.hasDefaultReplicationFactor()) return false;
      if (hasDefaultReplicationFactor()) {
        if (!getDefaultReplicationFactor()
            .equals(other.getDefaultReplicationFactor())) return false;
      }
      if (hasMessageMaxBytes() != other.hasMessageMaxBytes()) return false;
      if (hasMessageMaxBytes()) {
        if (!getMessageMaxBytes()
            .equals(other.getMessageMaxBytes())) return false;
      }
      if (hasReplicaFetchMaxBytes() != other.hasReplicaFetchMaxBytes()) return false;
      if (hasReplicaFetchMaxBytes()) {
        if (!getReplicaFetchMaxBytes()
            .equals(other.getReplicaFetchMaxBytes())) return false;
      }
      if (!getSslCipherSuitesList()
          .equals(other.getSslCipherSuitesList())) return false;
      if (hasOffsetsRetentionMinutes() != other.hasOffsetsRetentionMinutes()) return false;
      if (hasOffsetsRetentionMinutes()) {
        if (!getOffsetsRetentionMinutes()
            .equals(other.getOffsetsRetentionMinutes())) return false;
      }
      if (!saslEnabledMechanisms_.equals(other.saslEnabledMechanisms_)) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + COMPRESSION_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + compressionType_;
      if (hasLogFlushIntervalMessages()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MESSAGES_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMessages().hashCode();
      }
      if (hasLogFlushIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushIntervalMs().hashCode();
      }
      if (hasLogFlushSchedulerIntervalMs()) {
        hash = (37 * hash) + LOG_FLUSH_SCHEDULER_INTERVAL_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogFlushSchedulerIntervalMs().hashCode();
      }
      if (hasLogRetentionBytes()) {
        hash = (37 * hash) + LOG_RETENTION_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionBytes().hashCode();
      }
      if (hasLogRetentionHours()) {
        hash = (37 * hash) + LOG_RETENTION_HOURS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionHours().hashCode();
      }
      if (hasLogRetentionMinutes()) {
        hash = (37 * hash) + LOG_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMinutes().hashCode();
      }
      if (hasLogRetentionMs()) {
        hash = (37 * hash) + LOG_RETENTION_MS_FIELD_NUMBER;
        hash = (53 * hash) + getLogRetentionMs().hashCode();
      }
      if (hasLogSegmentBytes()) {
        hash = (37 * hash) + LOG_SEGMENT_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getLogSegmentBytes().hashCode();
      }
      if (hasLogPreallocate()) {
        hash = (37 * hash) + LOG_PREALLOCATE_FIELD_NUMBER;
        hash = (53 * hash) + getLogPreallocate().hashCode();
      }
      if (hasSocketSendBufferBytes()) {
        hash = (37 * hash) + SOCKET_SEND_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketSendBufferBytes().hashCode();
      }
      if (hasSocketReceiveBufferBytes()) {
        hash = (37 * hash) + SOCKET_RECEIVE_BUFFER_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getSocketReceiveBufferBytes().hashCode();
      }
      if (hasAutoCreateTopicsEnable()) {
        hash = (37 * hash) + AUTO_CREATE_TOPICS_ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + getAutoCreateTopicsEnable().hashCode();
      }
      if (hasNumPartitions()) {
        hash = (37 * hash) + NUM_PARTITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumPartitions().hashCode();
      }
      if (hasDefaultReplicationFactor()) {
        hash = (37 * hash) + DEFAULT_REPLICATION_FACTOR_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultReplicationFactor().hashCode();
      }
      if (hasMessageMaxBytes()) {
        hash = (37 * hash) + MESSAGE_MAX_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getMessageMaxBytes().hashCode();
      }
      if (hasReplicaFetchMaxBytes()) {
        hash = (37 * hash) + REPLICA_FETCH_MAX_BYTES_FIELD_NUMBER;
        hash = (53 * hash) + getReplicaFetchMaxBytes().hashCode();
      }
      if (getSslCipherSuitesCount() > 0) {
        hash = (37 * hash) + SSL_CIPHER_SUITES_FIELD_NUMBER;
        hash = (53 * hash) + getSslCipherSuitesList().hashCode();
      }
      if (hasOffsetsRetentionMinutes()) {
        hash = (37 * hash) + OFFSETS_RETENTION_MINUTES_FIELD_NUMBER;
        hash = (53 * hash) + getOffsetsRetentionMinutes().hashCode();
      }
      if (getSaslEnabledMechanismsCount() > 0) {
        hash = (37 * hash) + SASL_ENABLED_MECHANISMS_FIELD_NUMBER;
        hash = (53 * hash) + saslEnabledMechanisms_.hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Kafka version 3.x broker configuration.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.KafkaConfig3}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.KafkaConfig3)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3OrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        compressionType_ = 0;

        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = null;
        } else {
          messageMaxBytes_ = null;
          messageMaxBytesBuilder_ = null;
        }
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = null;
        } else {
          replicaFetchMaxBytes_ = null;
          replicaFetchMaxBytesBuilder_ = null;
        }
        sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = null;
        } else {
          offsetsRetentionMinutes_ = null;
          offsetsRetentionMinutesBuilder_ = null;
        }
        saslEnabledMechanisms_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3(this);
        int from_bitField0_ = bitField0_;
        result.compressionType_ = compressionType_;
        if (logFlushIntervalMessagesBuilder_ == null) {
          result.logFlushIntervalMessages_ = logFlushIntervalMessages_;
        } else {
          result.logFlushIntervalMessages_ = logFlushIntervalMessagesBuilder_.build();
        }
        if (logFlushIntervalMsBuilder_ == null) {
          result.logFlushIntervalMs_ = logFlushIntervalMs_;
        } else {
          result.logFlushIntervalMs_ = logFlushIntervalMsBuilder_.build();
        }
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMs_;
        } else {
          result.logFlushSchedulerIntervalMs_ = logFlushSchedulerIntervalMsBuilder_.build();
        }
        if (logRetentionBytesBuilder_ == null) {
          result.logRetentionBytes_ = logRetentionBytes_;
        } else {
          result.logRetentionBytes_ = logRetentionBytesBuilder_.build();
        }
        if (logRetentionHoursBuilder_ == null) {
          result.logRetentionHours_ = logRetentionHours_;
        } else {
          result.logRetentionHours_ = logRetentionHoursBuilder_.build();
        }
        if (logRetentionMinutesBuilder_ == null) {
          result.logRetentionMinutes_ = logRetentionMinutes_;
        } else {
          result.logRetentionMinutes_ = logRetentionMinutesBuilder_.build();
        }
        if (logRetentionMsBuilder_ == null) {
          result.logRetentionMs_ = logRetentionMs_;
        } else {
          result.logRetentionMs_ = logRetentionMsBuilder_.build();
        }
        if (logSegmentBytesBuilder_ == null) {
          result.logSegmentBytes_ = logSegmentBytes_;
        } else {
          result.logSegmentBytes_ = logSegmentBytesBuilder_.build();
        }
        if (logPreallocateBuilder_ == null) {
          result.logPreallocate_ = logPreallocate_;
        } else {
          result.logPreallocate_ = logPreallocateBuilder_.build();
        }
        if (socketSendBufferBytesBuilder_ == null) {
          result.socketSendBufferBytes_ = socketSendBufferBytes_;
        } else {
          result.socketSendBufferBytes_ = socketSendBufferBytesBuilder_.build();
        }
        if (socketReceiveBufferBytesBuilder_ == null) {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytes_;
        } else {
          result.socketReceiveBufferBytes_ = socketReceiveBufferBytesBuilder_.build();
        }
        if (autoCreateTopicsEnableBuilder_ == null) {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnable_;
        } else {
          result.autoCreateTopicsEnable_ = autoCreateTopicsEnableBuilder_.build();
        }
        if (numPartitionsBuilder_ == null) {
          result.numPartitions_ = numPartitions_;
        } else {
          result.numPartitions_ = numPartitionsBuilder_.build();
        }
        if (defaultReplicationFactorBuilder_ == null) {
          result.defaultReplicationFactor_ = defaultReplicationFactor_;
        } else {
          result.defaultReplicationFactor_ = defaultReplicationFactorBuilder_.build();
        }
        if (messageMaxBytesBuilder_ == null) {
          result.messageMaxBytes_ = messageMaxBytes_;
        } else {
          result.messageMaxBytes_ = messageMaxBytesBuilder_.build();
        }
        if (replicaFetchMaxBytesBuilder_ == null) {
          result.replicaFetchMaxBytes_ = replicaFetchMaxBytes_;
        } else {
          result.replicaFetchMaxBytes_ = replicaFetchMaxBytesBuilder_.build();
        }
        if (((bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = sslCipherSuites_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.sslCipherSuites_ = sslCipherSuites_;
        if (offsetsRetentionMinutesBuilder_ == null) {
          result.offsetsRetentionMinutes_ = offsetsRetentionMinutes_;
        } else {
          result.offsetsRetentionMinutes_ = offsetsRetentionMinutesBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.saslEnabledMechanisms_ = saslEnabledMechanisms_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3.getDefaultInstance()) return this;
        if (other.compressionType_ != 0) {
          setCompressionTypeValue(other.getCompressionTypeValue());
        }
        if (other.hasLogFlushIntervalMessages()) {
          mergeLogFlushIntervalMessages(other.getLogFlushIntervalMessages());
        }
        if (other.hasLogFlushIntervalMs()) {
          mergeLogFlushIntervalMs(other.getLogFlushIntervalMs());
        }
        if (other.hasLogFlushSchedulerIntervalMs()) {
          mergeLogFlushSchedulerIntervalMs(other.getLogFlushSchedulerIntervalMs());
        }
        if (other.hasLogRetentionBytes()) {
          mergeLogRetentionBytes(other.getLogRetentionBytes());
        }
        if (other.hasLogRetentionHours()) {
          mergeLogRetentionHours(other.getLogRetentionHours());
        }
        if (other.hasLogRetentionMinutes()) {
          mergeLogRetentionMinutes(other.getLogRetentionMinutes());
        }
        if (other.hasLogRetentionMs()) {
          mergeLogRetentionMs(other.getLogRetentionMs());
        }
        if (other.hasLogSegmentBytes()) {
          mergeLogSegmentBytes(other.getLogSegmentBytes());
        }
        if (other.hasLogPreallocate()) {
          mergeLogPreallocate(other.getLogPreallocate());
        }
        if (other.hasSocketSendBufferBytes()) {
          mergeSocketSendBufferBytes(other.getSocketSendBufferBytes());
        }
        if (other.hasSocketReceiveBufferBytes()) {
          mergeSocketReceiveBufferBytes(other.getSocketReceiveBufferBytes());
        }
        if (other.hasAutoCreateTopicsEnable()) {
          mergeAutoCreateTopicsEnable(other.getAutoCreateTopicsEnable());
        }
        if (other.hasNumPartitions()) {
          mergeNumPartitions(other.getNumPartitions());
        }
        if (other.hasDefaultReplicationFactor()) {
          mergeDefaultReplicationFactor(other.getDefaultReplicationFactor());
        }
        if (other.hasMessageMaxBytes()) {
          mergeMessageMaxBytes(other.getMessageMaxBytes());
        }
        if (other.hasReplicaFetchMaxBytes()) {
          mergeReplicaFetchMaxBytes(other.getReplicaFetchMaxBytes());
        }
        if (!other.sslCipherSuites_.isEmpty()) {
          if (sslCipherSuites_.isEmpty()) {
            sslCipherSuites_ = other.sslCipherSuites_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureSslCipherSuitesIsMutable();
            sslCipherSuites_.addAll(other.sslCipherSuites_);
          }
          onChanged();
        }
        if (other.hasOffsetsRetentionMinutes()) {
          mergeOffsetsRetentionMinutes(other.getOffsetsRetentionMinutes());
        }
        if (!other.saslEnabledMechanisms_.isEmpty()) {
          if (saslEnabledMechanisms_.isEmpty()) {
            saslEnabledMechanisms_ = other.saslEnabledMechanisms_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureSaslEnabledMechanismsIsMutable();
            saslEnabledMechanisms_.addAll(other.saslEnabledMechanisms_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int compressionType_ = 0;
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return The enum numeric value on the wire for compressionType.
       */
      @java.lang.Override public int getCompressionTypeValue() {
        return compressionType_;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @param value The enum numeric value on the wire for compressionType to set.
       * @return This builder for chaining.
       */
      public Builder setCompressionTypeValue(int value) {
        
        compressionType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return The compressionType.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.Common.CompressionType getCompressionType() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.Common.CompressionType result = yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.valueOf(compressionType_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.Common.CompressionType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @param value The compressionType to set.
       * @return This builder for chaining.
       */
      public Builder setCompressionType(yandex.cloud.api.mdb.kafka.v1.Common.CompressionType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        compressionType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Cluster topics compression type.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.CompressionType compression_type = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearCompressionType() {
        
        compressionType_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMessages_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMessagesBuilder_;
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       * @return Whether the logFlushIntervalMessages field is set.
       */
      public boolean hasLogFlushIntervalMessages() {
        return logFlushIntervalMessagesBuilder_ != null || logFlushIntervalMessages_ != null;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       * @return The logFlushIntervalMessages.
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          return logFlushIntervalMessages_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        } else {
          return logFlushIntervalMessagesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMessages_ = value;
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder setLogFlushIntervalMessages(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder mergeLogFlushIntervalMessages(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMessagesBuilder_ == null) {
          if (logFlushIntervalMessages_ != null) {
            logFlushIntervalMessages_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMessages_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMessages_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMessagesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public Builder clearLogFlushIntervalMessages() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessages_ = null;
          onChanged();
        } else {
          logFlushIntervalMessages_ = null;
          logFlushIntervalMessagesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMessagesBuilder() {
        
        onChanged();
        return getLogFlushIntervalMessagesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMessagesOrBuilder() {
        if (logFlushIntervalMessagesBuilder_ != null) {
          return logFlushIntervalMessagesBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMessages_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMessages_;
        }
      }
      /**
       * <pre>
       * The number of messages accumulated on a log partition before messages are flushed to disk.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_messages] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_messages = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMessagesFieldBuilder() {
        if (logFlushIntervalMessagesBuilder_ == null) {
          logFlushIntervalMessagesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMessages(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMessages_ = null;
        }
        return logFlushIntervalMessagesBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushIntervalMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushIntervalMsBuilder_;
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       * @return Whether the logFlushIntervalMs field is set.
       */
      public boolean hasLogFlushIntervalMs() {
        return logFlushIntervalMsBuilder_ != null || logFlushIntervalMs_ != null;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       * @return The logFlushIntervalMs.
       */
      public com.google.protobuf.Int64Value getLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          return logFlushIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        } else {
          return logFlushIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushIntervalMs_ = value;
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder setLogFlushIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder mergeLogFlushIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushIntervalMsBuilder_ == null) {
          if (logFlushIntervalMs_ != null) {
            logFlushIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public Builder clearLogFlushIntervalMs() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMs_ = null;
          onChanged();
        } else {
          logFlushIntervalMs_ = null;
          logFlushIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushIntervalMsOrBuilder() {
        if (logFlushIntervalMsBuilder_ != null) {
          return logFlushIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushIntervalMs_;
        }
      }
      /**
       * <pre>
       * The maximum time (in milliseconds) that a message in any topic is kept in memory before flushed to disk.
       * If not set, the value of [log_flush_scheduler_interval_ms] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.flush_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_interval_ms = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushIntervalMsFieldBuilder() {
        if (logFlushIntervalMsBuilder_ == null) {
          logFlushIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushIntervalMs_ = null;
        }
        return logFlushIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logFlushSchedulerIntervalMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logFlushSchedulerIntervalMsBuilder_;
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       * @return Whether the logFlushSchedulerIntervalMs field is set.
       */
      public boolean hasLogFlushSchedulerIntervalMs() {
        return logFlushSchedulerIntervalMsBuilder_ != null || logFlushSchedulerIntervalMs_ != null;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       * @return The logFlushSchedulerIntervalMs.
       */
      public com.google.protobuf.Int64Value getLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          return logFlushSchedulerIntervalMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        } else {
          return logFlushSchedulerIntervalMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logFlushSchedulerIntervalMs_ = value;
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder setLogFlushSchedulerIntervalMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = builderForValue.build();
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder mergeLogFlushSchedulerIntervalMs(com.google.protobuf.Int64Value value) {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          if (logFlushSchedulerIntervalMs_ != null) {
            logFlushSchedulerIntervalMs_ =
              com.google.protobuf.Int64Value.newBuilder(logFlushSchedulerIntervalMs_).mergeFrom(value).buildPartial();
          } else {
            logFlushSchedulerIntervalMs_ = value;
          }
          onChanged();
        } else {
          logFlushSchedulerIntervalMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public Builder clearLogFlushSchedulerIntervalMs() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMs_ = null;
          onChanged();
        } else {
          logFlushSchedulerIntervalMs_ = null;
          logFlushSchedulerIntervalMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogFlushSchedulerIntervalMsBuilder() {
        
        onChanged();
        return getLogFlushSchedulerIntervalMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogFlushSchedulerIntervalMsOrBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ != null) {
          return logFlushSchedulerIntervalMsBuilder_.getMessageOrBuilder();
        } else {
          return logFlushSchedulerIntervalMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logFlushSchedulerIntervalMs_;
        }
      }
      /**
       * <pre>
       * The frequency of checks (in milliseconds) for any logs that need to be flushed to disk.
       * This check is done by the log flusher.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_flush_scheduler_interval_ms = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogFlushSchedulerIntervalMsFieldBuilder() {
        if (logFlushSchedulerIntervalMsBuilder_ == null) {
          logFlushSchedulerIntervalMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogFlushSchedulerIntervalMs(),
                  getParentForChildren(),
                  isClean());
          logFlushSchedulerIntervalMs_ = null;
        }
        return logFlushSchedulerIntervalMsBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionBytesBuilder_;
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       * @return Whether the logRetentionBytes field is set.
       */
      public boolean hasLogRetentionBytes() {
        return logRetentionBytesBuilder_ != null || logRetentionBytes_ != null;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       * @return The logRetentionBytes.
       */
      public com.google.protobuf.Int64Value getLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          return logRetentionBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        } else {
          return logRetentionBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionBytes_ = value;
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder setLogRetentionBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder mergeLogRetentionBytes(com.google.protobuf.Int64Value value) {
        if (logRetentionBytesBuilder_ == null) {
          if (logRetentionBytes_ != null) {
            logRetentionBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionBytes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionBytes_ = value;
          }
          onChanged();
        } else {
          logRetentionBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public Builder clearLogRetentionBytes() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytes_ = null;
          onChanged();
        } else {
          logRetentionBytes_ = null;
          logRetentionBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionBytesBuilder() {
        
        onChanged();
        return getLogRetentionBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionBytesOrBuilder() {
        if (logRetentionBytesBuilder_ != null) {
          return logRetentionBytesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionBytes_;
        }
      }
      /**
       * <pre>
       * Partition size limit; Kafka will discard old log segments to free up space if `delete` [TopicConfig3.cleanup_policy] is in effect.
       * This setting is helpful if you need to control the size of a log due to limited disk space.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_bytes = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionBytesFieldBuilder() {
        if (logRetentionBytesBuilder_ == null) {
          logRetentionBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionBytes(),
                  getParentForChildren(),
                  isClean());
          logRetentionBytes_ = null;
        }
        return logRetentionBytesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionHours_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionHoursBuilder_;
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       * @return Whether the logRetentionHours field is set.
       */
      public boolean hasLogRetentionHours() {
        return logRetentionHoursBuilder_ != null || logRetentionHours_ != null;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       * @return The logRetentionHours.
       */
      public com.google.protobuf.Int64Value getLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          return logRetentionHours_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        } else {
          return logRetentionHoursBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionHours_ = value;
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder setLogRetentionHours(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionHoursBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder mergeLogRetentionHours(com.google.protobuf.Int64Value value) {
        if (logRetentionHoursBuilder_ == null) {
          if (logRetentionHours_ != null) {
            logRetentionHours_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionHours_).mergeFrom(value).buildPartial();
          } else {
            logRetentionHours_ = value;
          }
          onChanged();
        } else {
          logRetentionHoursBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public Builder clearLogRetentionHours() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHours_ = null;
          onChanged();
        } else {
          logRetentionHours_ = null;
          logRetentionHoursBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionHoursBuilder() {
        
        onChanged();
        return getLogRetentionHoursFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionHoursOrBuilder() {
        if (logRetentionHoursBuilder_ != null) {
          return logRetentionHoursBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionHours_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionHours_;
        }
      }
      /**
       * <pre>
       * The number of hours to keep a log segment file before deleting it.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_hours = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionHoursFieldBuilder() {
        if (logRetentionHoursBuilder_ == null) {
          logRetentionHoursBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionHours(),
                  getParentForChildren(),
                  isClean());
          logRetentionHours_ = null;
        }
        return logRetentionHoursBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMinutes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMinutesBuilder_;
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       * @return Whether the logRetentionMinutes field is set.
       */
      public boolean hasLogRetentionMinutes() {
        return logRetentionMinutesBuilder_ != null || logRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       * @return The logRetentionMinutes.
       */
      public com.google.protobuf.Int64Value getLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          return logRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        } else {
          return logRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMinutes_ = value;
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder setLogRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder mergeLogRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (logRetentionMinutesBuilder_ == null) {
          if (logRetentionMinutes_ != null) {
            logRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          logRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public Builder clearLogRetentionMinutes() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutes_ = null;
          onChanged();
        } else {
          logRetentionMinutes_ = null;
          logRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMinutesBuilder() {
        
        onChanged();
        return getLogRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMinutesOrBuilder() {
        if (logRetentionMinutesBuilder_ != null) {
          return logRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * The number of minutes to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_hours] is used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_minutes = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMinutesFieldBuilder() {
        if (logRetentionMinutesBuilder_ == null) {
          logRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          logRetentionMinutes_ = null;
        }
        return logRetentionMinutesBuilder_;
      }

      private com.google.protobuf.Int64Value logRetentionMs_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logRetentionMsBuilder_;
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       * @return Whether the logRetentionMs field is set.
       */
      public boolean hasLogRetentionMs() {
        return logRetentionMsBuilder_ != null || logRetentionMs_ != null;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       * @return The logRetentionMs.
       */
      public com.google.protobuf.Int64Value getLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          return logRetentionMs_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        } else {
          return logRetentionMsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logRetentionMs_ = value;
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder setLogRetentionMs(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = builderForValue.build();
          onChanged();
        } else {
          logRetentionMsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder mergeLogRetentionMs(com.google.protobuf.Int64Value value) {
        if (logRetentionMsBuilder_ == null) {
          if (logRetentionMs_ != null) {
            logRetentionMs_ =
              com.google.protobuf.Int64Value.newBuilder(logRetentionMs_).mergeFrom(value).buildPartial();
          } else {
            logRetentionMs_ = value;
          }
          onChanged();
        } else {
          logRetentionMsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public Builder clearLogRetentionMs() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMs_ = null;
          onChanged();
        } else {
          logRetentionMs_ = null;
          logRetentionMsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogRetentionMsBuilder() {
        
        onChanged();
        return getLogRetentionMsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogRetentionMsOrBuilder() {
        if (logRetentionMsBuilder_ != null) {
          return logRetentionMsBuilder_.getMessageOrBuilder();
        } else {
          return logRetentionMs_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logRetentionMs_;
        }
      }
      /**
       * <pre>
       * The number of milliseconds to keep a log segment file before deleting it.
       * If not set, the value of [log_retention_minutes] is used.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.retention_ms] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_retention_ms = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogRetentionMsFieldBuilder() {
        if (logRetentionMsBuilder_ == null) {
          logRetentionMsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogRetentionMs(),
                  getParentForChildren(),
                  isClean());
          logRetentionMs_ = null;
        }
        return logRetentionMsBuilder_;
      }

      private com.google.protobuf.Int64Value logSegmentBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> logSegmentBytesBuilder_;
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       * @return Whether the logSegmentBytes field is set.
       */
      public boolean hasLogSegmentBytes() {
        return logSegmentBytesBuilder_ != null || logSegmentBytes_ != null;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       * @return The logSegmentBytes.
       */
      public com.google.protobuf.Int64Value getLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          return logSegmentBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        } else {
          return logSegmentBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logSegmentBytes_ = value;
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder setLogSegmentBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = builderForValue.build();
          onChanged();
        } else {
          logSegmentBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder mergeLogSegmentBytes(com.google.protobuf.Int64Value value) {
        if (logSegmentBytesBuilder_ == null) {
          if (logSegmentBytes_ != null) {
            logSegmentBytes_ =
              com.google.protobuf.Int64Value.newBuilder(logSegmentBytes_).mergeFrom(value).buildPartial();
          } else {
            logSegmentBytes_ = value;
          }
          onChanged();
        } else {
          logSegmentBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public Builder clearLogSegmentBytes() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytes_ = null;
          onChanged();
        } else {
          logSegmentBytes_ = null;
          logSegmentBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64Value.Builder getLogSegmentBytesBuilder() {
        
        onChanged();
        return getLogSegmentBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getLogSegmentBytesOrBuilder() {
        if (logSegmentBytesBuilder_ != null) {
          return logSegmentBytesBuilder_.getMessageOrBuilder();
        } else {
          return logSegmentBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : logSegmentBytes_;
        }
      }
      /**
       * <pre>
       * The maximum size of a single log file.
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.segment_bytes] setting.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value log_segment_bytes = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getLogSegmentBytesFieldBuilder() {
        if (logSegmentBytesBuilder_ == null) {
          logSegmentBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getLogSegmentBytes(),
                  getParentForChildren(),
                  isClean());
          logSegmentBytes_ = null;
        }
        return logSegmentBytesBuilder_;
      }

      private com.google.protobuf.BoolValue logPreallocate_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> logPreallocateBuilder_;
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       * @return Whether the logPreallocate field is set.
       */
      public boolean hasLogPreallocate() {
        return logPreallocateBuilder_ != null || logPreallocate_ != null;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       * @return The logPreallocate.
       */
      public com.google.protobuf.BoolValue getLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          return logPreallocate_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        } else {
          return logPreallocateBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logPreallocate_ = value;
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder setLogPreallocate(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = builderForValue.build();
          onChanged();
        } else {
          logPreallocateBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder mergeLogPreallocate(com.google.protobuf.BoolValue value) {
        if (logPreallocateBuilder_ == null) {
          if (logPreallocate_ != null) {
            logPreallocate_ =
              com.google.protobuf.BoolValue.newBuilder(logPreallocate_).mergeFrom(value).buildPartial();
          } else {
            logPreallocate_ = value;
          }
          onChanged();
        } else {
          logPreallocateBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public Builder clearLogPreallocate() {
        if (logPreallocateBuilder_ == null) {
          logPreallocate_ = null;
          onChanged();
        } else {
          logPreallocate_ = null;
          logPreallocateBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValue.Builder getLogPreallocateBuilder() {
        
        onChanged();
        return getLogPreallocateFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getLogPreallocateOrBuilder() {
        if (logPreallocateBuilder_ != null) {
          return logPreallocateBuilder_.getMessageOrBuilder();
        } else {
          return logPreallocate_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : logPreallocate_;
        }
      }
      /**
       * <pre>
       * Should pre allocate file when create new segment?
       * This is the global cluster-level setting that can be overridden on a topic level by using the [TopicConfig3.preallocate] setting.
       * </pre>
       *
       * <code>.google.protobuf.BoolValue log_preallocate = 10;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getLogPreallocateFieldBuilder() {
        if (logPreallocateBuilder_ == null) {
          logPreallocateBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getLogPreallocate(),
                  getParentForChildren(),
                  isClean());
          logPreallocate_ = null;
        }
        return logPreallocateBuilder_;
      }

      private com.google.protobuf.Int64Value socketSendBufferBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketSendBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       * @return Whether the socketSendBufferBytes field is set.
       */
      public boolean hasSocketSendBufferBytes() {
        return socketSendBufferBytesBuilder_ != null || socketSendBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       * @return The socketSendBufferBytes.
       */
      public com.google.protobuf.Int64Value getSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          return socketSendBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        } else {
          return socketSendBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketSendBufferBytes_ = value;
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder setSocketSendBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder mergeSocketSendBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketSendBufferBytesBuilder_ == null) {
          if (socketSendBufferBytes_ != null) {
            socketSendBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketSendBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketSendBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketSendBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public Builder clearSocketSendBufferBytes() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytes_ = null;
          onChanged();
        } else {
          socketSendBufferBytes_ = null;
          socketSendBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketSendBufferBytesBuilder() {
        
        onChanged();
        return getSocketSendBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketSendBufferBytesOrBuilder() {
        if (socketSendBufferBytesBuilder_ != null) {
          return socketSendBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketSendBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketSendBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_SNDBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_send_buffer_bytes = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketSendBufferBytesFieldBuilder() {
        if (socketSendBufferBytesBuilder_ == null) {
          socketSendBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketSendBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketSendBufferBytes_ = null;
        }
        return socketSendBufferBytesBuilder_;
      }

      private com.google.protobuf.Int64Value socketReceiveBufferBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> socketReceiveBufferBytesBuilder_;
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       * @return Whether the socketReceiveBufferBytes field is set.
       */
      public boolean hasSocketReceiveBufferBytes() {
        return socketReceiveBufferBytesBuilder_ != null || socketReceiveBufferBytes_ != null;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       * @return The socketReceiveBufferBytes.
       */
      public com.google.protobuf.Int64Value getSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          return socketReceiveBufferBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        } else {
          return socketReceiveBufferBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          socketReceiveBufferBytes_ = value;
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder setSocketReceiveBufferBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = builderForValue.build();
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder mergeSocketReceiveBufferBytes(com.google.protobuf.Int64Value value) {
        if (socketReceiveBufferBytesBuilder_ == null) {
          if (socketReceiveBufferBytes_ != null) {
            socketReceiveBufferBytes_ =
              com.google.protobuf.Int64Value.newBuilder(socketReceiveBufferBytes_).mergeFrom(value).buildPartial();
          } else {
            socketReceiveBufferBytes_ = value;
          }
          onChanged();
        } else {
          socketReceiveBufferBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public Builder clearSocketReceiveBufferBytes() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytes_ = null;
          onChanged();
        } else {
          socketReceiveBufferBytes_ = null;
          socketReceiveBufferBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64Value.Builder getSocketReceiveBufferBytesBuilder() {
        
        onChanged();
        return getSocketReceiveBufferBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getSocketReceiveBufferBytesOrBuilder() {
        if (socketReceiveBufferBytesBuilder_ != null) {
          return socketReceiveBufferBytesBuilder_.getMessageOrBuilder();
        } else {
          return socketReceiveBufferBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : socketReceiveBufferBytes_;
        }
      }
      /**
       * <pre>
       * The SO_RCVBUF buffer of the socket server sockets. If the value is -1, the OS default will be used.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value socket_receive_buffer_bytes = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getSocketReceiveBufferBytesFieldBuilder() {
        if (socketReceiveBufferBytesBuilder_ == null) {
          socketReceiveBufferBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getSocketReceiveBufferBytes(),
                  getParentForChildren(),
                  isClean());
          socketReceiveBufferBytes_ = null;
        }
        return socketReceiveBufferBytesBuilder_;
      }

      private com.google.protobuf.BoolValue autoCreateTopicsEnable_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> autoCreateTopicsEnableBuilder_;
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       * @return Whether the autoCreateTopicsEnable field is set.
       */
      public boolean hasAutoCreateTopicsEnable() {
        return autoCreateTopicsEnableBuilder_ != null || autoCreateTopicsEnable_ != null;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       * @return The autoCreateTopicsEnable.
       */
      public com.google.protobuf.BoolValue getAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          return autoCreateTopicsEnable_ == null ? com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        } else {
          return autoCreateTopicsEnableBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          autoCreateTopicsEnable_ = value;
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder setAutoCreateTopicsEnable(
          com.google.protobuf.BoolValue.Builder builderForValue) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = builderForValue.build();
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder mergeAutoCreateTopicsEnable(com.google.protobuf.BoolValue value) {
        if (autoCreateTopicsEnableBuilder_ == null) {
          if (autoCreateTopicsEnable_ != null) {
            autoCreateTopicsEnable_ =
              com.google.protobuf.BoolValue.newBuilder(autoCreateTopicsEnable_).mergeFrom(value).buildPartial();
          } else {
            autoCreateTopicsEnable_ = value;
          }
          onChanged();
        } else {
          autoCreateTopicsEnableBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public Builder clearAutoCreateTopicsEnable() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnable_ = null;
          onChanged();
        } else {
          autoCreateTopicsEnable_ = null;
          autoCreateTopicsEnableBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValue.Builder getAutoCreateTopicsEnableBuilder() {
        
        onChanged();
        return getAutoCreateTopicsEnableFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      public com.google.protobuf.BoolValueOrBuilder getAutoCreateTopicsEnableOrBuilder() {
        if (autoCreateTopicsEnableBuilder_ != null) {
          return autoCreateTopicsEnableBuilder_.getMessageOrBuilder();
        } else {
          return autoCreateTopicsEnable_ == null ?
              com.google.protobuf.BoolValue.getDefaultInstance() : autoCreateTopicsEnable_;
        }
      }
      /**
       * <pre>
       * Enable auto creation of topic on the server
       * </pre>
       *
       * <code>.google.protobuf.BoolValue auto_create_topics_enable = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder> 
          getAutoCreateTopicsEnableFieldBuilder() {
        if (autoCreateTopicsEnableBuilder_ == null) {
          autoCreateTopicsEnableBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.BoolValue, com.google.protobuf.BoolValue.Builder, com.google.protobuf.BoolValueOrBuilder>(
                  getAutoCreateTopicsEnable(),
                  getParentForChildren(),
                  isClean());
          autoCreateTopicsEnable_ = null;
        }
        return autoCreateTopicsEnableBuilder_;
      }

      private com.google.protobuf.Int64Value numPartitions_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> numPartitionsBuilder_;
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       * @return Whether the numPartitions field is set.
       */
      public boolean hasNumPartitions() {
        return numPartitionsBuilder_ != null || numPartitions_ != null;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       * @return The numPartitions.
       */
      public com.google.protobuf.Int64Value getNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          return numPartitions_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        } else {
          return numPartitionsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          numPartitions_ = value;
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder setNumPartitions(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = builderForValue.build();
          onChanged();
        } else {
          numPartitionsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder mergeNumPartitions(com.google.protobuf.Int64Value value) {
        if (numPartitionsBuilder_ == null) {
          if (numPartitions_ != null) {
            numPartitions_ =
              com.google.protobuf.Int64Value.newBuilder(numPartitions_).mergeFrom(value).buildPartial();
          } else {
            numPartitions_ = value;
          }
          onChanged();
        } else {
          numPartitionsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public Builder clearNumPartitions() {
        if (numPartitionsBuilder_ == null) {
          numPartitions_ = null;
          onChanged();
        } else {
          numPartitions_ = null;
          numPartitionsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64Value.Builder getNumPartitionsBuilder() {
        
        onChanged();
        return getNumPartitionsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getNumPartitionsOrBuilder() {
        if (numPartitionsBuilder_ != null) {
          return numPartitionsBuilder_.getMessageOrBuilder();
        } else {
          return numPartitions_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : numPartitions_;
        }
      }
      /**
       * <pre>
       * Default number of partitions per topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value num_partitions = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getNumPartitionsFieldBuilder() {
        if (numPartitionsBuilder_ == null) {
          numPartitionsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getNumPartitions(),
                  getParentForChildren(),
                  isClean());
          numPartitions_ = null;
        }
        return numPartitionsBuilder_;
      }

      private com.google.protobuf.Int64Value defaultReplicationFactor_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> defaultReplicationFactorBuilder_;
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       * @return Whether the defaultReplicationFactor field is set.
       */
      public boolean hasDefaultReplicationFactor() {
        return defaultReplicationFactorBuilder_ != null || defaultReplicationFactor_ != null;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       * @return The defaultReplicationFactor.
       */
      public com.google.protobuf.Int64Value getDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          return defaultReplicationFactor_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        } else {
          return defaultReplicationFactorBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultReplicationFactor_ = value;
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder setDefaultReplicationFactor(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = builderForValue.build();
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder mergeDefaultReplicationFactor(com.google.protobuf.Int64Value value) {
        if (defaultReplicationFactorBuilder_ == null) {
          if (defaultReplicationFactor_ != null) {
            defaultReplicationFactor_ =
              com.google.protobuf.Int64Value.newBuilder(defaultReplicationFactor_).mergeFrom(value).buildPartial();
          } else {
            defaultReplicationFactor_ = value;
          }
          onChanged();
        } else {
          defaultReplicationFactorBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public Builder clearDefaultReplicationFactor() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactor_ = null;
          onChanged();
        } else {
          defaultReplicationFactor_ = null;
          defaultReplicationFactorBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64Value.Builder getDefaultReplicationFactorBuilder() {
        
        onChanged();
        return getDefaultReplicationFactorFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getDefaultReplicationFactorOrBuilder() {
        if (defaultReplicationFactorBuilder_ != null) {
          return defaultReplicationFactorBuilder_.getMessageOrBuilder();
        } else {
          return defaultReplicationFactor_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : defaultReplicationFactor_;
        }
      }
      /**
       * <pre>
       * Default replication factor of the topic on the whole cluster
       * </pre>
       *
       * <code>.google.protobuf.Int64Value default_replication_factor = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getDefaultReplicationFactorFieldBuilder() {
        if (defaultReplicationFactorBuilder_ == null) {
          defaultReplicationFactorBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getDefaultReplicationFactor(),
                  getParentForChildren(),
                  isClean());
          defaultReplicationFactor_ = null;
        }
        return defaultReplicationFactorBuilder_;
      }

      private com.google.protobuf.Int64Value messageMaxBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> messageMaxBytesBuilder_;
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       * @return Whether the messageMaxBytes field is set.
       */
      public boolean hasMessageMaxBytes() {
        return messageMaxBytesBuilder_ != null || messageMaxBytes_ != null;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       * @return The messageMaxBytes.
       */
      public com.google.protobuf.Int64Value getMessageMaxBytes() {
        if (messageMaxBytesBuilder_ == null) {
          return messageMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
        } else {
          return messageMaxBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder setMessageMaxBytes(com.google.protobuf.Int64Value value) {
        if (messageMaxBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          messageMaxBytes_ = value;
          onChanged();
        } else {
          messageMaxBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder setMessageMaxBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = builderForValue.build();
          onChanged();
        } else {
          messageMaxBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder mergeMessageMaxBytes(com.google.protobuf.Int64Value value) {
        if (messageMaxBytesBuilder_ == null) {
          if (messageMaxBytes_ != null) {
            messageMaxBytes_ =
              com.google.protobuf.Int64Value.newBuilder(messageMaxBytes_).mergeFrom(value).buildPartial();
          } else {
            messageMaxBytes_ = value;
          }
          onChanged();
        } else {
          messageMaxBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public Builder clearMessageMaxBytes() {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytes_ = null;
          onChanged();
        } else {
          messageMaxBytes_ = null;
          messageMaxBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public com.google.protobuf.Int64Value.Builder getMessageMaxBytesBuilder() {
        
        onChanged();
        return getMessageMaxBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getMessageMaxBytesOrBuilder() {
        if (messageMaxBytesBuilder_ != null) {
          return messageMaxBytesBuilder_.getMessageOrBuilder();
        } else {
          return messageMaxBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : messageMaxBytes_;
        }
      }
      /**
       * <pre>
       * The largest record batch size allowed by Kafka. Default value: 1048588.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value message_max_bytes = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getMessageMaxBytesFieldBuilder() {
        if (messageMaxBytesBuilder_ == null) {
          messageMaxBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getMessageMaxBytes(),
                  getParentForChildren(),
                  isClean());
          messageMaxBytes_ = null;
        }
        return messageMaxBytesBuilder_;
      }

      private com.google.protobuf.Int64Value replicaFetchMaxBytes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> replicaFetchMaxBytesBuilder_;
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       * @return Whether the replicaFetchMaxBytes field is set.
       */
      public boolean hasReplicaFetchMaxBytes() {
        return replicaFetchMaxBytesBuilder_ != null || replicaFetchMaxBytes_ != null;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       * @return The replicaFetchMaxBytes.
       */
      public com.google.protobuf.Int64Value getReplicaFetchMaxBytes() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          return replicaFetchMaxBytes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
        } else {
          return replicaFetchMaxBytesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder setReplicaFetchMaxBytes(com.google.protobuf.Int64Value value) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          replicaFetchMaxBytes_ = value;
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder setReplicaFetchMaxBytes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = builderForValue.build();
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder mergeReplicaFetchMaxBytes(com.google.protobuf.Int64Value value) {
        if (replicaFetchMaxBytesBuilder_ == null) {
          if (replicaFetchMaxBytes_ != null) {
            replicaFetchMaxBytes_ =
              com.google.protobuf.Int64Value.newBuilder(replicaFetchMaxBytes_).mergeFrom(value).buildPartial();
          } else {
            replicaFetchMaxBytes_ = value;
          }
          onChanged();
        } else {
          replicaFetchMaxBytesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public Builder clearReplicaFetchMaxBytes() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytes_ = null;
          onChanged();
        } else {
          replicaFetchMaxBytes_ = null;
          replicaFetchMaxBytesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public com.google.protobuf.Int64Value.Builder getReplicaFetchMaxBytesBuilder() {
        
        onChanged();
        return getReplicaFetchMaxBytesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getReplicaFetchMaxBytesOrBuilder() {
        if (replicaFetchMaxBytesBuilder_ != null) {
          return replicaFetchMaxBytesBuilder_.getMessageOrBuilder();
        } else {
          return replicaFetchMaxBytes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : replicaFetchMaxBytes_;
        }
      }
      /**
       * <pre>
       * The number of bytes of messages to attempt to fetch for each partition. Default value: 1048576.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value replica_fetch_max_bytes = 17;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getReplicaFetchMaxBytesFieldBuilder() {
        if (replicaFetchMaxBytesBuilder_ == null) {
          replicaFetchMaxBytesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getReplicaFetchMaxBytes(),
                  getParentForChildren(),
                  isClean());
          replicaFetchMaxBytes_ = null;
        }
        return replicaFetchMaxBytesBuilder_;
      }

      private com.google.protobuf.LazyStringList sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureSslCipherSuitesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          sslCipherSuites_ = new com.google.protobuf.LazyStringArrayList(sslCipherSuites_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return A list containing the sslCipherSuites.
       */
      public com.google.protobuf.ProtocolStringList
          getSslCipherSuitesList() {
        return sslCipherSuites_.getUnmodifiableView();
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return The count of sslCipherSuites.
       */
      public int getSslCipherSuitesCount() {
        return sslCipherSuites_.size();
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index of the element to return.
       * @return The sslCipherSuites at the given index.
       */
      public java.lang.String getSslCipherSuites(int index) {
        return sslCipherSuites_.get(index);
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index of the value to return.
       * @return The bytes of the sslCipherSuites at the given index.
       */
      public com.google.protobuf.ByteString
          getSslCipherSuitesBytes(int index) {
        return sslCipherSuites_.getByteString(index);
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param index The index to set the value at.
       * @param value The sslCipherSuites to set.
       * @return This builder for chaining.
       */
      public Builder setSslCipherSuites(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param value The sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addSslCipherSuites(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param values The sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addAllSslCipherSuites(
          java.lang.Iterable<java.lang.String> values) {
        ensureSslCipherSuitesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, sslCipherSuites_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @return This builder for chaining.
       */
      public Builder clearSslCipherSuites() {
        sslCipherSuites_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of cipher suites.
       * </pre>
       *
       * <code>repeated string ssl_cipher_suites = 18;</code>
       * @param value The bytes of the sslCipherSuites to add.
       * @return This builder for chaining.
       */
      public Builder addSslCipherSuitesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureSslCipherSuitesIsMutable();
        sslCipherSuites_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.Int64Value offsetsRetentionMinutes_;
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> offsetsRetentionMinutesBuilder_;
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       * @return Whether the offsetsRetentionMinutes field is set.
       */
      public boolean hasOffsetsRetentionMinutes() {
        return offsetsRetentionMinutesBuilder_ != null || offsetsRetentionMinutes_ != null;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       * @return The offsetsRetentionMinutes.
       */
      public com.google.protobuf.Int64Value getOffsetsRetentionMinutes() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          return offsetsRetentionMinutes_ == null ? com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
        } else {
          return offsetsRetentionMinutesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder setOffsetsRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          offsetsRetentionMinutes_ = value;
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder setOffsetsRetentionMinutes(
          com.google.protobuf.Int64Value.Builder builderForValue) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = builderForValue.build();
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder mergeOffsetsRetentionMinutes(com.google.protobuf.Int64Value value) {
        if (offsetsRetentionMinutesBuilder_ == null) {
          if (offsetsRetentionMinutes_ != null) {
            offsetsRetentionMinutes_ =
              com.google.protobuf.Int64Value.newBuilder(offsetsRetentionMinutes_).mergeFrom(value).buildPartial();
          } else {
            offsetsRetentionMinutes_ = value;
          }
          onChanged();
        } else {
          offsetsRetentionMinutesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public Builder clearOffsetsRetentionMinutes() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutes_ = null;
          onChanged();
        } else {
          offsetsRetentionMinutes_ = null;
          offsetsRetentionMinutesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public com.google.protobuf.Int64Value.Builder getOffsetsRetentionMinutesBuilder() {
        
        onChanged();
        return getOffsetsRetentionMinutesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      public com.google.protobuf.Int64ValueOrBuilder getOffsetsRetentionMinutesOrBuilder() {
        if (offsetsRetentionMinutesBuilder_ != null) {
          return offsetsRetentionMinutesBuilder_.getMessageOrBuilder();
        } else {
          return offsetsRetentionMinutes_ == null ?
              com.google.protobuf.Int64Value.getDefaultInstance() : offsetsRetentionMinutes_;
        }
      }
      /**
       * <pre>
       * Offset storage time after a consumer group loses all its consumers. Default: 10080.
       * </pre>
       *
       * <code>.google.protobuf.Int64Value offsets_retention_minutes = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder> 
          getOffsetsRetentionMinutesFieldBuilder() {
        if (offsetsRetentionMinutesBuilder_ == null) {
          offsetsRetentionMinutesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              com.google.protobuf.Int64Value, com.google.protobuf.Int64Value.Builder, com.google.protobuf.Int64ValueOrBuilder>(
                  getOffsetsRetentionMinutes(),
                  getParentForChildren(),
                  isClean());
          offsetsRetentionMinutes_ = null;
        }
        return offsetsRetentionMinutesBuilder_;
      }

      private java.util.List<java.lang.Integer> saslEnabledMechanisms_ =
        java.util.Collections.emptyList();
      private void ensureSaslEnabledMechanismsIsMutable() {
        if (!((bitField0_ & 0x00000002) != 0)) {
          saslEnabledMechanisms_ = new java.util.ArrayList<java.lang.Integer>(saslEnabledMechanisms_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return A list containing the saslEnabledMechanisms.
       */
      public java.util.List<yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> getSaslEnabledMechanismsList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism>(saslEnabledMechanisms_, saslEnabledMechanisms_converter_);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return The count of saslEnabledMechanisms.
       */
      public int getSaslEnabledMechanismsCount() {
        return saslEnabledMechanisms_.size();
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the element to return.
       * @return The saslEnabledMechanisms at the given index.
       */
      public yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism getSaslEnabledMechanisms(int index) {
        return saslEnabledMechanisms_converter_.convert(saslEnabledMechanisms_.get(index));
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index to set the value at.
       * @param value The saslEnabledMechanisms to set.
       * @return This builder for chaining.
       */
      public Builder setSaslEnabledMechanisms(
          int index, yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param value The saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addSaslEnabledMechanisms(yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param values The saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addAllSaslEnabledMechanisms(
          java.lang.Iterable<? extends yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism> values) {
        ensureSaslEnabledMechanismsIsMutable();
        for (yandex.cloud.api.mdb.kafka.v1.Common.SaslMechanism value : values) {
          saslEnabledMechanisms_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return This builder for chaining.
       */
      public Builder clearSaslEnabledMechanisms() {
        saslEnabledMechanisms_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @return A list containing the enum numeric values on the wire for saslEnabledMechanisms.
       */
      public java.util.List<java.lang.Integer>
      getSaslEnabledMechanismsValueList() {
        return java.util.Collections.unmodifiableList(saslEnabledMechanisms_);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the value to return.
       * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
       */
      public int getSaslEnabledMechanismsValue(int index) {
        return saslEnabledMechanisms_.get(index);
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param index The index of the value to return.
       * @return The enum numeric value on the wire of saslEnabledMechanisms at the given index.
       * @return This builder for chaining.
       */
      public Builder setSaslEnabledMechanismsValue(
          int index, int value) {
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param value The enum numeric value on the wire for saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addSaslEnabledMechanismsValue(int value) {
        ensureSaslEnabledMechanismsIsMutable();
        saslEnabledMechanisms_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The list of SASL mechanisms enabled in the Kafka server. Default: [SCRAM_SHA_512].
       * </pre>
       *
       * <code>repeated .yandex.cloud.mdb.kafka.v1.SaslMechanism sasl_enabled_mechanisms = 20;</code>
       * @param values The enum numeric values on the wire for saslEnabledMechanisms to add.
       * @return This builder for chaining.
       */
      public Builder addAllSaslEnabledMechanismsValue(
          java.lang.Iterable<java.lang.Integer> values) {
        ensureSaslEnabledMechanismsIsMutable();
        for (int value : values) {
          saslEnabledMechanisms_.add(value);
        }
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig3)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.KafkaConfig3)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<KafkaConfig3>
        PARSER = new com.google.protobuf.AbstractParser<KafkaConfig3>() {
      @java.lang.Override
      public KafkaConfig3 parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KafkaConfig3(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<KafkaConfig3> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<KafkaConfig3> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.KafkaConfig3 getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface HostOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Host)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The clusterId.
     */
    java.lang.String getClusterId();
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The bytes for clusterId.
     */
    com.google.protobuf.ByteString
        getClusterIdBytes();

    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     * @return The zoneId.
     */
    java.lang.String getZoneId();
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     * @return The bytes for zoneId.
     */
    com.google.protobuf.ByteString
        getZoneIdBytes();

    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     * @return The enum numeric value on the wire for role.
     */
    int getRoleValue();
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     * @return The role.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole();

    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     * @return Whether the resources field is set.
     */
    boolean hasResources();
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     * @return The resources.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources();
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder();

    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     * @return The enum numeric value on the wire for health.
     */
    int getHealthValue();
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     * @return The health.
     */
    yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth();

    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     * @return The subnetId.
     */
    java.lang.String getSubnetId();
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     * @return The bytes for subnetId.
     */
    com.google.protobuf.ByteString
        getSubnetIdBytes();

    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the node.
     * If the value is `true`, then this node is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 9;</code>
     * @return The assignPublicIp.
     */
    boolean getAssignPublicIp();
  }
  /**
   * <pre>
   * Cluster host metadata.
   * </pre>
   *
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Host}
   */
  public static final class Host extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Host)
      HostOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Host.newBuilder() to construct.
    private Host(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Host() {
      name_ = "";
      clusterId_ = "";
      zoneId_ = "";
      role_ = 0;
      health_ = 0;
      subnetId_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Host();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Host(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              java.lang.String s = input.readStringRequireUtf8();

              clusterId_ = s;
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              zoneId_ = s;
              break;
            }
            case 32: {
              int rawValue = input.readEnum();

              role_ = rawValue;
              break;
            }
            case 42: {
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder subBuilder = null;
              if (resources_ != null) {
                subBuilder = resources_.toBuilder();
              }
              resources_ = input.readMessage(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resources_);
                resources_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {
              int rawValue = input.readEnum();

              health_ = rawValue;
              break;
            }
            case 66: {
              java.lang.String s = input.readStringRequireUtf8();

              subnetId_ = s;
              break;
            }
            case 72: {

              assignPublicIp_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Builder.class);
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Host.Role}
     */
    public enum Role
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>ROLE_UNSPECIFIED = 0;</code>
       */
      ROLE_UNSPECIFIED(0),
      /**
       * <pre>
       * the host is a Kafka broker.
       * </pre>
       *
       * <code>KAFKA = 1;</code>
       */
      KAFKA(1),
      /**
       * <pre>
       * the host is a ZooKeeper server.
       * </pre>
       *
       * <code>ZOOKEEPER = 2;</code>
       */
      ZOOKEEPER(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <code>ROLE_UNSPECIFIED = 0;</code>
       */
      public static final int ROLE_UNSPECIFIED_VALUE = 0;
      /**
       * <pre>
       * the host is a Kafka broker.
       * </pre>
       *
       * <code>KAFKA = 1;</code>
       */
      public static final int KAFKA_VALUE = 1;
      /**
       * <pre>
       * the host is a ZooKeeper server.
       * </pre>
       *
       * <code>ZOOKEEPER = 2;</code>
       */
      public static final int ZOOKEEPER_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Role valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Role forNumber(int value) {
        switch (value) {
          case 0: return ROLE_UNSPECIFIED;
          case 1: return KAFKA;
          case 2: return ZOOKEEPER;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Role>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Role> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Role>() {
              public Role findValueByNumber(int number) {
                return Role.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDescriptor().getEnumTypes().get(0);
      }

      private static final Role[] VALUES = values();

      public static Role valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Role(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Host.Role)
    }

    /**
     * Protobuf enum {@code yandex.cloud.mdb.kafka.v1.Host.Health}
     */
    public enum Health
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       * health of the host is unknown.
       * </pre>
       *
       * <code>UNKNOWN = 0;</code>
       */
      UNKNOWN(0),
      /**
       * <pre>
       * the host is performing all its functions normally.
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      ALIVE(1),
      /**
       * <pre>
       * the host is inoperable and cannot perform any of its essential functions.
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      DEAD(2),
      /**
       * <pre>
       * the host is degraded and can perform only some of its essential functions.
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      DEGRADED(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       * health of the host is unknown.
       * </pre>
       *
       * <code>UNKNOWN = 0;</code>
       */
      public static final int UNKNOWN_VALUE = 0;
      /**
       * <pre>
       * the host is performing all its functions normally.
       * </pre>
       *
       * <code>ALIVE = 1;</code>
       */
      public static final int ALIVE_VALUE = 1;
      /**
       * <pre>
       * the host is inoperable and cannot perform any of its essential functions.
       * </pre>
       *
       * <code>DEAD = 2;</code>
       */
      public static final int DEAD_VALUE = 2;
      /**
       * <pre>
       * the host is degraded and can perform only some of its essential functions.
       * </pre>
       *
       * <code>DEGRADED = 3;</code>
       */
      public static final int DEGRADED_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static Health valueOf(int value) {
        return forNumber(value);
      }

      /**
       * @param value The numeric wire value of the corresponding enum entry.
       * @return The enum associated with the given numeric wire value.
       */
      public static Health forNumber(int value) {
        switch (value) {
          case 0: return UNKNOWN;
          case 1: return ALIVE;
          case 2: return DEAD;
          case 3: return DEGRADED;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Health>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Health> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Health>() {
              public Health findValueByNumber(int number) {
                return Health.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        if (this == UNRECOGNIZED) {
          throw new java.lang.IllegalStateException(
              "Can't get the descriptor of an unrecognized enum value.");
        }
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDescriptor().getEnumTypes().get(1);
      }

      private static final Health[] VALUES = values();

      public static Health valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Health(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:yandex.cloud.mdb.kafka.v1.Host.Health)
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Name of the host.
     * </pre>
     *
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLUSTER_ID_FIELD_NUMBER = 2;
    private volatile java.lang.Object clusterId_;
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The clusterId.
     */
    @java.lang.Override
    public java.lang.String getClusterId() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        clusterId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the Apache Kafka® cluster.
     * </pre>
     *
     * <code>string cluster_id = 2;</code>
     * @return The bytes for clusterId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getClusterIdBytes() {
      java.lang.Object ref = clusterId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        clusterId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ZONE_ID_FIELD_NUMBER = 3;
    private volatile java.lang.Object zoneId_;
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     * @return The zoneId.
     */
    @java.lang.Override
    public java.lang.String getZoneId() {
      java.lang.Object ref = zoneId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        zoneId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the availability zone where the host resides.
     * </pre>
     *
     * <code>string zone_id = 3;</code>
     * @return The bytes for zoneId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getZoneIdBytes() {
      java.lang.Object ref = zoneId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        zoneId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ROLE_FIELD_NUMBER = 4;
    private int role_;
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     * @return The enum numeric value on the wire for role.
     */
    @java.lang.Override public int getRoleValue() {
      return role_;
    }
    /**
     * <pre>
     * Host role.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
     * @return The role.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.valueOf(role_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.UNRECOGNIZED : result;
    }

    public static final int RESOURCES_FIELD_NUMBER = 5;
    private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     * @return Whether the resources field is set.
     */
    @java.lang.Override
    public boolean hasResources() {
      return resources_ != null;
    }
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     * @return The resources.
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
      return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
    }
    /**
     * <pre>
     * Computational resources allocated to the host.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
     */
    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
      return getResources();
    }

    public static final int HEALTH_FIELD_NUMBER = 6;
    private int health_;
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     * @return The enum numeric value on the wire for health.
     */
    @java.lang.Override public int getHealthValue() {
      return health_;
    }
    /**
     * <pre>
     * Aggregated host health data.
     * </pre>
     *
     * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
     * @return The health.
     */
    @java.lang.Override public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth() {
      @SuppressWarnings("deprecation")
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.valueOf(health_);
      return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNRECOGNIZED : result;
    }

    public static final int SUBNET_ID_FIELD_NUMBER = 8;
    private volatile java.lang.Object subnetId_;
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     * @return The subnetId.
     */
    @java.lang.Override
    public java.lang.String getSubnetId() {
      java.lang.Object ref = subnetId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        subnetId_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * ID of the subnet the host resides in.
     * </pre>
     *
     * <code>string subnet_id = 8;</code>
     * @return The bytes for subnetId.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getSubnetIdBytes() {
      java.lang.Object ref = subnetId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        subnetId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int ASSIGN_PUBLIC_IP_FIELD_NUMBER = 9;
    private boolean assignPublicIp_;
    /**
     * <pre>
     * The flag that defines whether a public IP address is assigned to the node.
     * If the value is `true`, then this node is available on the Internet via it's public IP address.
     * </pre>
     *
     * <code>bool assign_public_ip = 9;</code>
     * @return The assignPublicIp.
     */
    @java.lang.Override
    public boolean getAssignPublicIp() {
      return assignPublicIp_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(zoneId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, zoneId_);
      }
      if (role_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.ROLE_UNSPECIFIED.getNumber()) {
        output.writeEnum(4, role_);
      }
      if (resources_ != null) {
        output.writeMessage(5, getResources());
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNKNOWN.getNumber()) {
        output.writeEnum(6, health_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(subnetId_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, subnetId_);
      }
      if (assignPublicIp_ != false) {
        output.writeBool(9, assignPublicIp_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(clusterId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, clusterId_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(zoneId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, zoneId_);
      }
      if (role_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.ROLE_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, role_);
      }
      if (resources_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getResources());
      }
      if (health_ != yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNKNOWN.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, health_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(subnetId_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, subnetId_);
      }
      if (assignPublicIp_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, assignPublicIp_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) obj;

      if (!getName()
          .equals(other.getName())) return false;
      if (!getClusterId()
          .equals(other.getClusterId())) return false;
      if (!getZoneId()
          .equals(other.getZoneId())) return false;
      if (role_ != other.role_) return false;
      if (hasResources() != other.hasResources()) return false;
      if (hasResources()) {
        if (!getResources()
            .equals(other.getResources())) return false;
      }
      if (health_ != other.health_) return false;
      if (!getSubnetId()
          .equals(other.getSubnetId())) return false;
      if (getAssignPublicIp()
          != other.getAssignPublicIp()) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
      hash = (53 * hash) + getClusterId().hashCode();
      hash = (37 * hash) + ZONE_ID_FIELD_NUMBER;
      hash = (53 * hash) + getZoneId().hashCode();
      hash = (37 * hash) + ROLE_FIELD_NUMBER;
      hash = (53 * hash) + role_;
      if (hasResources()) {
        hash = (37 * hash) + RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getResources().hashCode();
      }
      hash = (37 * hash) + HEALTH_FIELD_NUMBER;
      hash = (53 * hash) + health_;
      hash = (37 * hash) + SUBNET_ID_FIELD_NUMBER;
      hash = (53 * hash) + getSubnetId().hashCode();
      hash = (37 * hash) + ASSIGN_PUBLIC_IP_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAssignPublicIp());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Cluster host metadata.
     * </pre>
     *
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Host}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Host)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.HostOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        clusterId_ = "";

        zoneId_ = "";

        role_ = 0;

        if (resourcesBuilder_ == null) {
          resources_ = null;
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }
        health_ = 0;

        subnetId_ = "";

        assignPublicIp_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host(this);
        result.name_ = name_;
        result.clusterId_ = clusterId_;
        result.zoneId_ = zoneId_;
        result.role_ = role_;
        if (resourcesBuilder_ == null) {
          result.resources_ = resources_;
        } else {
          result.resources_ = resourcesBuilder_.build();
        }
        result.health_ = health_;
        result.subnetId_ = subnetId_;
        result.assignPublicIp_ = assignPublicIp_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getClusterId().isEmpty()) {
          clusterId_ = other.clusterId_;
          onChanged();
        }
        if (!other.getZoneId().isEmpty()) {
          zoneId_ = other.zoneId_;
          onChanged();
        }
        if (other.role_ != 0) {
          setRoleValue(other.getRoleValue());
        }
        if (other.hasResources()) {
          mergeResources(other.getResources());
        }
        if (other.health_ != 0) {
          setHealthValue(other.getHealthValue());
        }
        if (!other.getSubnetId().isEmpty()) {
          subnetId_ = other.subnetId_;
          onChanged();
        }
        if (other.getAssignPublicIp() != false) {
          setAssignPublicIp(other.getAssignPublicIp());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Name of the host.
       * </pre>
       *
       * <code>string name = 1;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object clusterId_ = "";
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return The clusterId.
       */
      public java.lang.String getClusterId() {
        java.lang.Object ref = clusterId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          clusterId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return The bytes for clusterId.
       */
      public com.google.protobuf.ByteString
          getClusterIdBytes() {
        java.lang.Object ref = clusterId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          clusterId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @param value The clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        clusterId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearClusterId() {
        
        clusterId_ = getDefaultInstance().getClusterId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the Apache Kafka® cluster.
       * </pre>
       *
       * <code>string cluster_id = 2;</code>
       * @param value The bytes for clusterId to set.
       * @return This builder for chaining.
       */
      public Builder setClusterIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        clusterId_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object zoneId_ = "";
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       * @return The zoneId.
       */
      public java.lang.String getZoneId() {
        java.lang.Object ref = zoneId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          zoneId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       * @return The bytes for zoneId.
       */
      public com.google.protobuf.ByteString
          getZoneIdBytes() {
        java.lang.Object ref = zoneId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          zoneId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       * @param value The zoneId to set.
       * @return This builder for chaining.
       */
      public Builder setZoneId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        zoneId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearZoneId() {
        
        zoneId_ = getDefaultInstance().getZoneId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the availability zone where the host resides.
       * </pre>
       *
       * <code>string zone_id = 3;</code>
       * @param value The bytes for zoneId to set.
       * @return This builder for chaining.
       */
      public Builder setZoneIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        zoneId_ = value;
        onChanged();
        return this;
      }

      private int role_ = 0;
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       * @return The enum numeric value on the wire for role.
       */
      @java.lang.Override public int getRoleValue() {
        return role_;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       * @param value The enum numeric value on the wire for role to set.
       * @return This builder for chaining.
       */
      public Builder setRoleValue(int value) {
        
        role_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       * @return The role.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role getRole() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.valueOf(role_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       * @param value The role to set.
       * @return This builder for chaining.
       */
      public Builder setRole(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Role value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        role_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Host role.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Role role = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearRole() {
        
        role_ = 0;
        onChanged();
        return this;
      }

      private yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources resources_;
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> resourcesBuilder_;
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       * @return Whether the resources field is set.
       */
      public boolean hasResources() {
        return resourcesBuilder_ != null || resources_ != null;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       * @return The resources.
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources getResources() {
        if (resourcesBuilder_ == null) {
          return resources_ == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
        } else {
          return resourcesBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder setResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
        if (resourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resources_ = value;
          onChanged();
        } else {
          resourcesBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder setResources(
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder builderForValue) {
        if (resourcesBuilder_ == null) {
          resources_ = builderForValue.build();
          onChanged();
        } else {
          resourcesBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder mergeResources(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources value) {
        if (resourcesBuilder_ == null) {
          if (resources_ != null) {
            resources_ =
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.newBuilder(resources_).mergeFrom(value).buildPartial();
          } else {
            resources_ = value;
          }
          onChanged();
        } else {
          resourcesBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public Builder clearResources() {
        if (resourcesBuilder_ == null) {
          resources_ = null;
          onChanged();
        } else {
          resources_ = null;
          resourcesBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder getResourcesBuilder() {
        
        onChanged();
        return getResourcesFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder getResourcesOrBuilder() {
        if (resourcesBuilder_ != null) {
          return resourcesBuilder_.getMessageOrBuilder();
        } else {
          return resources_ == null ?
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.getDefaultInstance() : resources_;
        }
      }
      /**
       * <pre>
       * Computational resources allocated to the host.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Resources resources = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder> 
          getResourcesFieldBuilder() {
        if (resourcesBuilder_ == null) {
          resourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Resources.Builder, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.ResourcesOrBuilder>(
                  getResources(),
                  getParentForChildren(),
                  isClean());
          resources_ = null;
        }
        return resourcesBuilder_;
      }

      private int health_ = 0;
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       * @return The enum numeric value on the wire for health.
       */
      @java.lang.Override public int getHealthValue() {
        return health_;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       * @param value The enum numeric value on the wire for health to set.
       * @return This builder for chaining.
       */
      public Builder setHealthValue(int value) {
        
        health_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       * @return The health.
       */
      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health getHealth() {
        @SuppressWarnings("deprecation")
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health result = yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.valueOf(health_);
        return result == null ? yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       * @param value The health to set.
       * @return This builder for chaining.
       */
      public Builder setHealth(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host.Health value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        health_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Aggregated host health data.
       * </pre>
       *
       * <code>.yandex.cloud.mdb.kafka.v1.Host.Health health = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearHealth() {
        
        health_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object subnetId_ = "";
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       * @return The subnetId.
       */
      public java.lang.String getSubnetId() {
        java.lang.Object ref = subnetId_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          subnetId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       * @return The bytes for subnetId.
       */
      public com.google.protobuf.ByteString
          getSubnetIdBytes() {
        java.lang.Object ref = subnetId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          subnetId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       * @param value The subnetId to set.
       * @return This builder for chaining.
       */
      public Builder setSubnetId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        subnetId_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearSubnetId() {
        
        subnetId_ = getDefaultInstance().getSubnetId();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * ID of the subnet the host resides in.
       * </pre>
       *
       * <code>string subnet_id = 8;</code>
       * @param value The bytes for subnetId to set.
       * @return This builder for chaining.
       */
      public Builder setSubnetIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        subnetId_ = value;
        onChanged();
        return this;
      }

      private boolean assignPublicIp_ ;
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       * @return The assignPublicIp.
       */
      @java.lang.Override
      public boolean getAssignPublicIp() {
        return assignPublicIp_;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       * @param value The assignPublicIp to set.
       * @return This builder for chaining.
       */
      public Builder setAssignPublicIp(boolean value) {
        
        assignPublicIp_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The flag that defines whether a public IP address is assigned to the node.
       * If the value is `true`, then this node is available on the Internet via it's public IP address.
       * </pre>
       *
       * <code>bool assign_public_ip = 9;</code>
       * @return This builder for chaining.
       */
      public Builder clearAssignPublicIp() {
        
        assignPublicIp_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Host)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Host)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Host>
        PARSER = new com.google.protobuf.AbstractParser<Host>() {
      @java.lang.Override
      public Host parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Host(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Host> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Host> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Host getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface AccessOrBuilder extends
      // @@protoc_insertion_point(interface_extends:yandex.cloud.mdb.kafka.v1.Access)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Allow access for DataTransfer.
     * </pre>
     *
     * <code>bool data_transfer = 1;</code>
     * @return The dataTransfer.
     */
    boolean getDataTransfer();
  }
  /**
   * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Access}
   */
  public static final class Access extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:yandex.cloud.mdb.kafka.v1.Access)
      AccessOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use Access.newBuilder() to construct.
    private Access(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private Access() {
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new Access();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private Access(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {

              dataTransfer_ = input.readBool();
              break;
            }
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Access_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder.class);
    }

    public static final int DATA_TRANSFER_FIELD_NUMBER = 1;
    private boolean dataTransfer_;
    /**
     * <pre>
     * Allow access for DataTransfer.
     * </pre>
     *
     * <code>bool data_transfer = 1;</code>
     * @return The dataTransfer.
     */
    @java.lang.Override
    public boolean getDataTransfer() {
      return dataTransfer_;
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (dataTransfer_ != false) {
        output.writeBool(1, dataTransfer_);
      }
      unknownFields.writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (dataTransfer_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, dataTransfer_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access)) {
        return super.equals(obj);
      }
      yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access other = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access) obj;

      if (getDataTransfer()
          != other.getDataTransfer()) return false;
      if (!unknownFields.equals(other.unknownFields)) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + DATA_TRANSFER_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getDataTransfer());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code yandex.cloud.mdb.kafka.v1.Access}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:yandex.cloud.mdb.kafka.v1.Access)
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.AccessOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor;
      }

      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Access_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.class, yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.Builder.class);
      }

      // Construct using yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        dataTransfer_ = false;

        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getDefaultInstanceForType() {
        return yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.getDefaultInstance();
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access build() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access buildPartial() {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access result = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access(this);
        result.dataTransfer_ = dataTransfer_;
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access) {
          return mergeFrom((yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access other) {
        if (other == yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access.getDefaultInstance()) return this;
        if (other.getDataTransfer() != false) {
          setDataTransfer(other.getDataTransfer());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private boolean dataTransfer_ ;
      /**
       * <pre>
       * Allow access for DataTransfer.
       * </pre>
       *
       * <code>bool data_transfer = 1;</code>
       * @return The dataTransfer.
       */
      @java.lang.Override
      public boolean getDataTransfer() {
        return dataTransfer_;
      }
      /**
       * <pre>
       * Allow access for DataTransfer.
       * </pre>
       *
       * <code>bool data_transfer = 1;</code>
       * @param value The dataTransfer to set.
       * @return This builder for chaining.
       */
      public Builder setDataTransfer(boolean value) {
        
        dataTransfer_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Allow access for DataTransfer.
       * </pre>
       *
       * <code>bool data_transfer = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearDataTransfer() {
        
        dataTransfer_ = false;
        onChanged();
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:yandex.cloud.mdb.kafka.v1.Access)
    }

    // @@protoc_insertion_point(class_scope:yandex.cloud.mdb.kafka.v1.Access)
    private static final yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access();
    }

    public static yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<Access>
        PARSER = new com.google.protobuf.AbstractParser<Access>() {
      @java.lang.Override
      public Access parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Access(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<Access> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<Access> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public yandex.cloud.api.mdb.kafka.v1.ClusterOuterClass.Access getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_yandex_cloud_mdb_kafka_v1_Access_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\'yandex/cloud/mdb/kafka/v1/cluster.prot" +
      "o\022\031yandex.cloud.mdb.kafka.v1\032 google/pro" +
      "tobuf/descriptor.proto\032\036google/protobuf/" +
      "wrappers.proto\032\037google/protobuf/timestam" +
      "p.proto\032&yandex/cloud/mdb/kafka/v1/commo" +
      "n.proto\032+yandex/cloud/mdb/kafka/v1/maint" +
      "enance.proto\"\231\010\n\007Cluster\022\n\n\002id\030\001 \001(\t\022\021\n\t" +
      "folder_id\030\002 \001(\t\022.\n\ncreated_at\030\003 \001(\0132\032.go" +
      "ogle.protobuf.Timestamp\022\014\n\004name\030\004 \001(\t\022\023\n" +
      "\013description\030\005 \001(\t\022>\n\006labels\030\006 \003(\0132..yan" +
      "dex.cloud.mdb.kafka.v1.Cluster.LabelsEnt" +
      "ry\022C\n\013environment\030\007 \001(\0162..yandex.cloud.m" +
      "db.kafka.v1.Cluster.Environment\0229\n\nmonit" +
      "oring\030\010 \003(\0132%.yandex.cloud.mdb.kafka.v1." +
      "Monitoring\0225\n\006config\030\t \001(\0132%.yandex.clou" +
      "d.mdb.kafka.v1.ConfigSpec\022\022\n\nnetwork_id\030" +
      "\n \001(\t\0229\n\006health\030\013 \001(\0162).yandex.cloud.mdb" +
      ".kafka.v1.Cluster.Health\0229\n\006status\030\014 \001(\016" +
      "2).yandex.cloud.mdb.kafka.v1.Cluster.Sta" +
      "tus\022\032\n\022security_group_ids\030\r \003(\t\022\026\n\016host_" +
      "group_ids\030\016 \003(\t\022\033\n\023deletion_protection\030\017" +
      " \001(\010\022H\n\022maintenance_window\030\020 \001(\0132,.yande" +
      "x.cloud.mdb.kafka.v1.MaintenanceWindow\022J" +
      "\n\021planned_operation\030\021 \001(\0132/.yandex.cloud" +
      ".mdb.kafka.v1.MaintenanceOperation\032-\n\013La" +
      "belsEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028" +
      "\001\"I\n\013Environment\022\033\n\027ENVIRONMENT_UNSPECIF" +
      "IED\020\000\022\016\n\nPRODUCTION\020\001\022\r\n\tPRESTABLE\020\002\"?\n\006" +
      "Health\022\022\n\016HEALTH_UNKNOWN\020\000\022\t\n\005ALIVE\020\001\022\010\n" +
      "\004DEAD\020\002\022\014\n\010DEGRADED\020\003\"y\n\006Status\022\022\n\016STATU" +
      "S_UNKNOWN\020\000\022\014\n\010CREATING\020\001\022\013\n\007RUNNING\020\002\022\t" +
      "\n\005ERROR\020\003\022\014\n\010UPDATING\020\004\022\014\n\010STOPPING\020\005\022\013\n" +
      "\007STOPPED\020\006\022\014\n\010STARTING\020\007\"=\n\nMonitoring\022\014" +
      "\n\004name\030\001 \001(\t\022\023\n\013description\030\002 \001(\t\022\014\n\004lin" +
      "k\030\003 \001(\t\"\225\006\n\nConfigSpec\022\017\n\007version\030\001 \001(\t\022" +
      ":\n\005kafka\030\002 \001(\0132+.yandex.cloud.mdb.kafka." +
      "v1.ConfigSpec.Kafka\022B\n\tzookeeper\030\003 \001(\0132/" +
      ".yandex.cloud.mdb.kafka.v1.ConfigSpec.Zo" +
      "okeeper\022\017\n\007zone_id\030\004 \003(\t\0222\n\rbrokers_coun" +
      "t\030\005 \001(\0132\033.google.protobuf.Int64Value\022\030\n\020" +
      "assign_public_ip\030\006 \001(\010\022\030\n\020unmanaged_topi" +
      "cs\030\007 \001(\010\022\027\n\017schema_registry\030\010 \001(\010\0221\n\006acc" +
      "ess\030\t \001(\0132!.yandex.cloud.mdb.kafka.v1.Ac" +
      "cess\022L\n\017rest_api_config\030\n \001(\01323.yandex.c" +
      "loud.mdb.kafka.v1.ConfigSpec.RestAPIConf" +
      "ig\032\372\001\n\005Kafka\0227\n\tresources\030\001 \001(\0132$.yandex" +
      ".cloud.mdb.kafka.v1.Resources\022V\n\020kafka_c" +
      "onfig_2_8\030\004 \001(\0132).yandex.cloud.mdb.kafka" +
      ".v1.KafkaConfig2_8H\000R\017kafkaConfig_2_8\022P\n" +
      "\016kafka_config_3\030\005 \001(\0132\'.yandex.cloud.mdb" +
      ".kafka.v1.KafkaConfig3H\000R\rkafkaConfig_3B" +
      "\016\n\014kafka_config\032D\n\tZookeeper\0227\n\tresource" +
      "s\030\001 \001(\0132$.yandex.cloud.mdb.kafka.v1.Reso" +
      "urces\032 \n\rRestAPIConfig\022\017\n\007enabled\030\001 \001(\010\"" +
      "P\n\tResources\022\032\n\022resource_preset_id\030\001 \001(\t" +
      "\022\021\n\tdisk_size\030\002 \001(\003\022\024\n\014disk_type_id\030\003 \001(" +
      "\t\"\300\t\n\016KafkaConfig2_8\022D\n\020compression_type" +
      "\030\001 \001(\0162*.yandex.cloud.mdb.kafka.v1.Compr" +
      "essionType\022@\n\033log_flush_interval_message" +
      "s\030\002 \001(\0132\033.google.protobuf.Int64Value\022:\n\025" +
      "log_flush_interval_ms\030\003 \001(\0132\033.google.pro" +
      "tobuf.Int64Value\022D\n\037log_flush_scheduler_" +
      "interval_ms\030\004 \001(\0132\033.google.protobuf.Int6" +
      "4Value\0228\n\023log_retention_bytes\030\005 \001(\0132\033.go" +
      "ogle.protobuf.Int64Value\0228\n\023log_retentio" +
      "n_hours\030\006 \001(\0132\033.google.protobuf.Int64Val" +
      "ue\022:\n\025log_retention_minutes\030\007 \001(\0132\033.goog" +
      "le.protobuf.Int64Value\0225\n\020log_retention_" +
      "ms\030\010 \001(\0132\033.google.protobuf.Int64Value\0226\n" +
      "\021log_segment_bytes\030\t \001(\0132\033.google.protob" +
      "uf.Int64Value\0223\n\017log_preallocate\030\n \001(\0132\032" +
      ".google.protobuf.BoolValue\022=\n\030socket_sen" +
      "d_buffer_bytes\030\013 \001(\0132\033.google.protobuf.I" +
      "nt64Value\022@\n\033socket_receive_buffer_bytes" +
      "\030\014 \001(\0132\033.google.protobuf.Int64Value\022=\n\031a" +
      "uto_create_topics_enable\030\r \001(\0132\032.google." +
      "protobuf.BoolValue\0223\n\016num_partitions\030\016 \001" +
      "(\0132\033.google.protobuf.Int64Value\022?\n\032defau" +
      "lt_replication_factor\030\017 \001(\0132\033.google.pro" +
      "tobuf.Int64Value\0226\n\021message_max_bytes\030\020 " +
      "\001(\0132\033.google.protobuf.Int64Value\022<\n\027repl" +
      "ica_fetch_max_bytes\030\021 \001(\0132\033.google.proto" +
      "buf.Int64Value\022\031\n\021ssl_cipher_suites\030\022 \003(" +
      "\t\022>\n\031offsets_retention_minutes\030\023 \001(\0132\033.g" +
      "oogle.protobuf.Int64Value\022I\n\027sasl_enable" +
      "d_mechanisms\030\024 \003(\0162(.yandex.cloud.mdb.ka" +
      "fka.v1.SaslMechanism\"\276\t\n\014KafkaConfig3\022D\n" +
      "\020compression_type\030\001 \001(\0162*.yandex.cloud.m" +
      "db.kafka.v1.CompressionType\022@\n\033log_flush" +
      "_interval_messages\030\002 \001(\0132\033.google.protob" +
      "uf.Int64Value\022:\n\025log_flush_interval_ms\030\003" +
      " \001(\0132\033.google.protobuf.Int64Value\022D\n\037log" +
      "_flush_scheduler_interval_ms\030\004 \001(\0132\033.goo" +
      "gle.protobuf.Int64Value\0228\n\023log_retention" +
      "_bytes\030\005 \001(\0132\033.google.protobuf.Int64Valu" +
      "e\0228\n\023log_retention_hours\030\006 \001(\0132\033.google." +
      "protobuf.Int64Value\022:\n\025log_retention_min" +
      "utes\030\007 \001(\0132\033.google.protobuf.Int64Value\022" +
      "5\n\020log_retention_ms\030\010 \001(\0132\033.google.proto" +
      "buf.Int64Value\0226\n\021log_segment_bytes\030\t \001(" +
      "\0132\033.google.protobuf.Int64Value\0223\n\017log_pr" +
      "eallocate\030\n \001(\0132\032.google.protobuf.BoolVa" +
      "lue\022=\n\030socket_send_buffer_bytes\030\013 \001(\0132\033." +
      "google.protobuf.Int64Value\022@\n\033socket_rec" +
      "eive_buffer_bytes\030\014 \001(\0132\033.google.protobu" +
      "f.Int64Value\022=\n\031auto_create_topics_enabl" +
      "e\030\r \001(\0132\032.google.protobuf.BoolValue\0223\n\016n" +
      "um_partitions\030\016 \001(\0132\033.google.protobuf.In" +
      "t64Value\022?\n\032default_replication_factor\030\017" +
      " \001(\0132\033.google.protobuf.Int64Value\0226\n\021mes" +
      "sage_max_bytes\030\020 \001(\0132\033.google.protobuf.I" +
      "nt64Value\022<\n\027replica_fetch_max_bytes\030\021 \001" +
      "(\0132\033.google.protobuf.Int64Value\022\031\n\021ssl_c" +
      "ipher_suites\030\022 \003(\t\022>\n\031offsets_retention_" +
      "minutes\030\023 \001(\0132\033.google.protobuf.Int64Val" +
      "ue\022I\n\027sasl_enabled_mechanisms\030\024 \003(\0162(.ya" +
      "ndex.cloud.mdb.kafka.v1.SaslMechanism\"\375\002" +
      "\n\004Host\022\014\n\004name\030\001 \001(\t\022\022\n\ncluster_id\030\002 \001(\t" +
      "\022\017\n\007zone_id\030\003 \001(\t\0222\n\004role\030\004 \001(\0162$.yandex" +
      ".cloud.mdb.kafka.v1.Host.Role\0227\n\tresourc" +
      "es\030\005 \001(\0132$.yandex.cloud.mdb.kafka.v1.Res" +
      "ources\0226\n\006health\030\006 \001(\0162&.yandex.cloud.md" +
      "b.kafka.v1.Host.Health\022\021\n\tsubnet_id\030\010 \001(" +
      "\t\022\030\n\020assign_public_ip\030\t \001(\010\"6\n\004Role\022\024\n\020R" +
      "OLE_UNSPECIFIED\020\000\022\t\n\005KAFKA\020\001\022\r\n\tZOOKEEPE" +
      "R\020\002\"8\n\006Health\022\013\n\007UNKNOWN\020\000\022\t\n\005ALIVE\020\001\022\010\n" +
      "\004DEAD\020\002\022\014\n\010DEGRADED\020\003\"\037\n\006Access\022\025\n\rdata_" +
      "transfer\030\001 \001(\010Bd\n\035yandex.cloud.api.mdb.k" +
      "afka.v1ZCgithub.com/yandex-cloud/go-genp" +
      "roto/yandex/cloud/mdb/kafka/v1;kafkab\006pr" +
      "oto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          com.google.protobuf.DescriptorProtos.getDescriptor(),
          com.google.protobuf.WrappersProto.getDescriptor(),
          com.google.protobuf.TimestampProto.getDescriptor(),
          yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor(),
          yandex.cloud.api.mdb.kafka.v1.Maintenance.getDescriptor(),
        });
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor,
        new java.lang.String[] { "Id", "FolderId", "CreatedAt", "Name", "Description", "Labels", "Environment", "Monitoring", "Config", "NetworkId", "Health", "Status", "SecurityGroupIds", "HostGroupIds", "DeletionProtection", "MaintenanceWindow", "PlannedOperation", });
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_Cluster_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Cluster_LabelsEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Monitoring_descriptor,
        new java.lang.String[] { "Name", "Description", "Link", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor,
        new java.lang.String[] { "Version", "Kafka", "Zookeeper", "ZoneId", "BrokersCount", "AssignPublicIp", "UnmanagedTopics", "SchemaRegistry", "Access", "RestApiConfig", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor.getNestedTypes().get(0);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Kafka_descriptor,
        new java.lang.String[] { "Resources", "KafkaConfig28", "KafkaConfig3", "KafkaConfig", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor.getNestedTypes().get(1);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_Zookeeper_descriptor,
        new java.lang.String[] { "Resources", });
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor =
      internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_descriptor.getNestedTypes().get(2);
    internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_ConfigSpec_RestAPIConfig_descriptor,
        new java.lang.String[] { "Enabled", });
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_yandex_cloud_mdb_kafka_v1_Resources_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Resources_descriptor,
        new java.lang.String[] { "ResourcePresetId", "DiskSize", "DiskTypeId", });
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig2_8_descriptor,
        new java.lang.String[] { "CompressionType", "LogFlushIntervalMessages", "LogFlushIntervalMs", "LogFlushSchedulerIntervalMs", "LogRetentionBytes", "LogRetentionHours", "LogRetentionMinutes", "LogRetentionMs", "LogSegmentBytes", "LogPreallocate", "SocketSendBufferBytes", "SocketReceiveBufferBytes", "AutoCreateTopicsEnable", "NumPartitions", "DefaultReplicationFactor", "MessageMaxBytes", "ReplicaFetchMaxBytes", "SslCipherSuites", "OffsetsRetentionMinutes", "SaslEnabledMechanisms", });
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_KafkaConfig3_descriptor,
        new java.lang.String[] { "CompressionType", "LogFlushIntervalMessages", "LogFlushIntervalMs", "LogFlushSchedulerIntervalMs", "LogRetentionBytes", "LogRetentionHours", "LogRetentionMinutes", "LogRetentionMs", "LogSegmentBytes", "LogPreallocate", "SocketSendBufferBytes", "SocketReceiveBufferBytes", "AutoCreateTopicsEnable", "NumPartitions", "DefaultReplicationFactor", "MessageMaxBytes", "ReplicaFetchMaxBytes", "SslCipherSuites", "OffsetsRetentionMinutes", "SaslEnabledMechanisms", });
    internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_yandex_cloud_mdb_kafka_v1_Host_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Host_descriptor,
        new java.lang.String[] { "Name", "ClusterId", "ZoneId", "Role", "Resources", "Health", "SubnetId", "AssignPublicIp", });
    internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_yandex_cloud_mdb_kafka_v1_Access_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_yandex_cloud_mdb_kafka_v1_Access_descriptor,
        new java.lang.String[] { "DataTransfer", });
    com.google.protobuf.DescriptorProtos.getDescriptor();
    com.google.protobuf.WrappersProto.getDescriptor();
    com.google.protobuf.TimestampProto.getDescriptor();
    yandex.cloud.api.mdb.kafka.v1.Common.getDescriptor();
    yandex.cloud.api.mdb.kafka.v1.Maintenance.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
